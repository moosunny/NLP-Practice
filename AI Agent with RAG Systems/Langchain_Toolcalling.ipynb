{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.3.1 (from -r requirements.txt (line 1))\n",
      "  Downloading langchain-0.3.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langgraph==0.2.34 (from -r requirements.txt (line 2))\n",
      "  Downloading langgraph-0.2.34-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain-openai==0.2.1 (from -r requirements.txt (line 3))\n",
      "  Downloading langchain_openai-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain-community==0.3.1 (from -r requirements.txt (line 4))\n",
      "  Downloading langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting langchain-chroma==0.1.4 (from -r requirements.txt (line 5))\n",
      "  Downloading langchain_chroma-0.1.4-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting langchain-ollama==0.2.0 (from -r requirements.txt (line 6))\n",
      "  Downloading langchain_ollama-0.2.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langchain-google-genai==2.0.0 (from -r requirements.txt (line 7))\n",
      "  Downloading langchain_google_genai-2.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting langchain-groq==0.2.0 (from -r requirements.txt (line 8))\n",
      "  Downloading langchain_groq-0.2.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio==4.44.1 (from -r requirements.txt (line 9))\n",
      "  Downloading gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (1.0.1)\n",
      "Collecting bs4==0.0.2 (from -r requirements.txt (line 11))\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting wikipedia==1.4.0 (from -r requirements.txt (line 12))\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from langchain==0.3.1->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from langchain==0.3.1->-r requirements.txt (line 1)) (2.0.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from langchain==0.3.1->-r requirements.txt (line 1)) (3.11.14)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from langchain==0.3.1->-r requirements.txt (line 1)) (0.3.51)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from langchain==0.3.1->-r requirements.txt (line 1)) (0.3.8)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.3.1->-r requirements.txt (line 1))\n",
      "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy<2,>=1 (from langchain==0.3.1->-r requirements.txt (line 1))\n",
      "  Downloading numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from langchain==0.3.1->-r requirements.txt (line 1)) (2.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from langchain==0.3.1->-r requirements.txt (line 1)) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain==0.3.1->-r requirements.txt (line 1))\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from langgraph==0.2.34->-r requirements.txt (line 2)) (2.0.21)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from langchain-openai==0.2.1->-r requirements.txt (line 3)) (1.68.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from langchain-openai==0.2.1->-r requirements.txt (line 3)) (0.9.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from langchain-community==0.3.1->-r requirements.txt (line 4)) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from langchain-community==0.3.1->-r requirements.txt (line 4)) (2.8.1)\n",
      "Collecting chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 (from langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: fastapi<1,>=0.95.2 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.115.9)\n",
      "Requirement already satisfied: ollama<1,>=0.3.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from langchain-ollama==0.2.0->-r requirements.txt (line 6)) (0.4.7)\n",
      "Collecting google-generativeai<0.8.0,>=0.7.0 (from langchain-google-genai==2.0.0->-r requirements.txt (line 7))\n",
      "  Downloading google_generativeai-0.7.2-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from langchain-groq==0.2.0->-r requirements.txt (line 8)) (0.22.0)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (4.9.0)\n",
      "Collecting ffmpy (from gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.3.0 (from gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (0.29.3)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (6.5.2)\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (3.1.6)\n",
      "Collecting markupsafe~=2.0 (from gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (3.10.1)\n",
      "Requirement already satisfied: orjson~=3.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (3.10.15)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (2.2.3)\n",
      "Collecting pillow<11.0,>=8.0 (from gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading pillow-10.4.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting pydub (from gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting ruff>=0.2.2 (from gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading ruff-0.11.4-py3-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (0.12.5)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (4.12.2)\n",
      "Requirement already satisfied: urllib3~=2.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (2.3.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (0.34.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from bs4==0.0.2->-r requirements.txt (line 11)) (4.13.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from gradio-client==1.3.0->gradio==4.44.1->-r requirements.txt (line 9)) (2025.3.0)\n",
      "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading websockets-12.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1->-r requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1->-r requirements.txt (line 1)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1->-r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1->-r requirements.txt (line 1)) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1->-r requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1->-r requirements.txt (line 1)) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio==4.44.1->-r requirements.txt (line 9)) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio==4.44.1->-r requirements.txt (line 9)) (1.3.1)\n",
      "Requirement already satisfied: build>=1.0.3 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.7.6)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (3.23.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.31.1)\n",
      "Collecting tokenizers<=0.20.3,>=0.13.2 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading tokenizers-0.20.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (7.7.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.71.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (4.3.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (32.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (5.1.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (13.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.1->-r requirements.txt (line 4)) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.1->-r requirements.txt (line 4)) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from fastapi<1,>=0.95.2->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.45.3)\n",
      "Collecting google-ai-generativelanguage==0.6.6 (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7))\n",
      "  Downloading google_ai_generativelanguage-0.6.6-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: google-api-core in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7)) (2.24.2)\n",
      "Collecting google-api-python-client (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7))\n",
      "  Downloading google_api_python_client-2.166.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7)) (2.38.0)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7)) (5.29.4)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7)) (1.26.1)\n",
      "Collecting protobuf (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7))\n",
      "  Downloading protobuf-4.25.6-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from groq<1,>=0.4.1->langchain-groq==0.2.0->-r requirements.txt (line 8)) (1.9.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from httpx>=0.24.1->gradio==4.44.1->-r requirements.txt (line 9)) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from httpx>=0.24.1->gradio==4.44.1->-r requirements.txt (line 9)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio==4.44.1->-r requirements.txt (line 9)) (0.14.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from huggingface-hub>=0.19.3->gradio==4.44.1->-r requirements.txt (line 9)) (3.18.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain==0.3.1->-r requirements.txt (line 1)) (1.33)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph==0.2.34->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.1->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==4.44.1->-r requirements.txt (line 9)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==4.44.1->-r requirements.txt (line 9)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==4.44.1->-r requirements.txt (line 9)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==4.44.1->-r requirements.txt (line 9)) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==4.44.1->-r requirements.txt (line 9)) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==4.44.1->-r requirements.txt (line 9)) (2.9.0.post0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.1->-r requirements.txt (line 3)) (0.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio==4.44.1->-r requirements.txt (line 9)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio==4.44.1->-r requirements.txt (line 9)) (2025.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.1->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.1->-r requirements.txt (line 1)) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.3.1->-r requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.1->-r requirements.txt (line 3)) (2024.11.6)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio==4.44.1->-r requirements.txt (line 9)) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio==4.44.1->-r requirements.txt (line 9)) (1.5.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from beautifulsoup4->bs4==0.0.2->-r requirements.txt (line 11)) (2.6)\n",
      "Requirement already satisfied: pyproject_hooks in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7)) (1.69.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7)) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7)) (4.9)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain==0.3.1->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.17.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.9)\n",
      "Requirement already satisfied: coloredlogs in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (25.2.10)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (8.6.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.31.1 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.31.1 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.31.1)\n",
      "INFO: pip is looking at multiple versions of opentelemetry-proto to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.31.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.31.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.31.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.31.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_proto-1.31.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_sdk-1.29.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_proto-1.28.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_sdk-1.28.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_proto-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "INFO: pip is still looking at multiple versions of opentelemetry-proto to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_proto-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.52b1 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.52b1 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.52b1 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.52b1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from opentelemetry-instrumentation-asgi==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (3.8.1)\n",
      "INFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-semantic-conventions==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Using cached opentelemetry_semantic_conventions-0.52b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.52b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Using cached opentelemetry_instrumentation-0.52b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "INFO: pip is still looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.52b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.52b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation-0.52b0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_semantic_conventions-0.52b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_util_http-0.52b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_api-1.31.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting importlib-metadata<=8.5.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-util-http==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_api-1.29.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-util-http==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_api-1.28.2-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.49b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.49b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation-0.49b1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_semantic_conventions-0.49b1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_util_http-0.49b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_api-1.28.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.49b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.49b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation-0.49b0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_semantic_conventions-0.49b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_util_http-0.49b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_api-1.28.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (75.8.0)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting importlib-metadata<=8.4.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (2.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (2.19.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.1->-r requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.0.4)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7))\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7))\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7))\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7)) (1.71.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7)) (0.6.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/Deeplearning/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.3.0)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7))\n",
      "  Downloading grpcio_status-1.71.0rc2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.70.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.69.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.69.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.68.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_status-1.68.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.67.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.67.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.67.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading grpcio_status-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0rc5-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0rc3-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0rc2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.5-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.4-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.0rc2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.3-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.0rc2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain-0.3.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langgraph-0.2.34-py3-none-any.whl (107 kB)\n",
      "Downloading langchain_openai-0.2.1-py3-none-any.whl (49 kB)\n",
      "Downloading langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_chroma-0.1.4-py3-none-any.whl (10 kB)\n",
      "Downloading langchain_ollama-0.2.0-py3-none-any.whl (14 kB)\n",
      "Downloading langchain_google_genai-2.0.0-py3-none-any.whl (39 kB)\n",
      "Downloading langchain_groq-0.2.0-py3-none-any.whl (14 kB)\n",
      "Downloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
      "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading chromadb-0.5.23-py3-none-any.whl (628 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_generativeai-0.7.2-py3-none-any.whl (164 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.6-py3-none-any.whl (718 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m718.3/718.3 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Downloading MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_universal2.whl (18 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.4.0-cp311-cp311-macosx_11_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.11.4-py3-none-macosx_11_0_arm64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading protobuf-4.25.6-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n",
      "Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
      "Downloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
      "Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
      "Downloading tokenizers-0.20.3-cp311-cp311-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-12.0-cp311-cp311-macosx_11_0_arm64.whl (121 kB)\n",
      "Downloading google_api_python_client-2.166.0-py2.py3-none-any.whl (13.2 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio_status-1.63.0rc1-py3-none-any.whl (14 kB)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11728 sha256=254ea8fd1ad55cb4831f60cc5c1ff04061e6c7b4a68717d4a91967f12c5fe5c7\n",
      "  Stored in directory: /Users/choimusun/Library/Caches/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: pydub, websockets, uritemplate, tomlkit, tenacity, semantic-version, ruff, python-multipart, protobuf, pillow, opentelemetry-util-http, numpy, markupsafe, importlib-metadata, httplib2, ffmpy, aiofiles, wikipedia, opentelemetry-proto, opentelemetry-api, bs4, tokenizers, opentelemetry-semantic-conventions, opentelemetry-instrumentation, opentelemetry-exporter-otlp-proto-common, langsmith, grpcio-status, gradio-client, google-auth-httplib2, opentelemetry-sdk, opentelemetry-instrumentation-asgi, gradio, google-api-python-client, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, langchain-openai, langchain-ollama, langchain-groq, google-ai-generativelanguage, langgraph, langchain, google-generativeai, chromadb, langchain-google-genai, langchain-community, langchain-chroma\n",
      "  Attempting uninstall: websockets\n",
      "    Found existing installation: websockets 15.0.1\n",
      "    Uninstalling websockets-15.0.1:\n",
      "      Successfully uninstalled websockets-15.0.1\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.29.4\n",
      "    Uninstalling protobuf-5.29.4:\n",
      "      Successfully uninstalled protobuf-5.29.4\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.1.0\n",
      "    Uninstalling pillow-11.1.0:\n",
      "      Successfully uninstalled pillow-11.1.0\n",
      "  Attempting uninstall: opentelemetry-util-http\n",
      "    Found existing installation: opentelemetry-util-http 0.52b1\n",
      "    Uninstalling opentelemetry-util-http-0.52b1:\n",
      "      Successfully uninstalled opentelemetry-util-http-0.52b1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.4\n",
      "    Uninstalling numpy-2.2.4:\n",
      "      Successfully uninstalled numpy-2.2.4\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib_metadata 8.6.1\n",
      "    Uninstalling importlib_metadata-8.6.1:\n",
      "      Successfully uninstalled importlib_metadata-8.6.1\n",
      "  Attempting uninstall: opentelemetry-proto\n",
      "    Found existing installation: opentelemetry-proto 1.31.1\n",
      "    Uninstalling opentelemetry-proto-1.31.1:\n",
      "      Successfully uninstalled opentelemetry-proto-1.31.1\n",
      "  Attempting uninstall: opentelemetry-api\n",
      "    Found existing installation: opentelemetry-api 1.31.1\n",
      "    Uninstalling opentelemetry-api-1.31.1:\n",
      "      Successfully uninstalled opentelemetry-api-1.31.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.1\n",
      "    Uninstalling tokenizers-0.21.1:\n",
      "      Successfully uninstalled tokenizers-0.21.1\n",
      "  Attempting uninstall: opentelemetry-semantic-conventions\n",
      "    Found existing installation: opentelemetry-semantic-conventions 0.52b1\n",
      "    Uninstalling opentelemetry-semantic-conventions-0.52b1:\n",
      "      Successfully uninstalled opentelemetry-semantic-conventions-0.52b1\n",
      "  Attempting uninstall: opentelemetry-instrumentation\n",
      "    Found existing installation: opentelemetry-instrumentation 0.52b1\n",
      "    Uninstalling opentelemetry-instrumentation-0.52b1:\n",
      "      Successfully uninstalled opentelemetry-instrumentation-0.52b1\n",
      "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
      "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.31.1\n",
      "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.31.1:\n",
      "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.31.1\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.3.18\n",
      "    Uninstalling langsmith-0.3.18:\n",
      "      Successfully uninstalled langsmith-0.3.18\n",
      "  Attempting uninstall: grpcio-status\n",
      "    Found existing installation: grpcio-status 1.71.0\n",
      "    Uninstalling grpcio-status-1.71.0:\n",
      "      Successfully uninstalled grpcio-status-1.71.0\n",
      "  Attempting uninstall: opentelemetry-sdk\n",
      "    Found existing installation: opentelemetry-sdk 1.31.1\n",
      "    Uninstalling opentelemetry-sdk-1.31.1:\n",
      "      Successfully uninstalled opentelemetry-sdk-1.31.1\n",
      "  Attempting uninstall: opentelemetry-instrumentation-asgi\n",
      "    Found existing installation: opentelemetry-instrumentation-asgi 0.52b1\n",
      "    Uninstalling opentelemetry-instrumentation-asgi-0.52b1:\n",
      "      Successfully uninstalled opentelemetry-instrumentation-asgi-0.52b1\n",
      "  Attempting uninstall: opentelemetry-instrumentation-fastapi\n",
      "    Found existing installation: opentelemetry-instrumentation-fastapi 0.52b1\n",
      "    Uninstalling opentelemetry-instrumentation-fastapi-0.52b1:\n",
      "      Successfully uninstalled opentelemetry-instrumentation-fastapi-0.52b1\n",
      "  Attempting uninstall: opentelemetry-exporter-otlp-proto-grpc\n",
      "    Found existing installation: opentelemetry-exporter-otlp-proto-grpc 1.31.1\n",
      "    Uninstalling opentelemetry-exporter-otlp-proto-grpc-1.31.1:\n",
      "      Successfully uninstalled opentelemetry-exporter-otlp-proto-grpc-1.31.1\n",
      "  Attempting uninstall: langchain-openai\n",
      "    Found existing installation: langchain-openai 0.3.12\n",
      "    Uninstalling langchain-openai-0.3.12:\n",
      "      Successfully uninstalled langchain-openai-0.3.12\n",
      "  Attempting uninstall: langchain-ollama\n",
      "    Found existing installation: langchain-ollama 0.2.3\n",
      "    Uninstalling langchain-ollama-0.2.3:\n",
      "      Successfully uninstalled langchain-ollama-0.2.3\n",
      "  Attempting uninstall: langchain-groq\n",
      "    Found existing installation: langchain-groq 0.3.2\n",
      "    Uninstalling langchain-groq-0.3.2:\n",
      "      Successfully uninstalled langchain-groq-0.3.2\n",
      "  Attempting uninstall: google-ai-generativelanguage\n",
      "    Found existing installation: google-ai-generativelanguage 0.6.17\n",
      "    Uninstalling google-ai-generativelanguage-0.6.17:\n",
      "      Successfully uninstalled google-ai-generativelanguage-0.6.17\n",
      "  Attempting uninstall: langgraph\n",
      "    Found existing installation: langgraph 0.3.25\n",
      "    Uninstalling langgraph-0.3.25:\n",
      "      Successfully uninstalled langgraph-0.3.25\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.23\n",
      "    Uninstalling langchain-0.3.23:\n",
      "      Successfully uninstalled langchain-0.3.23\n",
      "  Attempting uninstall: chromadb\n",
      "    Found existing installation: chromadb 1.0.0\n",
      "    Uninstalling chromadb-1.0.0:\n",
      "      Successfully uninstalled chromadb-1.0.0\n",
      "  Attempting uninstall: langchain-google-genai\n",
      "    Found existing installation: langchain-google-genai 2.1.2\n",
      "    Uninstalling langchain-google-genai-2.1.2:\n",
      "      Successfully uninstalled langchain-google-genai-2.1.2\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.3.21\n",
      "    Uninstalling langchain-community-0.3.21:\n",
      "      Successfully uninstalled langchain-community-0.3.21\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 4.49.0 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\n",
      "grpcio-tools 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiofiles-23.2.1 bs4-0.0.2 chromadb-0.5.23 ffmpy-0.5.0 google-ai-generativelanguage-0.6.6 google-api-python-client-2.166.0 google-auth-httplib2-0.2.0 google-generativeai-0.7.2 gradio-4.44.1 gradio-client-1.3.0 grpcio-status-1.63.0rc1 httplib2-0.22.0 importlib-metadata-8.4.0 langchain-0.3.1 langchain-chroma-0.1.4 langchain-community-0.3.1 langchain-google-genai-2.0.0 langchain-groq-0.2.0 langchain-ollama-0.2.0 langchain-openai-0.2.1 langgraph-0.2.34 langsmith-0.1.147 markupsafe-2.1.5 numpy-1.26.4 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 pillow-10.4.0 protobuf-4.25.6 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.4 semantic-version-2.10.0 tenacity-8.5.0 tokenizers-0.20.3 tomlkit-0.12.0 uritemplate-4.1.1 websockets-12.0 wikipedia-1.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, json\n",
    "\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    \n",
    "tavily   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://m.blog.naver.com/wineislikeacat/223096696241', 'content': ' ,     ?  ,  !\\n\\n     .\\n       .\\n       ,\\n     .\\n\\u200b\\n        ,\\n        \\n        .\\n\\u200b\\n  \\n (Carbernet Sauvignon), (Syrah)  !\\n\\u200b\\n\\n   \\n\\n    ? ! [...]      !\\n, !\\n\\u200b\\n     ?\\n        .\\n        :)\\n\\u200b\\n      \\n    .\\n\\u200b\\n? ?  ?    ! - 1,  :)          ... blog.naver.com\\n ? ?  ?    ! - 2,  :)      4  . ... blog.naver.com\\n\\u200b\\n\\n &     [...]         \\n           .\\n            .\\n\\u200b\\n           \\n (Sangiovege)   .\\n\\u200b\\n\\n  \\n\\n   ? ,  !\\n\\n   \\n      .\\n      .\\n\\u200b\\n      \\n    ,\\n      .\\n\\u200b\\n        \\n    (Malbec)   !\\n\\u200b'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'url': 'https://mashija.com/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%B5%9C%EA%B3%A0%EC%9D%98-%EC%99%80%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%A0%EB%A5%BC-%EA%B2%83%EC%9D%B8/', 'content': 'Bora Kim 2022 1 27\\n (Cabernet Sauvignon)  (Malbec)       ,       ,           . [...] <     5  >\\n  (Cabernet Sauvignon)\\n (Malbec)\\n / (Grenache / Shiraz blends)\\n /(Syrah / Shiraz)\\n (Sangiovese)\\n              .\\n        ,             .\\n<   >\\n              ,        . [...]    (Karen MacNeil)     10  (grilled)          .\\n       \\n2018    (Peter Richards MW)              . .\\n    (Cabernet Franc) ?  (Carignan), (Cinsault)     (Syrah) ? DWWA    Decanter Retailer Awards     (ros)    . .'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'url': 'http://mustnews.co.kr/View.aspx?No=1526378', 'content': ' 40       ,          ,   .\\n\\n>>    2016\\n\\n :  U.S.A  \\n\\n SIP         .\\n\\n         ,                    .\\n\\n\\n\\n\\r\\n                                     \\r\\n                                    wzerow@mustnews.co.kr\\n\\n \\n\\n \\n\\n \\n\\n\\n\\n \\n\\n\\n\\n \\n\\n \\n\\n  [...]  \\n\\n\\n\\n   \\n\\n\\n\\n>>  ,   \\n\\n :  U.S.A \\n\\n, ,                .\\n\\n      .     7                     .\\n\\n>>  ,     2016\\n\\n :  \\n\\n  , ,    ,       . [...]   5110,1 107-222\\xa0 |\\xa0  : 070-8840-5040\\xa0 |\\xa0  : 0504-222-7103\\r\\n : \\xa0 |\\xa0  : 504 \\xa0 |\\xa0  :  :   52094\\xa0 |\\xa0  : 2019-01-20\\xa0 |\\xa0  : 2019-02-07\\xa0 |\\xa0  : \\r\\n :  |\\xa0   (,, )   ,   ,   .\\r\\nCopyright  2024\\xa0. All rights reserved. mail to wzerow@mustnews.co.kr'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'url': 'https://blog.naver.com/chelina89/220634349414?viewType=pc', 'content': '1.  - 6 .            .  2.   - 3'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "query = \"   .\"\n",
    "\n",
    "web_search = TavilySearchResults(max_results=4)\n",
    "\n",
    "search_results = web_search.invoke(query)\n",
    "\n",
    "for result in search_results:\n",
    "    print(result)\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": \n",
      "<class 'list'>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "name: \n",
      "tavily_search_results_json\n",
      "----------------------------------------------------------------------------------------------------\n",
      "description: \n",
      "A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "schema: \n",
      "{'description': 'Input for the Tavily tool.', 'properties': {'query': {'description': 'search query to look up', 'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'TavilyInput', 'type': 'object'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\": \")\n",
    "print(type(search_results))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(web_search.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "print(web_search.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "print(web_search.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI   Toolcalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools([web_search]) #tavily    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "content='!  ?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 82, 'total_tokens': 94, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'finish_reason': 'stop', 'logprobs': None} id='run-0a9809ec-10c0-4ff2-b377-cec9649c7efe-0' usage_metadata={'input_tokens': 82, 'output_tokens': 12, 'total_tokens': 94}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "!  ?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = '.'\n",
    "print(query)\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "print(ai_msg)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(ai_msg.content)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(ai_msg.tool_calls)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_BHh7S21cYQsL9937qWVjxi26', 'function': {'arguments': '{\"query\":\"   \"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 91, 'total_tokens': 119, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-6d280e8b-aa8b-45be-bf91-18e320e18c26-0' tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': '   '}, 'id': 'call_BHh7S21cYQsL9937qWVjxi26', 'type': 'tool_call'}] usage_metadata={'input_tokens': 91, 'output_tokens': 28, 'total_tokens': 119}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[{'name': 'tavily_search_results_json', 'args': {'query': '   '}, 'id': 'call_BHh7S21cYQsL9937qWVjxi26', 'type': 'tool_call'}]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"   .\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "print(ai_msg)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(ai_msg.content)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(ai_msg.tool_calls)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'tavily_search_results_json',\n",
       " 'args': {'query': '   '},\n",
       " 'id': 'call_BHh7S21cYQsL9937qWVjxi26',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = ai_msg.tool_calls[0]\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tavily_search_results_json   : \n",
      "----------------------------------------------------------------------------------------------------\n",
      "[{'url': 'https://alcohol.hobby-tech.com/entry/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%B0%B0%EB%96%A1%EA%B6%81%ED%95%A9-%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%97%90-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%99%80%EC%9D%B8-5%EA%B0%80%EC%A7%80', 'content': ' ;  ;  .  :    ;   (Chteau Margaux).    '}, {'url': 'https://m.blog.naver.com/wineislikeacat/223096696241', 'content': ' ,     ?  ,  !\\n\\n     .\\n       .\\n       ,\\n     .\\n\\u200b\\n        ,\\n        \\n        .\\n\\u200b\\n  \\n (Carbernet Sauvignon), (Syrah)  !\\n\\u200b\\n\\n   \\n\\n    ? ! [...]      !\\n, !\\n\\u200b\\n     ?\\n        .\\n        :)\\n\\u200b\\n      \\n    .\\n\\u200b\\n? ?  ?    ! - 1,  :)          ... blog.naver.com\\n ? ?  ?    ! - 2,  :)      4  . ... blog.naver.com\\n\\u200b\\n\\n &     [...]         \\n           .\\n            .\\n\\u200b\\n           \\n (Sangiovege)   .\\n\\u200b\\n\\n  \\n\\n   ? ,  !\\n\\n   \\n      .\\n      .\\n\\u200b\\n      \\n    ,\\n      .\\n\\u200b\\n        \\n    (Malbec)   !\\n\\u200b'}, {'url': 'https://mashija.com/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%B5%9C%EA%B3%A0%EC%9D%98-%EC%99%80%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%A0%EB%A5%BC-%EA%B2%83%EC%9D%B8/', 'content': 'Bora Kim 2022 1 27\\n (Cabernet Sauvignon)  (Malbec)       ,       ,           . [...] <     5  >\\n  (Cabernet Sauvignon)\\n (Malbec)\\n / (Grenache / Shiraz blends)\\n /(Syrah / Shiraz)\\n (Sangiovese)\\n              .\\n        ,             .\\n<   >\\n              ,        . [...]      .      . 2020    .\\n    2007                (Syrah)   (Cte-Rtie)  (Super Tuscan)  . .\\n            .\\n   \\n         . (barnaise)         .    . .\\n<  >\\n   ,            ?'}, {'url': 'https://stibee.com/api/v1.0/emails/share/vf0yvmd1Z2AYBb3sKfktNyCXRMV2lAI=', 'content': '     (Vintage Champagne)      ,    ,           .\\n\\n ,     (Pinot noir)    /       .\\n\\n\\n\\n,      ,           ! \\n\\n |  | \\n | \\n\\n | [...]     ,    ,         . ,    (Pinot noir)    /       .,      ,           !  [...]     ,    ,         . ,    (Pinot noir)    /       .,      ,           ! '}]\n"
     ]
    }
   ],
   "source": [
    "###    \n",
    "\n",
    "tool_output = web_search.invoke(tool_call[\"args\"])\n",
    "print(f\"{tool_call['name']}   : \")\n",
    "print(\"-\"*100)\n",
    "print(tool_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=[{'url': 'https://alcohol.hobby-tech.com/entry/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%B0%B0%EB%96%A1%EA%B6%81%ED%95%A9-%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%97%90-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%99%80%EC%9D%B8-5%EA%B0%80%EC%A7%80', 'content': ' ;  ;  .  :    ;   (Chteau Margaux).    '}, {'url': 'https://m.blog.naver.com/wineislikeacat/223096696241', 'content': ' ,     ?  ,  !\\n\\n     .\\n       .\\n       ,\\n     .\\n\\u200b\\n        ,\\n        \\n        .\\n\\u200b\\n  \\n (Carbernet Sauvignon), (Syrah)  !\\n\\u200b\\n\\n   \\n\\n    ? ! [...]      !\\n, !\\n\\u200b\\n     ?\\n        .\\n        :)\\n\\u200b\\n      \\n    .\\n\\u200b\\n? ?  ?    ! - 1,  :)          ... blog.naver.com\\n ? ?  ?    ! - 2,  :)      4  . ... blog.naver.com\\n\\u200b\\n\\n &     [...]         \\n           .\\n            .\\n\\u200b\\n           \\n (Sangiovege)   .\\n\\u200b\\n\\n  \\n\\n   ? ,  !\\n\\n   \\n      .\\n      .\\n\\u200b\\n      \\n    ,\\n      .\\n\\u200b\\n        \\n    (Malbec)   !\\n\\u200b'}, {'url': 'https://mashija.com/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%B5%9C%EA%B3%A0%EC%9D%98-%EC%99%80%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%A0%EB%A5%BC-%EA%B2%83%EC%9D%B8/', 'content': 'Bora Kim 2022 1 27\\n (Cabernet Sauvignon)  (Malbec)       ,       ,           . [...] <     5  >\\n  (Cabernet Sauvignon)\\n (Malbec)\\n / (Grenache / Shiraz blends)\\n /(Syrah / Shiraz)\\n (Sangiovese)\\n              .\\n        ,             .\\n<   >\\n              ,        . [...]      .      . 2020    .\\n    2007                (Syrah)   (Cte-Rtie)  (Super Tuscan)  . .\\n            .\\n   \\n         . (barnaise)         .    . .\\n<  >\\n   ,            ?'}, {'url': 'https://stibee.com/api/v1.0/emails/share/vf0yvmd1Z2AYBb3sKfktNyCXRMV2lAI=', 'content': '     (Vintage Champagne)      ,    ,           .\\n\\n ,     (Pinot noir)    /       .\\n\\n\\n\\n,      ,           ! \\n\\n |  | \\n | \\n\\n | [...]     ,    ,         . ,    (Pinot noir)    /       .,      ,           !  [...]     ,    ,         . ,    (Pinot noir)    /       .,      ,           ! '}] name='tavily_search_results_json' tool_call_id='call_BHh7S21cYQsL9937qWVjxi26'\n"
     ]
    }
   ],
   "source": [
    "# toolMessage \n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "tool_message = ToolMessage(\n",
    "    name=tool_call[\"name\"],\n",
    "    tool_call_id=tool_call[\"id\"],\n",
    "    content=tool_output\n",
    ")\n",
    "\n",
    "print(tool_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='[{\"url\": \"https://alcohol.hobby-tech.com/entry/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%B0%B0%EB%96%A1%EA%B6%81%ED%95%A9-%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%97%90-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%99%80%EC%9D%B8-5%EA%B0%80%EC%A7%80\", \"content\": \" ;  ;  .  :    ;   (Chteau Margaux).    \"}, {\"url\": \"https://m.blog.naver.com/wineislikeacat/223096696241\", \"content\": \" ,     ?  ,  !\\\\n\\\\n     .\\\\n       .\\\\n       ,\\\\n     .\\\\n\\u200b\\\\n        ,\\\\n        \\\\n        .\\\\n\\u200b\\\\n  \\\\n (Carbernet Sauvignon), (Syrah)  !\\\\n\\u200b\\\\n\\\\n   \\\\n\\\\n    ? ! [...]      !\\\\n, !\\\\n\\u200b\\\\n     ?\\\\n        .\\\\n        :)\\\\n\\u200b\\\\n      \\\\n    .\\\\n\\u200b\\\\n? ?  ?    ! - 1,  :)          ... blog.naver.com\\\\n ? ?  ?    ! - 2,  :)      4  . ... blog.naver.com\\\\n\\u200b\\\\n\\\\n &     [...]         \\\\n           .\\\\n            .\\\\n\\u200b\\\\n           \\\\n (Sangiovege)   .\\\\n\\u200b\\\\n\\\\n  \\\\n\\\\n   ? ,  !\\\\n\\\\n   \\\\n      .\\\\n      .\\\\n\\u200b\\\\n      \\\\n    ,\\\\n      .\\\\n\\u200b\\\\n        \\\\n    (Malbec)   !\\\\n\\u200b\"}, {\"url\": \"https://mashija.com/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%B5%9C%EA%B3%A0%EC%9D%98-%EC%99%80%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%A0%EB%A5%BC-%EA%B2%83%EC%9D%B8/\", \"content\": \"Bora Kim 2022 1 27\\\\n (Cabernet Sauvignon)  (Malbec)       ,       ,           . [...] <     5  >\\\\n  (Cabernet Sauvignon)\\\\n (Malbec)\\\\n / (Grenache / Shiraz blends)\\\\n /(Syrah / Shiraz)\\\\n (Sangiovese)\\\\n              .\\\\n        ,             .\\\\n<   >\\\\n              ,        . [...]      .      . 2020    .\\\\n    2007                (Syrah)   (Cte-Rtie)  (Super Tuscan)  . .\\\\n            .\\\\n   \\\\n         . (barnaise)         .    . .\\\\n<  >\\\\n   ,            ?\"}, {\"url\": \"https://stibee.com/api/v1.0/emails/share/vf0yvmd1Z2AYBb3sKfktNyCXRMV2lAI=\", \"content\": \"     (Vintage Champagne)      ,    ,           .\\\\n\\\\n ,     (Pinot noir)    /       .\\\\n\\\\n\\\\n\\\\n,      ,           ! \\\\n\\\\n |  | \\\\n | \\\\n\\\\n | [...]     ,    ,         . ,    (Pinot noir)    /       .,      ,           !  [...]     ,    ,         . ,    (Pinot noir)    /       .,      ,           ! \"}]' name='tavily_search_results_json' tool_call_id='call_BHh7S21cYQsL9937qWVjxi26' artifact={'query': '   ', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://alcohol.hobby-tech.com/entry/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%B0%B0%EB%96%A1%EA%B6%81%ED%95%A9-%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%97%90-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%99%80%EC%9D%B8-5%EA%B0%80%EC%A7%80', 'title': ' !    5 -   ', 'content': ' ;  ;  .  :    ;   (Chteau Margaux).    ', 'score': 0.91901255, 'raw_content': None}, {'url': 'https://m.blog.naver.com/wineislikeacat/223096696241', 'title': '    !     ...', 'content': ' ,     ?  ,  !\\n\\n     .\\n       .\\n       ,\\n     .\\n\\u200b\\n        ,\\n        \\n        .\\n\\u200b\\n  \\n (Carbernet Sauvignon), (Syrah)  !\\n\\u200b\\n\\n   \\n\\n    ? ! [...]      !\\n, !\\n\\u200b\\n     ?\\n        .\\n        :)\\n\\u200b\\n      \\n    .\\n\\u200b\\n? ?  ?    ! - 1,  :)          ... blog.naver.com\\n ? ?  ?    ! - 2,  :)      4  . ... blog.naver.com\\n\\u200b\\n\\n &     [...]         \\n           .\\n            .\\n\\u200b\\n           \\n (Sangiovege)   .\\n\\u200b\\n\\n  \\n\\n   ? ,  !\\n\\n   \\n      .\\n      .\\n\\u200b\\n      \\n    ,\\n      .\\n\\u200b\\n        \\n    (Malbec)   !\\n\\u200b', 'score': 0.8958969, 'raw_content': None}, {'url': 'https://mashija.com/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%B5%9C%EA%B3%A0%EC%9D%98-%EC%99%80%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%A0%EB%A5%BC-%EA%B2%83%EC%9D%B8/', 'title': '   :   ? -  ', 'content': 'Bora Kim 2022 1 27\\n (Cabernet Sauvignon)  (Malbec)       ,       ,           . [...] <     5  >\\n  (Cabernet Sauvignon)\\n (Malbec)\\n / (Grenache / Shiraz blends)\\n /(Syrah / Shiraz)\\n (Sangiovese)\\n              .\\n        ,             .\\n<   >\\n              ,        . [...]      .      . 2020    .\\n    2007                (Syrah)   (Cte-Rtie)  (Super Tuscan)  . .\\n            .\\n   \\n         . (barnaise)         .    . .\\n<  >\\n   ,            ?', 'score': 0.8923472, 'raw_content': None}, {'url': 'https://stibee.com/api/v1.0/emails/share/vf0yvmd1Z2AYBb3sKfktNyCXRMV2lAI=', 'title': '    !?', 'content': '     (Vintage Champagne)      ,    ,           .\\n\\n ,     (Pinot noir)    /       .\\n\\n\\n\\n,      ,           ! \\n\\n |  | \\n | \\n\\n | [...]     ,    ,         . ,    (Pinot noir)    /       .,      ,           !  [...]     ,    ,         . ,    (Pinot noir)    /       .,      ,           ! ', 'score': 0.85097736, 'raw_content': None}], 'response_time': 0.32}\n"
     ]
    }
   ],
   "source": [
    "#    Toolcall message  \n",
    "\n",
    "tool_message = web_search.invoke(tool_call)\n",
    "print(tool_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolMessage(content='[{\"url\": \"https://alcohol.hobby-tech.com/entry/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%B0%B0%EB%96%A1%EA%B6%81%ED%95%A9-%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%97%90-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%99%80%EC%9D%B8-5%EA%B0%80%EC%A7%80\", \"content\": \" ;  ;  .  :    ;   (Chteau Margaux).    \"}, {\"url\": \"https://m.blog.naver.com/wineislikeacat/223096696241\", \"content\": \" ,     ?  ,  !\\\\n\\\\n     .\\\\n       .\\\\n       ,\\\\n     .\\\\n\\u200b\\\\n        ,\\\\n        \\\\n        .\\\\n\\u200b\\\\n  \\\\n (Carbernet Sauvignon), (Syrah)  !\\\\n\\u200b\\\\n\\\\n   \\\\n\\\\n    ? ! [...]      !\\\\n, !\\\\n\\u200b\\\\n     ?\\\\n        .\\\\n        :)\\\\n\\u200b\\\\n      \\\\n    .\\\\n\\u200b\\\\n? ?  ?    ! - 1,  :)          ... blog.naver.com\\\\n ? ?  ?    ! - 2,  :)      4  . ... blog.naver.com\\\\n\\u200b\\\\n\\\\n &     [...]         \\\\n           .\\\\n            .\\\\n\\u200b\\\\n           \\\\n (Sangiovege)   .\\\\n\\u200b\\\\n\\\\n  \\\\n\\\\n   ? ,  !\\\\n\\\\n   \\\\n      .\\\\n      .\\\\n\\u200b\\\\n      \\\\n    ,\\\\n      .\\\\n\\u200b\\\\n        \\\\n    (Malbec)   !\\\\n\\u200b\"}, {\"url\": \"https://mashija.com/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%B5%9C%EA%B3%A0%EC%9D%98-%EC%99%80%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%A0%EB%A5%BC-%EA%B2%83%EC%9D%B8/\", \"content\": \"Bora Kim 2022 1 27\\\\n (Cabernet Sauvignon)  (Malbec)       ,       ,           . [...] <     5  >\\\\n  (Cabernet Sauvignon)\\\\n (Malbec)\\\\n / (Grenache / Shiraz blends)\\\\n /(Syrah / Shiraz)\\\\n (Sangiovese)\\\\n              .\\\\n        ,             .\\\\n<   >\\\\n              ,        . [...]      .      . 2020    .\\\\n    2007                (Syrah)   (Cte-Rtie)  (Super Tuscan)  . .\\\\n            .\\\\n   \\\\n         . (barnaise)         .    . .\\\\n<  >\\\\n   ,            ?\"}, {\"url\": \"https://stibee.com/api/v1.0/emails/share/vf0yvmd1Z2AYBb3sKfktNyCXRMV2lAI=\", \"content\": \"     (Vintage Champagne)      ,    ,           .\\\\n\\\\n ,     (Pinot noir)    /       .\\\\n\\\\n\\\\n\\\\n,      ,           ! \\\\n\\\\n |  | \\\\n | \\\\n\\\\n | [...]     ,    ,         . ,    (Pinot noir)    /       .,      ,           !  [...]     ,    ,         . ,    (Pinot noir)    /       .,      ,           ! \"}]', name='tavily_search_results_json', tool_call_id='call_BHh7S21cYQsL9937qWVjxi26', artifact={'query': '   ', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://alcohol.hobby-tech.com/entry/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%B0%B0%EB%96%A1%EA%B6%81%ED%95%A9-%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%97%90-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%99%80%EC%9D%B8-5%EA%B0%80%EC%A7%80', 'title': ' !    5 -   ', 'content': ' ;  ;  .  :    ;   (Chteau Margaux).    ', 'score': 0.91901255, 'raw_content': None}, {'url': 'https://m.blog.naver.com/wineislikeacat/223096696241', 'title': '    !     ...', 'content': ' ,     ?  ,  !\\n\\n     .\\n       .\\n       ,\\n     .\\n\\u200b\\n        ,\\n        \\n        .\\n\\u200b\\n  \\n (Carbernet Sauvignon), (Syrah)  !\\n\\u200b\\n\\n   \\n\\n    ? ! [...]      !\\n, !\\n\\u200b\\n     ?\\n        .\\n        :)\\n\\u200b\\n      \\n    .\\n\\u200b\\n? ?  ?    ! - 1,  :)          ... blog.naver.com\\n ? ?  ?    ! - 2,  :)      4  . ... blog.naver.com\\n\\u200b\\n\\n &     [...]         \\n           .\\n            .\\n\\u200b\\n           \\n (Sangiovege)   .\\n\\u200b\\n\\n  \\n\\n   ? ,  !\\n\\n   \\n      .\\n      .\\n\\u200b\\n      \\n    ,\\n      .\\n\\u200b\\n        \\n    (Malbec)   !\\n\\u200b', 'score': 0.8958969, 'raw_content': None}, {'url': 'https://mashija.com/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%B5%9C%EA%B3%A0%EC%9D%98-%EC%99%80%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%A0%EB%A5%BC-%EA%B2%83%EC%9D%B8/', 'title': '   :   ? -  ', 'content': 'Bora Kim 2022 1 27\\n (Cabernet Sauvignon)  (Malbec)       ,       ,           . [...] <     5  >\\n  (Cabernet Sauvignon)\\n (Malbec)\\n / (Grenache / Shiraz blends)\\n /(Syrah / Shiraz)\\n (Sangiovese)\\n              .\\n        ,             .\\n<   >\\n              ,        . [...]      .      . 2020    .\\n    2007                (Syrah)   (Cte-Rtie)  (Super Tuscan)  . .\\n            .\\n   \\n         . (barnaise)         .    . .\\n<  >\\n   ,            ?', 'score': 0.8923472, 'raw_content': None}, {'url': 'https://stibee.com/api/v1.0/emails/share/vf0yvmd1Z2AYBb3sKfktNyCXRMV2lAI=', 'title': '    !?', 'content': '     (Vintage Champagne)      ,    ,           .\\n\\n ,     (Pinot noir)    /       .\\n\\n\\n\\n,      ,           ! \\n\\n |  | \\n | \\n\\n | [...]     ,    ,         . ,    (Pinot noir)    /       .,      ,           !  [...]     ,    ,         . ,    (Pinot noir)    /       .,      ,           ! ', 'score': 0.85097736, 'raw_content': None}], 'response_time': 0.32})\n"
     ]
    }
   ],
   "source": [
    "pprint(tool_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'tavily_search_results_json'\n"
     ]
    }
   ],
   "source": [
    "pprint(tool_message.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ToolMessage(content='[{\"url\": \"https://alcohol.hobby-tech.com/entry/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%B0%B0%EB%96%A1%EA%B6%81%ED%95%A9-%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%97%90-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%99%80%EC%9D%B8-5%EA%B0%80%EC%A7%80\", \"content\": \" ;  ;  .  :    ;   (Chteau Margaux).    \"}, {\"url\": \"https://m.blog.naver.com/wineislikeacat/223096696241\", \"content\": \" ,     ?  ,  !\\\\n\\\\n     .\\\\n       .\\\\n       ,\\\\n     .\\\\n\\u200b\\\\n        ,\\\\n        \\\\n        .\\\\n\\u200b\\\\n  \\\\n (Carbernet Sauvignon), (Syrah)  !\\\\n\\u200b\\\\n\\\\n   \\\\n\\\\n    ? ! [...]      !\\\\n, !\\\\n\\u200b\\\\n     ?\\\\n        .\\\\n        :)\\\\n\\u200b\\\\n      \\\\n    .\\\\n\\u200b\\\\n? ?  ?    ! - 1,  :)          ... blog.naver.com\\\\n ? ?  ?    ! - 2,  :)      4  . ... blog.naver.com\\\\n\\u200b\\\\n\\\\n &     [...]         \\\\n           .\\\\n            .\\\\n\\u200b\\\\n           \\\\n (Sangiovege)   .\\\\n\\u200b\\\\n\\\\n  \\\\n\\\\n   ? ,  !\\\\n\\\\n   \\\\n      .\\\\n      .\\\\n\\u200b\\\\n      \\\\n    ,\\\\n      .\\\\n\\u200b\\\\n        \\\\n    (Malbec)   !\\\\n\\u200b\"}, {\"url\": \"https://mashija.com/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%B5%9C%EA%B3%A0%EC%9D%98-%EC%99%80%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%A0%EB%A5%BC-%EA%B2%83%EC%9D%B8/\", \"content\": \"Bora Kim 2022 1 27\\\\n (Cabernet Sauvignon)  (Malbec)       ,       ,           . [...] <     5  >\\\\n  (Cabernet Sauvignon)\\\\n (Malbec)\\\\n / (Grenache / Shiraz blends)\\\\n /(Syrah / Shiraz)\\\\n (Sangiovese)\\\\n              .\\\\n        ,             .\\\\n<   >\\\\n              ,        . [...]      .      . 2020    .\\\\n    2007                (Syrah)   (Cte-Rtie)  (Super Tuscan)  . .\\\\n            .\\\\n   \\\\n         . (barnaise)         .    . .\\\\n<  >\\\\n   ,            ?\"}, {\"url\": \"https://stibee.com/api/v1.0/emails/share/vf0yvmd1Z2AYBb3sKfktNyCXRMV2lAI=\", \"content\": \"     (Vintage Champagne)      ,    ,           .\\\\n\\\\n ,     (Pinot noir)    /       .\\\\n\\\\n\\\\n\\\\n,      ,           ! \\\\n\\\\n |  | \\\\n | \\\\n\\\\n | [...]     ,    ,         . ,    (Pinot noir)    /       .,      ,           !  [...]     ,    ,         . ,    (Pinot noir)    /       .,      ,           ! \"}]', name='tavily_search_results_json', tool_call_id='call_BHh7S21cYQsL9937qWVjxi26', artifact={'query': '   ', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://alcohol.hobby-tech.com/entry/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%B0%B0%EB%96%A1%EA%B6%81%ED%95%A9-%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%97%90-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%99%80%EC%9D%B8-5%EA%B0%80%EC%A7%80', 'title': ' !    5 -   ', 'content': ' ;  ;  .  :    ;   (Chteau Margaux).    ', 'score': 0.91901255, 'raw_content': None}, {'url': 'https://m.blog.naver.com/wineislikeacat/223096696241', 'title': '    !     ...', 'content': ' ,     ?  ,  !\\n\\n     .\\n       .\\n       ,\\n     .\\n\\u200b\\n        ,\\n        \\n        .\\n\\u200b\\n  \\n (Carbernet Sauvignon), (Syrah)  !\\n\\u200b\\n\\n   \\n\\n    ? ! [...]      !\\n, !\\n\\u200b\\n     ?\\n        .\\n        :)\\n\\u200b\\n      \\n    .\\n\\u200b\\n? ?  ?    ! - 1,  :)          ... blog.naver.com\\n ? ?  ?    ! - 2,  :)      4  . ... blog.naver.com\\n\\u200b\\n\\n &     [...]         \\n           .\\n            .\\n\\u200b\\n           \\n (Sangiovege)   .\\n\\u200b\\n\\n  \\n\\n   ? ,  !\\n\\n   \\n      .\\n      .\\n\\u200b\\n      \\n    ,\\n      .\\n\\u200b\\n        \\n    (Malbec)   !\\n\\u200b', 'score': 0.8958969, 'raw_content': None}, {'url': 'https://mashija.com/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%B5%9C%EA%B3%A0%EC%9D%98-%EC%99%80%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%A0%EB%A5%BC-%EA%B2%83%EC%9D%B8/', 'title': '   :   ? -  ', 'content': 'Bora Kim 2022 1 27\\n (Cabernet Sauvignon)  (Malbec)       ,       ,           . [...] <     5  >\\n  (Cabernet Sauvignon)\\n (Malbec)\\n / (Grenache / Shiraz blends)\\n /(Syrah / Shiraz)\\n (Sangiovese)\\n              .\\n        ,             .\\n<   >\\n              ,        . [...]      .      . 2020    .\\n    2007                (Syrah)   (Cte-Rtie)  (Super Tuscan)  . .\\n            .\\n   \\n         . (barnaise)         .    . .\\n<  >\\n   ,            ?', 'score': 0.8923472, 'raw_content': None}, {'url': 'https://stibee.com/api/v1.0/emails/share/vf0yvmd1Z2AYBb3sKfktNyCXRMV2lAI=', 'title': '    !?', 'content': '     (Vintage Champagne)      ,    ,           .\\n\\n ,     (Pinot noir)    /       .\\n\\n\\n\\n,      ,           ! \\n\\n |  | \\n | \\n\\n | [...]     ,    ,         . ,    (Pinot noir)    /       .,      ,           !  [...]     ,    ,         . ,    (Pinot noir)    /       .,      ,           ! ', 'score': 0.85097736, 'raw_content': None}], 'response_time': 0.68})]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('[{\"url\": '\n",
      " '\"https://alcohol.hobby-tech.com/entry/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%B0%B0%EB%96%A1%EA%B6%81%ED%95%A9-%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%97%90-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%99%80%EC%9D%B8-5%EA%B0%80%EC%A7%80\", '\n",
      " '\"content\": \" ;  ;  .  :    ;   '\n",
      " '(Chteau Margaux).    \"}, {\"url\": '\n",
      " '\"https://m.blog.naver.com/wineislikeacat/223096696241\", \"content\": \" , '\n",
      " '    ?  ,  !\\\\n\\\\n     .\\\\n '\n",
      " '      .\\\\n       ,\\\\n '\n",
      " '    .\\\\n\\u200b\\\\n        '\n",
      " ',\\\\n        \\\\n        '\n",
      " '.\\\\n\\u200b\\\\n  \\\\n (Carbernet Sauvignon), (Syrah) '\n",
      " ' !\\\\n\\u200b\\\\n\\\\n   \\\\n\\\\n    ? ! '\n",
      " '[...]      !\\\\n, !\\\\n\\u200b\\\\n  '\n",
      " '   ?\\\\n        .\\\\n     '\n",
      " '   :)\\\\n\\u200b\\\\n      \\\\n    '\n",
      " '.\\\\n\\u200b\\\\n? ?  ?    ! - 1,  :) '\n",
      " '         ... blog.naver.com\\\\n ? ?  ? '\n",
      " '   ! - 2,  :)      4  . '\n",
      " '... blog.naver.com\\\\n\\u200b\\\\n\\\\n &     [...]     '\n",
      " '    \\\\n           .\\\\n  '\n",
      " '          .\\\\n\\u200b\\\\n        '\n",
      " '   \\\\n (Sangiovege)   .\\\\n\\u200b\\\\n\\\\n '\n",
      " ' \\\\n\\\\n   ? ,  !\\\\n\\\\n   \\\\n '\n",
      " '     .\\\\n      .\\\\n\\u200b\\\\n  '\n",
      " '    \\\\n    ,\\\\n      '\n",
      " '.\\\\n\\u200b\\\\n        \\\\n    '\n",
      " '(Malbec)   !\\\\n\\u200b\"}, {\"url\": '\n",
      " '\"https://mashija.com/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%B5%9C%EA%B3%A0%EC%9D%98-%EC%99%80%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%A0%EB%A5%BC-%EA%B2%83%EC%9D%B8/\", '\n",
      " '\"content\": \"Bora Kim 2022 1 27\\\\n (Cabernet Sauvignon)  '\n",
      " '(Malbec)       ,       ,  '\n",
      " '         . [...] <     5 '\n",
      " ' >\\\\n  (Cabernet Sauvignon)\\\\n (Malbec)\\\\n / '\n",
      " '(Grenache / Shiraz blends)\\\\n /(Syrah / Shiraz)\\\\n '\n",
      " '(Sangiovese)\\\\n              '\n",
      " '.\\\\n        ,          '\n",
      " '   .\\\\n<   >\\\\n         '\n",
      " '     ,        . [...]     '\n",
      " ' .      . 2020    .\\\\n  '\n",
      " '  2007                '\n",
      " '(Syrah)   (Cte-Rtie)  (Super Tuscan)  . '\n",
      " '.\\\\n            .\\\\n   \\\\n '\n",
      " '        . (barnaise)       '\n",
      " '  .    . .\\\\n<  >\\\\n   ,  '\n",
      " '          ?\"}, {\"url\": '\n",
      " '\"https://stibee.com/api/v1.0/emails/share/vf0yvmd1Z2AYBb3sKfktNyCXRMV2lAI=\", '\n",
      " '\"content\": \"     (Vintage Champagne)      '\n",
      " ',    ,           .\\\\n\\\\n '\n",
      " ',     (Pinot noir)    /       '\n",
      " '.\\\\n\\\\n\\\\n\\\\n,      ,          '\n",
      " ' ! \\\\n\\\\n |  | \\\\n | \\\\n\\\\n | [...]     ,   '\n",
      " ' ,         . ,    '\n",
      " '(Pinot noir)    /       .,    '\n",
      " '  ,           !  [...]    '\n",
      " ' ,    ,         . '\n",
      " ',    (Pinot noir)    /       '\n",
      " '.,      ,           ! '\n",
      " '\"}]')\n"
     ]
    }
   ],
   "source": [
    "#   \n",
    "tool_messages = web_search.batch(ai_msg.tool_calls)\n",
    "print(tool_messages)\n",
    "print(\"-\"*100)\n",
    "pprint(tool_messages[0].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_BHh7S21cYQsL9937qWVjxi26', 'function': {'arguments': '{\"query\":\"   \"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 91, 'total_tokens': 119, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6d280e8b-aa8b-45be-bf91-18e320e18c26-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': '   '}, 'id': 'call_BHh7S21cYQsL9937qWVjxi26', 'type': 'tool_call'}], usage_metadata={'input_tokens': 91, 'output_tokens': 28, 'total_tokens': 119})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai_msg: \n",
      " content='' additional_kwargs={'tool_calls': [{'id': 'call_XRiKWawLoO2DbxXzb6ZbOVhK', 'function': {'arguments': '{\"query\":\"    2025 4\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 114, 'total_tokens': 150, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-5e40f9e2-964f-4c39-bd17-ec3030155ded-0' tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': '    2025 4'}, 'id': 'call_XRiKWawLoO2DbxXzb6ZbOVhK', 'type': 'tool_call'}] usage_metadata={'input_tokens': 114, 'output_tokens': 36, 'total_tokens': 150}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tool_msgs: \n",
      " [ToolMessage(content='[{\"url\": \"https://department.ssg.com/search.ssg?query=%EB%AA%A8%EC%97%A3%EC%83%B9%EB%8F%99\", \"content\": \"    Moet Chandon Imperial Champagne Flute Glasses Flutes 0.2 L S. 135,400. 129,980. 4%. .\"}, {\"url\": \"https://www.wine21.com/13_search/wine_view.html?Idx=149862\", \"content\": \"(France)  (Champagne).   (750ml) 3.3. QR code ...   . Moet & Chandon Imperial. ,  (). NV. 75,000 \"}, {\"url\": \"https://www.instagram.com/andazseoulgangnam/p/DFxAqQVCCi9/?api=%E8%B4%B9%E5%9F%8E%E6%80%8E%E4%B9%88%E6%89%BE%E5%B0%8F%E5%A7%90%E6%9C%8D%E5%8A%A1v%E4%BF%A18764603%E2%96%B7%E8%B4%B9%E5%9F%8E%E6%80%8E%E4%B9%88%E6%89%BE%E5%B0%8F%E5%A7%90%E5%85%A8%E5%A5%97%E7%89%B9%E6%AE%8A%E6%9C%8D%E5%8A%A1%E2%96%B7%E8%B4%B9%E5%9F%8E%E6%80%8E%E4%B9%88%E6%89%BE%E5%B0%8F%E5%A7%90%E4%B8%8A%E9%97%A8%E6%9C%8D%E5%8A%A1%E2%96%B7%E8%B4%B9%E5%9F%8E%E6%80%8E%E4%B9%88%E6%89%BE%E5%B0%8F%E5%A7%90%E8%81%94%E7%B3%BB%E6%96%B9%E5%BC%8F%E2%96%B7%E8%B4%B9%E5%9F%8E%E6%80%8E%E4%B9%88%E6%89%BE%E5%B0%8F%E5%A7%90%E4%B8%8A%E8%AF%BE%E7%BA%A6%E6%9C%8D%E5%8A%A1.vabf&hl=ne\", \"content\": \"     10  .   |   5:30 PM  11:30 PM  | 2     | \"}, {\"url\": \"https://dailyshot.co/m/item/4216?item=7875\", \"content\": \"       .            30~40%,    \"}]', name='tavily_search_results_json', tool_call_id='call_XRiKWawLoO2DbxXzb6ZbOVhK', artifact={'query': '    2025 4', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://department.ssg.com/search.ssg?query=%EB%AA%A8%EC%97%A3%EC%83%B9%EB%8F%99', 'title': ' -  ,  - SSG.com', 'content': '    Moet Chandon Imperial Champagne Flute Glasses Flutes 0.2 L S. 135,400. 129,980. 4%. .', 'score': 0.60077465, 'raw_content': None}, {'url': 'https://www.wine21.com/13_search/wine_view.html?Idx=149862', 'title': '[]    -  21', 'content': '(France)  (Champagne).   (750ml) 3.3. QR code ...   . Moet & Chandon Imperial. ,  (). NV. 75,000 ', 'score': 0.5565207, 'raw_content': None}, {'url': 'https://www.instagram.com/andazseoulgangnam/p/DFxAqQVCCi9/?api=%E8%B4%B9%E5%9F%8E%E6%80%8E%E4%B9%88%E6%89%BE%E5%B0%8F%E5%A7%90%E6%9C%8D%E5%8A%A1v%E4%BF%A18764603%E2%96%B7%E8%B4%B9%E5%9F%8E%E6%80%8E%E4%B9%88%E6%89%BE%E5%B0%8F%E5%A7%90%E5%85%A8%E5%A5%97%E7%89%B9%E6%AE%8A%E6%9C%8D%E5%8A%A1%E2%96%B7%E8%B4%B9%E5%9F%8E%E6%80%8E%E4%B9%88%E6%89%BE%E5%B0%8F%E5%A7%90%E4%B8%8A%E9%97%A8%E6%9C%8D%E5%8A%A1%E2%96%B7%E8%B4%B9%E5%9F%8E%E6%80%8E%E4%B9%88%E6%89%BE%E5%B0%8F%E5%A7%90%E8%81%94%E7%B3%BB%E6%96%B9%E5%BC%8F%E2%96%B7%E8%B4%B9%E5%9F%8E%E6%80%8E%E4%B9%88%E6%89%BE%E5%B0%8F%E5%A7%90%E4%B8%8A%E8%AF%BE%E7%BA%A6%E6%9C%8D%E5%8A%A1.vabf&hl=ne', 'title': ' #Andazstasty - andazseoulgangnam - Instagram', 'content': '     10  .   |   5:30 PM  11:30 PM  | 2     | ', 'score': 0.3753177, 'raw_content': None}, {'url': 'https://dailyshot.co/m/item/4216?item=7875', 'title': '      |    ...', 'content': '       .            30~40%,    ', 'score': 0.23398674, 'raw_content': None}], 'response_time': 3.24})]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('      :\\n'\n",
      " '\\n'\n",
      " '1. **   (750ml)** -  75,000 \\n'\n",
      " '2. **   ** -   135,400   129,980\\n'\n",
      " '\\n'\n",
      " '  [](https://www.wine21.com/13_search/wine_view.html?Idx=149862) '\n",
      " '  .')\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "#  \n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", f\"you are a helpful AI assistant. Today's date is {today}\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\")\n",
    "])\n",
    "\n",
    "llm_chain = prompt | llm_with_tools\n",
    "\n",
    "@chain\n",
    "def web_search_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "    print(\"ai_msg: \\n\", ai_msg)\n",
    "    print(\"-\"*100)\n",
    "    tool_msgs = web_search.batch(ai_msg.tool_calls, config=config)\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "    return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "response = web_search_chain.invoke(\"    ?\")\n",
    "\n",
    "pprint(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from typing import List\n",
    "\n",
    "@tool\n",
    "def search_web(query: str) -> List[str]:\n",
    "    \"\"\"Searchs the Internet for Information that does not exist in the datavase or for the latest information\"\"\"\n",
    "    tavily_search = TavilySearchResults(max_results=4)\n",
    "    docs = tavily_search.invoke(query)\n",
    "\n",
    "    formatted_docs = \"\\n---\\n\".join([\n",
    "        f'<Document hreg=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "        for doc in docs\n",
    "        ])\n",
    "    if len(formatted_docs) > 0:\n",
    "        return formatted_docs\n",
    "    return \"  .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": \n",
      "<class 'langchain_core.tools.structured.StructuredTool'>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "name: \n",
      "search_web\n",
      "----------------------------------------------------------------------------------------------------\n",
      "description: \n",
      "Searchs the Internet for Information that does not exist in the datavase or for the latest information\n",
      "----------------------------------------------------------------------------------------------------\n",
      "schema: \n",
      "{'description': 'Searchs the Internet for Information that does not exist in the datavase or for the latest information', 'properties': {'query': {'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'search_web', 'type': 'object'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#  \n",
    "print(\": \")\n",
    "print(type(search_web))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(search_web.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "print(search_web.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "print(search_web.args_schema.schema())\n",
    "print(\"-\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Document hreg=\"https://m.blog.naver.com/wineislikeacat/223096696241\"/>\n",
      " ,     ?  ,  !\n",
      "\n",
      "     .\n",
      "       .\n",
      "       ,\n",
      "     .\n",
      "\n",
      "        ,\n",
      "        \n",
      "        .\n",
      "\n",
      "  \n",
      " (Carbernet Sauvignon), (Syrah)  !\n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "    ? ! [...]      !\n",
      ", !\n",
      "\n",
      "     ?\n",
      "        .\n",
      "        :)\n",
      "\n",
      "      \n",
      "    .\n",
      "\n",
      "? ?  ?    ! - 1,  :)          ... blog.naver.com\n",
      " ? ?  ?    ! - 2,  :)      4  . ... blog.naver.com\n",
      "\n",
      "\n",
      " &     [...]         \n",
      "           .\n",
      "            .\n",
      "\n",
      "           \n",
      " (Sangiovege)   .\n",
      "\n",
      "\n",
      "  \n",
      "\n",
      "   ? ,  !\n",
      "\n",
      "   \n",
      "      .\n",
      "      .\n",
      "\n",
      "      \n",
      "    ,\n",
      "      .\n",
      "\n",
      "        \n",
      "    (Malbec)   !\n",
      "\n",
      "</Document>\n",
      "---\n",
      "<Document hreg=\"https://mashija.com/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%B5%9C%EA%B3%A0%EC%9D%98-%EC%99%80%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%A0%EB%A5%BC-%EA%B2%83%EC%9D%B8/\"/>\n",
      "Bora Kim 2022 1 27\n",
      " (Cabernet Sauvignon)  (Malbec)       ,       ,           . [...] <     5  >\n",
      "  (Cabernet Sauvignon)\n",
      " (Malbec)\n",
      " / (Grenache / Shiraz blends)\n",
      " /(Syrah / Shiraz)\n",
      " (Sangiovese)\n",
      "              .\n",
      "        ,             .\n",
      "<   >\n",
      "              ,        . [...]    (Karen MacNeil)     10  (grilled)          .\n",
      "       \n",
      "2018    (Peter Richards MW)              . .\n",
      "    (Cabernet Franc) ?  (Carignan), (Cinsault)     (Syrah) ? DWWA    Decanter Retailer Awards     (ros)    . .\n",
      "</Document>\n",
      "---\n",
      "<Document hreg=\"http://mustnews.co.kr/View.aspx?No=1526378\"/>\n",
      " 40       ,          ,   .\n",
      "\n",
      ">>    2016\n",
      "\n",
      " :  U.S.A  \n",
      "\n",
      " SIP         .\n",
      "\n",
      "         ,                    .\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                     \n",
      "                                    wzerow@mustnews.co.kr\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "  [...]  \n",
      "\n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      "\n",
      ">>  ,   \n",
      "\n",
      " :  U.S.A \n",
      "\n",
      ", ,                .\n",
      "\n",
      "      .     7                     .\n",
      "\n",
      ">>  ,     2016\n",
      "\n",
      " :  \n",
      "\n",
      "  , ,    ,       . [...]   5110,1 107-222 |  : 070-8840-5040 |  : 0504-222-7103\n",
      " :  |  : 504  |  :  :   52094 |  : 2019-01-20 |  : 2019-02-07 |  : \n",
      " :  |   (,, )   ,   ,   .\n",
      "Copyright  2024. All rights reserved. mail to wzerow@mustnews.co.kr\n",
      "</Document>\n",
      "---\n",
      "<Document hreg=\"https://blog.naver.com/chelina89/220634349414?viewType=pc\"/>\n",
      "1.  - 6 .            .  2.   - 3\n",
      "</Document>\n"
     ]
    }
   ],
   "source": [
    "query = \"   .\"\n",
    "search_results = search_web.invoke(query)\n",
    "\n",
    "print(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_1elQFpZMQ0QV7D7vvnLaoZR0', 'function': {'arguments': '{\"query\":\"   \"}', 'name': 'search_web'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 69, 'total_tokens': 93, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-94f20897-23a4-4728-97b9-e04c8d727270-0', tool_calls=[{'name': 'search_web', 'args': {'query': '   '}, 'id': 'call_1elQFpZMQ0QV7D7vvnLaoZR0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 69, 'output_tokens': 24, 'total_tokens': 93})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "''\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[{'args': {'query': '   '},\n",
      "  'id': 'call_1elQFpZMQ0QV7D7vvnLaoZR0',\n",
      "  'name': 'search_web',\n",
      "  'type': 'tool_call'}]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "llm_with_tools = llm.bind_tools(tools = [search_web])\n",
    "\n",
    "query = \"   .\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "pprint(ai_msg)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\"*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Key 'title' is not supported in schema, ignoring\n",
      "Key 'title' is not supported in schema, ignoring\n",
      "Key 'title' is not supported in schema, ignoring\n",
      "Key 'title' is not supported in schema, ignoring\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm_gemini_flash = ChatGoogleGenerativeAI(model = \"gemini-1.5-flash\", temperature = 0)\n",
    "llm_gemini_pro = ChatGoogleGenerativeAI(model = \"gemini-1.5-pro\", temperature = 0)\n",
    "llm_groq = ChatGroq(model = \"llama3-70b-8192\", temperature = 0)\n",
    "\n",
    "tools = [search_web]\n",
    "\n",
    "gemini_flash_with_tools = llm_gemini_flash.bind_tools(tools)\n",
    "gemini_pro_with_tools = llm_gemini_pro.bind_tools(tools)\n",
    "groq_with_tools = llm_groq.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gemini 1.5 flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='        .       ,         .\\n\\n       .\\n\\n* ** :**           .  \\n    * **  (Cabernet Sauvignon):**  ,   , ,     ,      .\\n    * ** (Malbec):**     ,   ,       .\\n    * ** (Merlot):**     ,   ,     .\\n    * **/ (Shiraz/Syrah):**       ,      .\\n\\n\\n* ** :**          .  \\n    * ** (Chardonnay):**         ,       .\\n\\n\\n  ,   ( ,   )      .\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-51d7c391-e95e-402a-9219-08d6c20b1d29-0', usage_metadata={'input_tokens': 61, 'output_tokens': 504, 'total_tokens': 565})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('        .       ,  '\n",
      " '       .\\n'\n",
      " '\\n'\n",
      " '       .\\n'\n",
      " '\\n'\n",
      " '* ** :**           .  \\n'\n",
      " '    * **  (Cabernet Sauvignon):**  ,   , ,   '\n",
      " '  ,      .\\n'\n",
      " '    * ** (Malbec):**     ,   ,       '\n",
      " '.\\n'\n",
      " '    * ** (Merlot):**     ,   ,     .\\n'\n",
      " '    * **/ (Shiraz/Syrah):**       ,      '\n",
      " '.\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '* ** :**          .  \\n'\n",
      " '    * ** (Chardonnay):**         ,     '\n",
      " '  .\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '  ,   ( ,   )      .\\n')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#    LLM  \n",
    "\n",
    "query = \"   .\"\n",
    "ai_msg = gemini_flash_with_tools.invoke(query)\n",
    "\n",
    "pprint(ai_msg)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gemini 1.5 Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='     .  ,  ,         .\\n\\n* **  (Cabernet Sauvignon):** ,    , ,       .            .\\n* ** (Merlot):**         .       .\\n* **  (Pinot Noir):**        , ,       .\\n* ** (Zinfandel):**        . ,        .\\n* **/ (Syrah/Shiraz):** ,     , ,        .\\n\\n        .         ,         ,        .\\n\\n         .\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-8246e3b6-62b7-423b-b4af-2329cd5dcc2f-0', usage_metadata={'input_tokens': 61, 'output_tokens': 516, 'total_tokens': 577})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('     .  ,  ,         '\n",
      " '.\\n'\n",
      " '\\n'\n",
      " '* **  (Cabernet Sauvignon):** ,    , ,     '\n",
      " '  .            .\\n'\n",
      " '* ** (Merlot):**         .    '\n",
      " '   .\\n'\n",
      " '* **  (Pinot Noir):**        , ,     '\n",
      " '  .\\n'\n",
      " '* ** (Zinfandel):**        . ,     '\n",
      " '   .\\n'\n",
      " '* **/ (Syrah/Shiraz):** ,     , ,     '\n",
      " '   .\\n'\n",
      " '\\n'\n",
      " '        .         , '\n",
      " '        ,        .\\n'\n",
      " '\\n'\n",
      " '         .\\n')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"   .\"\n",
    "ai_msg = gemini_pro_with_tools.invoke(query)\n",
    "\n",
    "pprint(ai_msg)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## llama3-70b-8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_1hhv', 'function': {'arguments': '{\"query\":\"wine pairing for steak\"}', 'name': 'search_web'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 925, 'total_tokens': 971, 'completion_time': 0.162430073, 'prompt_time': 0.030296883, 'queue_time': 0.24261601500000002, 'total_time': 0.192726956}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_dd4ae1c591', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-1e0cb764-aea4-4c80-8058-3c5b6648df84-0', tool_calls=[{'name': 'search_web', 'args': {'query': 'wine pairing for steak'}, 'id': 'call_1hhv', 'type': 'tool_call'}], usage_metadata={'input_tokens': 925, 'output_tokens': 46, 'total_tokens': 971})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "''\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[{'args': {'query': 'wine pairing for steak'},\n",
      "  'id': 'call_1hhv',\n",
      "  'name': 'search_web',\n",
      "  'type': 'tool_call'}]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"   .\"\n",
    "ai_msg = groq_with_tools.invoke(query)\n",
    "\n",
    "pprint(ai_msg)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jz/fp63dzmn3rqdm05pvyy503940000gn/T/ipykernel_5517/2088536305.py:24: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  wiki_search = runnable.as_tool(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "#    \n",
    "def search_wiki(input_data:dict) -> List[Document]:\n",
    "    \"\"\"Search Wikepedia documents based on user input(query) and return k documents\"\"\"\n",
    "    qeury = input_data[\"query\"]\n",
    "    k = input_data.get(\"k\", 2)\n",
    "    wiki_loader = WikipediaLoader(query = query, load_max_docs=k, lang = \"ko\")\n",
    "    wiki_docs = wiki_loader.load()\n",
    "    return wiki_docs\n",
    "\n",
    "#      \n",
    "class WikiSearchSchema(BaseModel):\n",
    "    \"\"\"Input schema for Wikipedia search.\"\"\"\n",
    "    query: str = Field(..., description=\"The query to search for in Wikipedia\")\n",
    "    k: int = Field(2, description=\"The number of documents to return(default is 2)\")\n",
    "\n",
    "#    Runnabel  \n",
    "runnable = RunnableLambda(search_wiki)\n",
    "wiki_search = runnable.as_tool(\n",
    "    name = \"wiki_search\",\n",
    "    description=dedent(\"\"\"\n",
    "        Use this took when you need to search for information on Wikipedia.\n",
    "        It searches for Wikipedia aericles related to the useful when general knowledge\n",
    "        or background information is required.\"\"\"),\n",
    "    args_schema=WikiSearchSchema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": \n",
      "<class 'langchain_core.tools.structured.StructuredTool'>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "name: \n",
      "wiki_search\n",
      "----------------------------------------------------------------------------------------------------\n",
      "description: \n",
      "('Use this took when you need to search for information on Wikipedia.\\n'\n",
      " 'It searches for Wikipedia aericles related to the useful when general '\n",
      " 'knowledge\\n'\n",
      " 'or background information is required.')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "schema: \n",
      "{'description': 'Input schema for Wikipedia search.',\n",
      " 'properties': {'k': {'default': 2,\n",
      "                      'description': 'The number of documents to '\n",
      "                                     'return(default is 2)',\n",
      "                      'title': 'K',\n",
      "                      'type': 'integer'},\n",
      "                'query': {'description': 'The query to search for in Wikipedia',\n",
      "                          'title': 'Query',\n",
      "                          'type': 'string'}},\n",
      " 'required': ['query'],\n",
      " 'title': 'WikiSearchSchema',\n",
      " 'type': 'object'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#  \n",
    "print(\": \")\n",
    "print(type(wiki_search))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(wiki_search.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(wiki_search.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(wiki_search.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='(: orzo)  (: risoni, : risone [*])  . \"\" :hordeum  \"\" . \"\" \" \" .            .      .        .   kritharki (\"little barley\")  manstra( ) , lisn al-`ufr (\" \")   .      .\n",
      "  (arpa ehriye) ,  .   ()  .\n",
      "\n",
      "\n",
      "==   ==\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==  ==' metadata={'title': '', 'summary': '(: orzo)  (: risoni, : risone [*])  . \"\" :hordeum  \"\" . \"\" \" \" .            .      .        .   kritharki (\"little barley\")  manstra( ) , lisn al-`ufr (\" \")   .      .\\n  (arpa ehriye) ,  .   ()  .', 'source': 'https://ko.wikipedia.org/wiki/%EC%98%A4%EB%A5%B4%EC%A1%B0'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "page_content=' (Italia , : cucina italiana  [*])    .  4      .        , , ,          .   18   .\n",
      "           .                       ,      .\n",
      "      4~8           .                  ,   .\n",
      "2013 CNN      .\n",
      "\n",
      "\n",
      "==  ==\n",
      "  4  .      ,  ,              .\n",
      "\n",
      "\n",
      "===  ===\n",
      "          .  4              .    ,      ,     .            470      (De re coquinaria )       .                 .              (pecorini)    .             .\n",
      "\n",
      "\n",
      "===  ===\n",
      "               .         .\n",
      "\n",
      " 9             .  , ,   ,    12                  .        .       ,  (atriya)   (trii)  . (Trii)         .         ,      .\n",
      "      ,     .        .        ,      ,          ,      .    ,  .\n",
      "\n",
      "              ,            .     13      (Liber de Coquina)    .            (Lavagna pie)          .\n",
      "15        (Libro de Arte Coquinaria, )          .      (Maccaroni Siciliani,  )          .         .         .         (coppiette) .         (Bolognese Torta,  )  (Sienese torta,  )     , , ,       .\n",
      "  1475        (De honesta voluptate et valetudine) .       ,               .\n",
      "\n",
      "\n",
      "===   ===\n",
      "    , ,       .         . 1549     (Christoforo Messisbugo) Banchetti Composizioni di Vivande     .       , 124     .\n",
      "\n",
      "1570   5      (Opera) .                     ,      .            .           .  ,     . 3     .     ,    . 5                .          .   ,      .\n",
      "1600  (Giangiacomo Castelvetro)    , (Brieve Racconto di Tutte le Radici di Tutte l'Herbe et di Tutti i Frutti)  .      .     ,' metadata={'title': ' ', 'summary': ' (Italia , : cucina italiana  [*])    .  4      .        , , ,          .   18   .\\n           .                       ,      .\\n      4~8           .                  ,   .\\n2013 CNN      .\\n\\n', 'source': 'https://ko.wikipedia.org/wiki/%EC%9D%B4%ED%83%88%EB%A6%AC%EC%95%84_%EC%9A%94%EB%A6%AC'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \" \"\n",
    "wiki_result = wiki_search.invoke({\"query\":query})\n",
    "\n",
    "for result in wiki_result:\n",
    "    print(result)\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_f6RTD0NsqFBmgX05yONqXR9F', 'function': {'arguments': '{\"query\": \"    \"}', 'name': 'search_web'}, 'type': 'function'}, {'id': 'call_pnccTmxWhDAGzOXPOAH7Lfvz', 'function': {'arguments': '{}', 'name': 'search_wiki'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 108, 'total_tokens': 159, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-799844e8-3ee3-4748-afb5-8da676243593-0', tool_calls=[{'name': 'search_web', 'args': {'query': '    '}, 'id': 'call_f6RTD0NsqFBmgX05yONqXR9F', 'type': 'tool_call'}, {'name': 'search_wiki', 'args': {}, 'id': 'call_pnccTmxWhDAGzOXPOAH7Lfvz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 108, 'output_tokens': 51, 'total_tokens': 159})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "''\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[{'args': {'query': '    '},\n",
      "  'id': 'call_f6RTD0NsqFBmgX05yONqXR9F',\n",
      "  'name': 'search_web',\n",
      "  'type': 'tool_call'},\n",
      " {'args': {},\n",
      "  'id': 'call_pnccTmxWhDAGzOXPOAH7Lfvz',\n",
      "  'name': 'search_wiki',\n",
      "  'type': 'tool_call'}]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "llm_with_tools = llm.bind_tools(tools = [search_web, search_wiki])\n",
    "\n",
    "query = \"     ?    .\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "pprint(ai_msg)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LCEL \n",
    "\n",
    "###     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('( )  ,        .    ,  '\n",
      " ' .    ,   . \\n'\n",
      " '\\n'\n",
      " '   4   ,   .   ,    '\n",
      " ' .      , 2013 CNN    .   '\n",
      " '   ,     ,      .')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "def wiki_search_and_summarize(input_data: dict):\n",
    "    wiki_loader = WikipediaLoader(query = input_data[\"query\"], load_max_docs=2, lang = \"ko\")\n",
    "    wiki_docs = wiki_loader.load()\n",
    "\n",
    "    formatted_docs = [f'<Document sorce=\"{doc.metadata[\"source\"]}\"/>\\n{doc.page_content}\\n</Document>' for doc in wiki_docs]\n",
    "\n",
    "    return formatted_docs\n",
    "\n",
    "#   \n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the following text in a concise manner: \\n\\n{context}\\n\\nSummary\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model = 'gpt-4o-mini', temperature = 0)\n",
    "summary_chain = (\n",
    "    {\"context\": RunnableLambda(wiki_search_and_summarize)} | summary_prompt | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "summarized_text = summary_chain.invoke({\"query\": \" \"})\n",
    "pprint(summarized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": \n",
      "<class 'langchain_core.tools.structured.StructuredTool'>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "name: \n",
      "wiki_summary\n",
      "----------------------------------------------------------------------------------------------------\n",
      "description: \n",
      "('Use this took when you need to search for information on Wikipedia.\\n'\n",
      " \"It searches for Wikipedia articles related to the user's query and returns\\n\"\n",
      " 'a summarized text. This tool is useful when genral knowledge\\n'\n",
      " 'or background information is required.')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "schema: \n",
      "{'description': 'Input schema for Wikipedia search.',\n",
      " 'properties': {'query': {'description': 'The query to search for wikipedia',\n",
      "                          'title': 'Query',\n",
      "                          'type': 'string'}},\n",
      " 'required': ['query'],\n",
      " 'title': 'WikiSummarySchema',\n",
      " 'type': 'object'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#      \n",
    "class WikiSummarySchema(BaseModel):\n",
    "    \"\"\"Input schema for Wikipedia search.\"\"\"\n",
    "    query: str = Field(..., description=\"The query to search for wikipedia\")\n",
    "\n",
    "# as_tool     \n",
    "wiki_summary = summary_chain.as_tool(\n",
    "    name = \"wiki_summary\",\n",
    "    description=dedent(\"\"\"\n",
    "        Use this took when you need to search for information on Wikipedia.\n",
    "        It searches for Wikipedia articles related to the user's query and returns\n",
    "        a summarized text. This tool is useful when genral knowledge\n",
    "        or background information is required.\"\"\"),\n",
    "        args_schema = WikiSummarySchema)\n",
    "\n",
    "#  \n",
    "print(\": \")\n",
    "print(type(wiki_summary))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(wiki_summary.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(wiki_summary.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(wiki_summary.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_yLuVaT2P7gCr8S9X04DrZWPg', 'function': {'arguments': '{\"query\": \"    \"}', 'name': 'search_web'}, 'type': 'function'}, {'id': 'call_YSBPGXg8iMM6cdFCkqdcntFb', 'function': {'arguments': '{\"query\": \"\"}', 'name': 'wiki_summary'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 152, 'total_tokens': 206, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-1e2e31e9-14ca-4711-8cef-65f8a0480323-0', tool_calls=[{'name': 'search_web', 'args': {'query': '    '}, 'id': 'call_yLuVaT2P7gCr8S9X04DrZWPg', 'type': 'tool_call'}, {'name': 'wiki_summary', 'args': {'query': ''}, 'id': 'call_YSBPGXg8iMM6cdFCkqdcntFb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 152, 'output_tokens': 54, 'total_tokens': 206})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "''\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[{'args': {'query': '    '},\n",
      "  'id': 'call_yLuVaT2P7gCr8S9X04DrZWPg',\n",
      "  'name': 'search_web',\n",
      "  'type': 'tool_call'},\n",
      " {'args': {'query': ''},\n",
      "  'id': 'call_YSBPGXg8iMM6cdFCkqdcntFb',\n",
      "  'name': 'wiki_summary',\n",
      "  'type': 'tool_call'}]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "llm_with_tools = llm.bind_tools(tools= [search_web, wiki_summary])\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "pprint(ai_msg)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'wiki_summary',\n",
       " 'args': {'query': ''},\n",
       " 'id': 'call_YSBPGXg8iMM6cdFCkqdcntFb',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg.tool_calls[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='    ,        .    , 13    .    ,    .        .       ,        .' name='wiki_summary' tool_call_id='call_YSBPGXg8iMM6cdFCkqdcntFb'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('    ,        .    , '\n",
      " '13    .    ,    .   '\n",
      " '     .       ,    '\n",
      " '    .')\n"
     ]
    }
   ],
   "source": [
    "tool_message = wiki_summary.invoke(ai_msg.tool_calls[1])\n",
    "\n",
    "print(tool_message)\n",
    "print(\"-\"*100)\n",
    "pprint(tool_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai_msg: \n",
      " content='' additional_kwargs={'tool_calls': [{'id': 'call_dsNDI0o8rlNEgVKxWwWAzCnP', 'function': {'arguments': '{\"query\":\" \"}', 'name': 'wiki_summary'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 120, 'total_tokens': 140, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-fe6329bd-9092-4849-a6f8-75e8627b8626-0' tool_calls=[{'name': 'wiki_summary', 'args': {'query': ' '}, 'id': 'call_dsNDI0o8rlNEgVKxWwWAzCnP', 'type': 'tool_call'}] usage_metadata={'input_tokens': 120, 'output_tokens': 20, 'total_tokens': 140}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tool_msgs: \n",
      " [ToolMessage(content='[{\"url\": \"https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%8A%A4%ED%83%80\", \"content\": \"Link to USDA Database entry\\\\n        ,[1]       .[2]\\\\n(: pasta)   .                ,   .  ,[3][4]     .\\\\n\\\\n\\\\n\\\\n \\\\\"(pasta)\\\\\" \\\\\", \\\\\"  .\\\\n\\\\n [...] ,   2000    ,    .      [10]     .            .[11]    \\\\\"\\\\\" (lagana)     ,        .    [9]           .\\\\n\\\\n          5                .\\\\n\\\\n\\\\n\\\\n  \\\\n\\\\n [...]  1   lagana    ,   . 2     1     lagana  .                  . 5             lagana   ,       .            .         13 14 .[9]\"}, {\"url\": \"http://m.blog.naver.com/rokmcssj/20185188044\", \"content\": \"\\\\n\\\\n \\\\n\\\\n\\\\n\\\\n\\\\n~\\\\n\\\\n  \\\\n\\\\n2013. 4. 7. 3:54\\\\n\\\\n \\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n? ??\\\\n\\\\n          \\\\n\\\\n  .         \\\\n\\\\n,\\xa0        .\\\\n\\\\n\\\\n\\\\n     ,      \\\\n\\\\n      .\\\\n\\\\n          \\\\n\\\\n         .\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n \\\\n\\\\n\\\\n\\\\n   .  3         [...]        1   .    \\\\n\\\\n1295           .\\\\n\\\\n\\\\n\\\\n 12 ,         \\xa0        \\\\n\\\\n        .\\\\n\\\\n\\\\n\\\\n    ,       \\xa0              .\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n  \\\\n\\\\n\\\\n\\\\n        .   [...]    <  >     \\\\n\\\\n      .\\\\n\\\\n\\\\n\\\\n  !\\\\n\\\\n          .  \\\\n\\\\n  11       .\\\\n\\\\n\\\\n\\\\n        \\\\n\\\\n12     .     \\ufeff\\ufeff\\\\n\\\\n ,       .\\\\n\\\\n\\\\n\\\\n \\\\n\\\\n\\\\n\\\\n        16  \\\\n\\\\n   ,     . \"}, {\"url\": \"https://guide.michelin.com/kr/ko/article/features/world-pasta-day-an-a-z-guide-to-pasta-kr\", \"content\": \"  \\\\\"paste\\\\\" ,          .          .       :          , 8        .     ,              . ,               .                A-Z   .    .      !   : [...]       .      \\\\\"\\\\\"  \\\\\"(pest) \\\\\"  \\\\\"(pestare)\\\\\" . [...]    300    ?     , ,    .             ,          .  ,     (farfalle),    (strichetti) .       .       ,   ,    ,       ,            .        ,        .  \\\\\"\\\\\"\"}, {\"url\": \"https://namu.wiki/w/%ED%8C%8C%EC%8A%A4%ED%83%80\", \"content\": \"(pasta)   [1]            .\"}]', name='tavily_search_results_json', tool_call_id='call_dsNDI0o8rlNEgVKxWwWAzCnP', artifact={'query': ' ', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%8A%A4%ED%83%80', 'title': ' - ,   ', 'content': 'Link to USDA Database entry\\n        ,[1]       .[2]\\n(: pasta)   .                ,   .  ,[3][4]     .\\n\\n\\n\\n \"(pasta)\" \", \"  .\\n\\n [...] ,   2000    ,    .      [10]     .            .[11]    \"\" (lagana)     ,        .    [9]           .\\n\\n          5                .\\n\\n\\n\\n  \\n\\n [...]  1   lagana    ,   . 2     1     lagana  .                  . 5             lagana   ,       .            .         13 14 .[9]', 'score': 0.86080295, 'raw_content': None}, {'url': 'http://m.blog.naver.com/rokmcssj/20185188044', 'title': '   -  ', 'content': '\\n\\n \\n\\n\\n\\n\\n~\\n\\n  \\n\\n2013. 4. 7. 3:54\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n? ??\\n\\n          \\n\\n  .         \\n\\n,\\xa0        .\\n\\n\\n\\n     ,      \\n\\n      .\\n\\n          \\n\\n         .\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n   .  3         [...]        1   .    \\n\\n1295           .\\n\\n\\n\\n 12 ,         \\xa0        \\n\\n        .\\n\\n\\n\\n    ,       \\xa0              .\\n\\n\\n\\n\\n\\n\\n\\n  \\n\\n\\n\\n        .   [...]    <  >     \\n\\n      .\\n\\n\\n\\n  !\\n\\n          .  \\n\\n  11       .\\n\\n\\n\\n        \\n\\n12     .     \\ufeff\\ufeff\\n\\n ,       .\\n\\n\\n\\n \\n\\n\\n\\n        16  \\n\\n   ,     . ', 'score': 0.8415267, 'raw_content': None}, {'url': 'https://guide.michelin.com/kr/ko/article/features/world-pasta-day-an-a-z-guide-to-pasta-kr', 'title': '  : A-Z   - MICHELIN Guide', 'content': '  \"paste\" ,          .          .       :          , 8        .     ,              . ,               .                A-Z   .    .      !   : [...]       .      \"\"  \"(pest) \"  \"(pestare)\" . [...]    300    ?     , ,    .             ,          .  ,     (farfalle),    (strichetti) .       .       ,   ,    ,       ,            .        ,        .  \"\"', 'score': 0.8390101, 'raw_content': None}, {'url': 'https://namu.wiki/w/%ED%8C%8C%EC%8A%A4%ED%83%80', 'title': ' - ', 'content': '(pasta)   [1]            .', 'score': 0.8386933, 'raw_content': None}], 'response_time': 2.9})]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('    ,          ,     '\n",
      " '  .    ,    .\\n'\n",
      " '\\n'\n",
      " '      .    2000    , '\n",
      " ' 12      .       , '\n",
      " '    .             '\n",
      " ' .\\n'\n",
      " '\\n'\n",
      " '   \"pasta\" ,  \"\" .    ,  '\n",
      " '    .      ,      '\n",
      " '.\\n'\n",
      " '\\n'\n",
      " '   [](https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%8A%A4%ED%83%80) '\n",
      " '  .')\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "#  \n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", f\"you are a helpful AI assistant. Today's date is {today}\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\")\n",
    "])\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools = [wiki_summary])\n",
    "\n",
    "llm_chain = prompt | llm_with_tools\n",
    "\n",
    "@chain\n",
    "def wiki_summary_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "    print(\"ai_msg: \\n\", ai_msg)\n",
    "    print(\"-\"*100)\n",
    "    tool_msgs = web_search.batch(ai_msg.tool_calls, config=config)\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "    return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "response = web_search_chain.invoke(\"   .\")\n",
    "\n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  \n",
    "\n",
    "### @tool decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10   .\n",
      "\n",
      " : 1\n",
      "\n",
      " :  \n",
      "\n",
      ": 1.  \n",
      "    : 35,000\n",
      "     :   ,  ,  \n",
      "    :    , ...\n",
      "\n",
      " : 2\n",
      "\n",
      " :  \n",
      "\n",
      ": 2.  \n",
      "    : 22,000\n",
      "     :   ,  ,   \n",
      "    :   ...\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./data/restaurant_menu.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "#  \n",
    "def split_menu_items(document):\n",
    "    \"\"\"\n",
    "       \n",
    "    \"\"\"\n",
    "    pattern = r'(\\d+\\.\\s.*?)(?=\\n\\n\\d+\\.|$)' #  \n",
    "    menu_items = re.findall(pattern, document.page_content, re.DOTALL)\n",
    "\n",
    "    menu_documents = []\n",
    "    for i, item in enumerate(menu_items, 1):\n",
    "        #   \n",
    "        menu_name = item.split('\\n')[0].split('.', 1)[1].strip()\n",
    "\n",
    "        menu_doc = Document(\n",
    "            page_content = item.strip(),\n",
    "            metadata = {\n",
    "                \"source\": document.metadata['source'],\n",
    "                \"menu_number\": i,\n",
    "                \"menu_name\": menu_name\n",
    "            }\n",
    "        )\n",
    "        menu_documents.append(menu_doc)\n",
    "\n",
    "    return menu_documents\n",
    "\n",
    "menu_documents = []\n",
    "for doc in documents:\n",
    "    menu_documents += split_menu_items(doc)\n",
    "\n",
    "print(f\" {len(menu_documents)}   .\")\n",
    "for doc in menu_documents[:2]:\n",
    "    print(f\"\\n : {doc.metadata['menu_number']}\")\n",
    "    print(f\"\\n : {doc.metadata['menu_name']}\")\n",
    "    print(f\"\\n: {doc.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " : 2\n",
      " : 1\n",
      " :  \n",
      "\n",
      " : 1\n",
      " :  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chroma Vectorstore\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embedding_model = OllamaEmbeddings(model = \"bge-m3\")\n",
    "\n",
    "menu_db = Chroma.from_documents(\n",
    "    documents=menu_documents,\n",
    "    embedding=embedding_model,\n",
    "    collection_name=\"restaurant_menu\",\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "\n",
    "menu_retriever = menu_db.as_retriever(\n",
    "    search_kwargs = {'k':2},\n",
    ")\n",
    "\n",
    "qeury = \"    ?\"\n",
    "docs = menu_retriever.invoke(qeury)\n",
    "print(f' : {len(docs)}')\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\" : {doc.metadata['menu_number']}\")\n",
    "    print(f\" : {doc.metadata['menu_name']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": \n",
      "<class 'langchain_core.tools.structured.StructuredTool'>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "name: \n",
      "search_menu\n",
      "----------------------------------------------------------------------------------------------------\n",
      "description: \n",
      "('Securely retrieve and access authorized restaurant menu information from the '\n",
      " 'encrypted database.\\n'\n",
      " 'Use this tool only for menu-related queries to maintatin data '\n",
      " 'confidentiality.')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "schema: \n",
      "{'description': 'Securely retrieve and access authorized restaurant menu '\n",
      "                'information from the encrypted database.\\n'\n",
      "                'Use this tool only for menu-related queries to maintatin data '\n",
      "                'confidentiality.',\n",
      " 'properties': {'query': {'title': 'Query', 'type': 'string'}},\n",
      " 'required': ['query'],\n",
      " 'title': 'search_menu',\n",
      " 'type': 'object'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "menu_db = Chroma(\n",
    "    embedding_function=embedding_model,\n",
    "    collection_name=\"restaurant_menu\",\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "\n",
    "@tool\n",
    "def search_menu(query: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Securely retrieve and access authorized restaurant menu information from the encrypted database.\n",
    "    Use this tool only for menu-related queries to maintatin data confidentiality.\n",
    "    \"\"\"\n",
    "    docs = menu_db.similarity_search(query, k=2)\n",
    "    if len(docs) > 0:\n",
    "        return docs\n",
    "    \n",
    "    return [Document(page_content=\"    .\")] #  \n",
    "\n",
    "#  \n",
    "print(\": \")\n",
    "print(type(search_menu))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(search_menu.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(search_menu.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(search_menu.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10   .\n",
      "\n",
      " : 1\n",
      "\n",
      " :   2015\n",
      "\n",
      ": 1.   2015\n",
      "    : 450,000\n",
      "     :  , ,  ,  \n",
      "    :     ...\n",
      "\n",
      " : 2\n",
      "\n",
      " :   2012\n",
      "\n",
      ": 2.   2012\n",
      "    : 380,000\n",
      "     : ,  \n",
      "    :      . ...\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./data/restaurant_wine.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "#  \n",
    "def split_menu_items(document):\n",
    "    \"\"\"\n",
    "       \n",
    "    \"\"\"\n",
    "    pattern = r'(\\d+\\.\\s.*?)(?=\\n\\n\\d+\\.|$)' #  \n",
    "    menu_items = re.findall(pattern, document.page_content, re.DOTALL)\n",
    "\n",
    "    menu_documents = []\n",
    "    for i, item in enumerate(menu_items, 1):\n",
    "        #   \n",
    "        menu_name = item.split('\\n')[0].split('.', 1)[1].strip()\n",
    "\n",
    "        menu_doc = Document(\n",
    "            page_content = item.strip(),\n",
    "            metadata = {\n",
    "                \"source\": document.metadata['source'],\n",
    "                \"wine_number\": i,\n",
    "                \"wine_name\": menu_name\n",
    "            }\n",
    "        )\n",
    "        menu_documents.append(menu_doc)\n",
    "\n",
    "    return menu_documents\n",
    "\n",
    "menu_documents = []\n",
    "for doc in documents:\n",
    "    menu_documents += split_menu_items(doc)\n",
    "\n",
    "print(f\" {len(menu_documents)}   .\")\n",
    "for doc in menu_documents[:2]:\n",
    "    print(f\"\\n : {doc.metadata['wine_number']}\")\n",
    "    print(f\"\\n : {doc.metadata['wine_name']}\")\n",
    "    print(f\"\\n: {doc.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": \n",
      "<class 'langchain_core.tools.structured.StructuredTool'>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "name: \n",
      "search_wine\n",
      "----------------------------------------------------------------------------------------------------\n",
      "description: \n",
      "('Securely retrieve and access authorized restaurant wine information from the '\n",
      " 'encrypted database.\\n'\n",
      " 'Use this tool only for wine-related queries to maintatin data '\n",
      " 'confidentiality.')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "schema: \n",
      "{'description': 'Securely retrieve and access authorized restaurant wine '\n",
      "                'information from the encrypted database.\\n'\n",
      "                'Use this tool only for wine-related queries to maintatin data '\n",
      "                'confidentiality.',\n",
      " 'properties': {'query': {'title': 'Query', 'type': 'string'}},\n",
      " 'required': ['query'],\n",
      " 'title': 'search_wine',\n",
      " 'type': 'object'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "wine_db = Chroma(\n",
    "    embedding_function=embedding_model,\n",
    "    collection_name=\"restaurant_wine\",\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "\n",
    "@tool\n",
    "def search_wine(query: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Securely retrieve and access authorized restaurant wine information from the encrypted database.\n",
    "    Use this tool only for wine-related queries to maintatin data confidentiality.\n",
    "    \"\"\"\n",
    "    docs = wine_db.similarity_search(query, k=2)\n",
    "    if len(docs) > 0:\n",
    "        return docs\n",
    "    \n",
    "    return [Document(page_content=\"    .\")] #  \n",
    "\n",
    "#  \n",
    "print(\": \")\n",
    "print(type(search_wine))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(search_wine.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(search_wine.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(search_wine.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_WfmC1kbSt2pYFlH3vk2zBlQ5', 'function': {'arguments': '{\"query\": \" \"}', 'name': 'search_menu'}, 'type': 'function'}, {'id': 'call_kVB8dWA1wrq3NeYCodJJ0QaR', 'function': {'arguments': '{\"query\": \"\"}', 'name': 'search_wine'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 139, 'total_tokens': 193, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-8fd16498-9d87-4d24-9533-787a7a0afe7b-0', tool_calls=[{'name': 'search_menu', 'args': {'query': ' '}, 'id': 'call_WfmC1kbSt2pYFlH3vk2zBlQ5', 'type': 'tool_call'}, {'name': 'search_wine', 'args': {'query': ''}, 'id': 'call_kVB8dWA1wrq3NeYCodJJ0QaR', 'type': 'tool_call'}], usage_metadata={'input_tokens': 139, 'output_tokens': 54, 'total_tokens': 193})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "''\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[{'args': {'query': ' '},\n",
      "  'id': 'call_WfmC1kbSt2pYFlH3vk2zBlQ5',\n",
      "  'name': 'search_menu',\n",
      "  'type': 'tool_call'},\n",
      " {'args': {'query': ''},\n",
      "  'id': 'call_kVB8dWA1wrq3NeYCodJJ0QaR',\n",
      "  'name': 'search_wine',\n",
      "  'type': 'tool_call'}]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# LLM  \n",
    "llm_with_tools = llm.bind_tools(tools=[search_menu, search_wine])\n",
    "\n",
    "query = \"    ?      .\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "pprint(ai_msg)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_web\n",
      "wiki_summary\n",
      "search_menu\n",
      "search_wine\n"
     ]
    }
   ],
   "source": [
    "tools = [search_web, wiki_summary, search_menu, search_wine]\n",
    "for tool in tools:\n",
    "    print(tool.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_menu: \n",
      "{'name': 'search_menu', 'args': {'query': ' '}, 'id': 'call_hczIS7cPjgLXTtPpVI9kpGpy', 'type': 'tool_call'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "search_wine: \n",
      "{'name': 'search_wine', 'args': {'query': '  '}, 'id': 'call_pigsyRDi7CVMXaCuNTJtqvk6', 'type': 'tool_call'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tool_msgs: \n",
      " [ToolMessage(content=\"[Document(metadata={'menu_name': ' ', 'menu_number': 1, 'source': './data/restaurant_menu.txt'}, page_content='1.  \\\\n    : 35,000\\\\n     :   ,  ,  \\\\n    :    , 21      .      ,       .       .'), Document(metadata={'menu_name': ' ', 'menu_number': 1, 'source': './data/restaurant_menu.txt'}, page_content='1.  \\\\n    : 35,000\\\\n     :   ,  ,  \\\\n    :    , 21      .      ,       .       .')]\", name='search_menu', tool_call_id='call_hczIS7cPjgLXTtPpVI9kpGpy'), ToolMessage(content=\"[Document(metadata={}, page_content='    .')]\", name='search_wine', tool_call_id='call_pigsyRDi7CVMXaCuNTJtqvk6')]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "###  \n",
      "\n",
      "- ****: 35,000\n",
      "- ****:\n",
      "  - :   ,  ,  \n",
      "  - :     21     ,     .      ,     .\n",
      "\n",
      "###   \n",
      "\n",
      "       .      :\n",
      "\n",
      "1. **  **:         .\n",
      "2. ****:        .\n",
      "3. ****:     ,     .\n",
      "\n",
      "        .\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", f\"you are a helpful AI assistant. Today's date is {today}\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\")\n",
    "])\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-4o-mini\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools = tools)\n",
    "\n",
    "llm_chain = prompt | llm_with_tools\n",
    "\n",
    "@chain\n",
    "def chain_with_tools(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "    \n",
    "    tool_msgs = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        print(f\"{tool_call['name']}: \\n{tool_call}\")\n",
    "        print(\"-\"*100)\n",
    "\n",
    "        if tool_call[\"name\"] == \"search_web\":\n",
    "            tool_message = search_web.invoke(tool_call, config = config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"wiki_summary\":\n",
    "            tool_message = wiki_summary.invoke(tool_call, config = config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"search_menu\":\n",
    "            tool_message = search_menu.invoke(tool_call, config = config)\n",
    "            tool_msgs.append(tool_message)\n",
    "        \n",
    "        elif tool_call[\"name\"] == \"search_wine\":\n",
    "            tool_message = search_wine.invoke(tool_call, config = config)\n",
    "            tool_msgs.append(tool_message)\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "\n",
    "    return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "response = chain_with_tools.invoke(\"    ?      .\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_menu: \n",
      "{'name': 'search_menu', 'args': {'query': ''}, 'id': 'call_ki24tazaRCVNRoL5Mu79cM80', 'type': 'tool_call'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "wiki_summary: \n",
      "{'name': 'wiki_summary', 'args': {'query': ''}, 'id': 'call_JYdraVhzaU4rFgGNYBaDdR4W', 'type': 'tool_call'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tool_msgs: \n",
      " [ToolMessage(content=\"[Document(metadata={'menu_name': ' ', 'menu_number': 6, 'source': './data/restaurant_menu.txt'}, page_content='6.  \\\\n    : 24,000\\\\n     :  , , , ,  \\\\n    :          .       ,     .     .'), Document(metadata={'menu_name': ' ', 'menu_number': 6, 'source': './data/restaurant_menu.txt'}, page_content='6.  \\\\n    : 24,000\\\\n     :  , , , ,  \\\\n    :          .       ,     .     .')]\", name='search_menu', tool_call_id='call_ki24tazaRCVNRoL5Mu79cM80'), ToolMessage(content='    ,       ,   .    ,    . ,       , 13   .    ,     .          . \\n\\n      ,    ,    .', name='wiki_summary', tool_call_id='call_JYdraVhzaU4rFgGNYBaDdR4W')]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "###  \n",
      "** (: 24,000)**  \n",
      "- ** **:  , , , ,    \n",
      "- ****:          .        .\n",
      "\n",
      "###    \n",
      "   ,          .        ,       .     , 14   . \n",
      "\n",
      "        ,  ,     .        .\n"
     ]
    }
   ],
   "source": [
    "response = chain_with_tools.invoke('  ?      .')\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-shot   Toolcalling  \n",
    "\n",
    "-    , few-shot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'search_menu', 'args': {'query': ''}, 'id': 'call_pfBbNB1uaUFv5wi0J4kV5ZOE', 'type': 'tool_call'}\n",
      "{'name': 'search_wine', 'args': {'query': '  '}, 'id': 'call_JFhYqFWObNE8OZs4W3WNvpRv', 'type': 'tool_call'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    HumanMessage(\"   ,     .\", name=\"example_user\"),\n",
    "    AIMessage(\"  ,     ,   .\", name=\"example_assistant\"),\n",
    "    AIMessage(\"\", name=\"example_assistant\", tool_calls=[{\"name\": \"search_menu\", \"args\": {\"query\": \" \"}, \"id\": \"1\"}]),\n",
    "    ToolMessage(\" :  28,000,    ,        \", tool_call_id=\"1\"),\n",
    "    AIMessage(\"   28,000,            .     .\", name=\"example_assistant\"),\n",
    "    AIMessage(\"\", name=\"example_assistant\", tool_calls=[{\"name\": \"wiki_summary\", \"args\": {\"query\": \" \", \"k\": 1}, \"id\": \"2\"}]),\n",
    "    ToolMessage(\"        ,        .      ,      .            .\", tool_call_id=\"2\"),\n",
    "    AIMessage(\"    .    .\", name=\"example_assistant\"),\n",
    "    AIMessage(\"\", name=\"example_assistant\", tool_calls=[{\"name\": \"search_wine\", \"args\": {\"query\": \"   \"}, \"id\": \"3\"}]),\n",
    "    ToolMessage(\"          . 1. :     . 2.  :      . 3. :     ,    .\", tool_call_id=\"3\"),\n",
    "    AIMessage(\" (28,000)      ,            .           .        ,      .          .       ,        ,               .\", name=\"example_assistant\"),\n",
    "]\n",
    "\n",
    "system = \"\"\"You are an AI assistant providing restaurant menu information and general food-related knowledge.\n",
    "For information about the restaurant's menu, use the search_menu tool.\n",
    "For other general information, use the wiki_summary tool.\n",
    "For wine recommendations or pairing information, use the search_wine tool.\n",
    "If additional web searches are needed or for the most up-to-date information, use the search_web tool.\n",
    "\"\"\"\n",
    "\n",
    "few_shot_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    *examples,\n",
    "    (\"human\", \"{query}\"),\n",
    "])\n",
    "\n",
    "# ChatOpenAI   \n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "#    LLM  \n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "# Few-shot    \n",
    "fewshot_search_chain = few_shot_prompt | llm_with_tools\n",
    "\n",
    "#  \n",
    "query = \"  ?    .\"\n",
    "response = fewshot_search_chain.invoke(query)\n",
    "\n",
    "#  \n",
    "for tool_call in response.tool_calls:\n",
    "    print(tool_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'wiki_summary', 'args': {'query': '', 'k': 1}, 'id': 'call_fMwj2XQk9hoScGAAWqqJr194', 'type': 'tool_call'}\n",
      "{'name': 'search_web', 'args': {'query': '    '}, 'id': 'call_IF6SO2gJD7hvEwEn8i7Hgp6a', 'type': 'tool_call'}\n"
     ]
    }
   ],
   "source": [
    "query = \"    ?     .\"\n",
    "response = fewshot_search_chain.invoke(query)\n",
    "\n",
    "for tool_call in response.tool_calls:\n",
    "    print(tool_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_menu: \n",
      "{'name': 'search_menu', 'args': {'query': ''}, 'id': 'call_aZ06i8LQNAbHlRRJrNqqDx1t', 'type': 'tool_call'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "search_wine: \n",
      "{'name': 'search_wine', 'args': {'query': ''}, 'id': 'call_Jk1ZtDRQbWzzRY2DX4X3vgoE', 'type': 'tool_call'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tool_msgs: \n",
      " [ToolMessage(content=\"[Document(metadata={'menu_name': ' ', 'menu_number': 1, 'source': './data/restaurant_menu.txt'}, page_content='1.  \\\\n    : 35,000\\\\n     :   ,  ,  \\\\n    :    , 21      .      ,       .       .'), Document(metadata={'menu_name': ' ', 'menu_number': 1, 'source': './data/restaurant_menu.txt'}, page_content='1.  \\\\n    : 35,000\\\\n     :   ,  ,  \\\\n    :    , 21      .      ,       .       .')]\", name='search_menu', tool_call_id='call_aZ06i8LQNAbHlRRJrNqqDx1t'), ToolMessage(content=\"[Document(metadata={}, page_content='    .')]\", name='search_wine', tool_call_id='call_Jk1ZtDRQbWzzRY2DX4X3vgoE')]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "###  \n",
      "    :\n",
      "\n",
      "- ****\n",
      "  - : 35,000\n",
      "  -  : , , \n",
      "  - :  , 21    .      .   .\n",
      "\n",
      "###   \n",
      "         .        :\n",
      "\n",
      "- ** **:  , , \n",
      "- ** **:         .\n",
      "\n",
      "           .\n"
     ]
    }
   ],
   "source": [
    "#   \n",
    "\n",
    "today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "system = \"\"\"You are an AI assistant providing restaurant menu information and general food-related knowledge.\n",
    "For information about the restaurant's menu, use the search_menu tool.\n",
    "For other general information, use the wiki_summary tool.\n",
    "For wine recommendations or pairing information, use the search_wine tool.\n",
    "If additional web searches are needed or for the most up-to-date information, use the search_web tool.\n",
    "\"\"\"\n",
    "\n",
    "few_shot_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    *examples,\n",
    "    (\"human\", \"{query}\"),\n",
    "    (\"placeholder\", \"{messages}\")\n",
    "])\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-4o-mini\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools = tools)\n",
    "\n",
    "@chain\n",
    "def restaurant_menu_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "    \n",
    "    tool_msgs = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        print(f\"{tool_call['name']}: \\n{tool_call}\")\n",
    "        print(\"-\"*100)\n",
    "\n",
    "        if tool_call[\"name\"] == \"search_web\":\n",
    "            tool_message = search_web.invoke(tool_call, config = config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"wiki_summary\":\n",
    "            tool_message = wiki_summary.invoke(tool_call, config = config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"search_menu\":\n",
    "            tool_message = search_menu.invoke(tool_call, config = config)\n",
    "            tool_msgs.append(tool_message)\n",
    "        \n",
    "        elif tool_call[\"name\"] == \"search_wine\":\n",
    "            tool_message = search_wine.invoke(tool_call, config = config)\n",
    "            tool_msgs.append(tool_message)\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "\n",
    "    return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "query = \"  ?    .\"\n",
    "response = restaurant_menu_chain.invoke(query)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki_summary: \n",
      "{'name': 'wiki_summary', 'args': {'query': ' '}, 'id': 'call_DPfi2SN8dG8vIXU5hSdq1K34', 'type': 'tool_call'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "search_menu: \n",
      "{'name': 'search_menu', 'args': {'query': '   '}, 'id': 'call_IEz9cSDEFhwqFIykwcI4qDHx', 'type': 'tool_call'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tool_msgs: \n",
      " [ToolMessage(content='( )  ,        .    ,   .    ,   . \\n\\n   4   ,     .   ,     .      , 2013 CNN     .      ,     ,      .', name='wiki_summary', tool_call_id='call_DPfi2SN8dG8vIXU5hSdq1K34'), ToolMessage(content=\"[Document(metadata={'menu_name': ' ', 'menu_number': 6, 'source': './data/restaurant_menu.txt'}, page_content='6.  \\\\n    : 24,000\\\\n     :  , , , ,  \\\\n    :          .       ,     .     .'), Document(metadata={'menu_name': ' ', 'menu_number': 6, 'source': './data/restaurant_menu.txt'}, page_content='6.  \\\\n    : 24,000\\\\n     :  , , , ,  \\\\n    :          .       ,     .     .')]\", name='search_menu', tool_call_id='call_IEz9cSDEFhwqFIykwcI4qDHx')]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "###  \n",
      "\n",
      "   ,       .      ,       . , 4         . \n",
      "\n",
      "     ,  ,         .      ,       .\n",
      "\n",
      "###     \n",
      "\n",
      "       :\n",
      "\n",
      "1. **  **\n",
      "   - ****:   \n",
      "   - ****:  24,000\n",
      "\n",
      "2. ** **\n",
      "   - ****: ,   (,  )\n",
      "   - ****:      \n",
      "\n",
      "3. **  **\n",
      "   - ****:  ,  ,   \n",
      "   - ****:   \n",
      "\n",
      "        ,     !\n"
     ]
    }
   ],
   "source": [
    "query = \"    ?     .\"\n",
    "response = restaurant_menu_chain.invoke(query)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "agent_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", dedent(\"\"\"\n",
    "        You are an AI assistant providing restaurant menu information and general food-related knowledge. \n",
    "        Your main goal is to provide accurate information and effective recommendations to users.\n",
    "\n",
    "        Key guidelines:\n",
    "        1. For restaurant menu information, use the search_menu tool. This tool provides details on menu items, including prices, ingredients, and cooking methods.\n",
    "        2. For general food information, history, and cultural background, utilize the wiki_summary tool.\n",
    "        3. For wine recommendations or food and wine pairing information, use the search_wine tool.\n",
    "        4. If additional web searches are needed or for the most up-to-date information, use the search_web tool.\n",
    "        5. Provide clear and concise responses based on the search results.\n",
    "        6. If a question is ambiguous or lacks necessary information, politely ask for clarification.\n",
    "        7. Always maintain a helpful and professional tone.\n",
    "        8. When providing menu information, describe in the order of price, main ingredients, and distinctive cooking methods.\n",
    "        9. When making recommendations, briefly explain the reasons.\n",
    "        10. Maintain a conversational, chatbot-like style in your final responses. Be friendly, engaging, and natural in your communication.\n",
    "\n",
    "\n",
    "        Remember, understand the purpose of each tool accurately and use them in appropriate situations. \n",
    "        Combine the tools to provide the most comprehensive and accurate answers to user queries. \n",
    "        Always strive to provide the most current and accurate information.\n",
    "        \"\"\")),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool calling Agent \n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "\n",
    "tools = [search_web, wiki_summary, search_wine, search_menu]\n",
    "agent = create_tool_calling_agent(llm, tools, agent_prompt)\n",
    "\n",
    "# AgentExecutor  \n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_menu` with `{'query': ' '}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[Document(metadata={'menu_name': ' ', 'menu_number': 1, 'source': './data/restaurant_menu.txt'}, page_content='1.  \\n    : 35,000\\n     :   ,  ,  \\n    :    , 21      .      ,       .       .'), Document(metadata={'menu_name': ' ', 'menu_number': 1, 'source': './data/restaurant_menu.txt'}, page_content='1.  \\n    : 35,000\\n     :   ,  ,  \\n    :    , 21      .      ,       .       .')]\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_wine` with `{'query': ''}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m[Document(metadata={}, page_content='    .')]\u001b[0m\u001b[32;1m\u001b[1;3m###   \n",
      "- ****: 35,000\n",
      "- ** **:  (  ), ,  \n",
      "- ****:   21         .           .    ,   .\n",
      "\n",
      "###   \n",
      "        .         :\n",
      "- ** **:  ,           .\n",
      "- ** **:         .\n",
      "\n",
      "          !       .\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# AgentExecutor \n",
    "\n",
    "query = \"    ?      .\"\n",
    "agent_response = agent_executor.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '    ?      .',\n",
      " 'output': '###   \\n'\n",
      "           '- ****: 35,000\\n'\n",
      "           '- ** **:  (  ), ,  \\n'\n",
      "           '- ****:   21         . '\n",
      "           '          .    ,  '\n",
      "           ' .\\n'\n",
      "           '\\n'\n",
      "           '###   \\n'\n",
      "           '        .       '\n",
      "           '  :\\n'\n",
      "           '- ** **:  ,           .\\n'\n",
      "           '- ** **:         .\\n'\n",
      "           '\\n'\n",
      "           '          !       '\n",
      "           '.'}\n"
     ]
    }
   ],
   "source": [
    "pprint(agent_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from typing import List, Tuple\n",
    "\n",
    "def answer_invoke(message: str, history: List[Tuple[str, str]]) -> str:\n",
    "    try:\n",
    "        #   AI     \n",
    "        chat_history = []\n",
    "        for human, ai in history:\n",
    "            chat_history.append(HumanMessage(content=human))\n",
    "            chat_history.append(AIMessage(content=ai))\n",
    "        \n",
    "        # agent_executor   \n",
    "        response = agent_executor.invoke({\n",
    "            \"input\": message,\n",
    "            \"chat_history\": chat_history[-2:]    #  2    \n",
    "        })\n",
    "        \n",
    "        # agent_executor    \n",
    "        return response['output']\n",
    "    except Exception as e:\n",
    "        #       \n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        return \".     .   .\"\n",
    "\n",
    "#   \n",
    "example_questions = [\n",
    "    \"    .\",\n",
    "    \"     .\",\n",
    "    \"    ?     .\",\n",
    "    \"    ?\"\n",
    "]\n",
    "\n",
    "# Gradio  \n",
    "demo = gr.ChatInterface(\n",
    "    fn=answer_invoke,\n",
    "    title=\"  AI \",\n",
    "    description=\" , ,     .\",\n",
    "    examples=example_questions,\n",
    "    theme=gr.themes.Soft()\n",
    ")\n",
    "\n",
    "#  \n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "#  \n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
