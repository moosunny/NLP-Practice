{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.3.1 (from -r requirements.txt (line 1))\n",
      "  Downloading langchain-0.3.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langgraph==0.2.34 (from -r requirements.txt (line 2))\n",
      "  Downloading langgraph-0.2.34-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain-openai==0.2.1 (from -r requirements.txt (line 3))\n",
      "  Downloading langchain_openai-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain-community==0.3.1 (from -r requirements.txt (line 4))\n",
      "  Downloading langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting langchain-chroma==0.1.4 (from -r requirements.txt (line 5))\n",
      "  Downloading langchain_chroma-0.1.4-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting langchain-ollama==0.2.0 (from -r requirements.txt (line 6))\n",
      "  Downloading langchain_ollama-0.2.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langchain-google-genai==2.0.0 (from -r requirements.txt (line 7))\n",
      "  Downloading langchain_google_genai-2.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting langchain-groq==0.2.0 (from -r requirements.txt (line 8))\n",
      "  Downloading langchain_groq-0.2.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio==4.44.1 (from -r requirements.txt (line 9))\n",
      "  Downloading gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from -r requirements.txt (line 10)) (1.0.1)\n",
      "Collecting bs4==0.0.2 (from -r requirements.txt (line 11))\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting wikipedia==1.4.0 (from -r requirements.txt (line 12))\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain==0.3.1->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain==0.3.1->-r requirements.txt (line 1)) (2.0.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain==0.3.1->-r requirements.txt (line 1)) (3.11.16)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain==0.3.1->-r requirements.txt (line 1)) (0.3.51)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain==0.3.1->-r requirements.txt (line 1)) (0.3.8)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.3.1->-r requirements.txt (line 1))\n",
      "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy<2,>=1 (from langchain==0.3.1->-r requirements.txt (line 1))\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain==0.3.1->-r requirements.txt (line 1)) (2.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain==0.3.1->-r requirements.txt (line 1)) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain==0.3.1->-r requirements.txt (line 1))\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langgraph==0.2.34->-r requirements.txt (line 2)) (2.0.21)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain-openai==0.2.1->-r requirements.txt (line 3)) (1.70.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain-openai==0.2.1->-r requirements.txt (line 3)) (0.9.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain-community==0.3.1->-r requirements.txt (line 4)) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain-community==0.3.1->-r requirements.txt (line 4)) (2.8.1)\n",
      "Collecting chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 (from langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: fastapi<1,>=0.95.2 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.115.9)\n",
      "Requirement already satisfied: ollama<1,>=0.3.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain-ollama==0.2.0->-r requirements.txt (line 6)) (0.4.7)\n",
      "Collecting google-generativeai<0.8.0,>=0.7.0 (from langchain-google-genai==2.0.0->-r requirements.txt (line 7))\n",
      "  Downloading google_generativeai-0.7.2-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain-groq==0.2.0->-r requirements.txt (line 8)) (0.22.0)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (4.9.0)\n",
      "Collecting ffmpy (from gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.3.0 (from gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (0.29.3)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (6.5.2)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (2.1.5)\n",
      "Collecting matplotlib~=3.0 (from gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading matplotlib-3.10.1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (3.10.15)\n",
      "Requirement already satisfied: packaging in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (2.2.3)\n",
      "Collecting pillow<11.0,>=8.0 (from gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading pillow-10.4.0-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pydub (from gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting ruff>=0.2.2 (from gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading ruff-0.11.4-py3-none-win_amd64.whl.metadata (26 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (0.12.5)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (4.12.2)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (2.3.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from gradio==4.44.1->-r requirements.txt (line 9)) (0.34.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from bs4==0.0.2->-r requirements.txt (line 11)) (4.13.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from gradio-client==1.3.0->gradio==4.44.1->-r requirements.txt (line 9)) (2024.6.1)\n",
      "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading websockets-12.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1->-r requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1->-r requirements.txt (line 1)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1->-r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1->-r requirements.txt (line 1)) (6.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1->-r requirements.txt (line 1)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1->-r requirements.txt (line 1)) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from anyio<5.0,>=3.0->gradio==4.44.1->-r requirements.txt (line 9)) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from anyio<5.0,>=3.0->gradio==4.44.1->-r requirements.txt (line 9)) (1.3.1)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.7.6)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (3.23.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.31.1)\n",
      "Collecting tokenizers<=0.20.3,>=0.13.2 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading tokenizers-0.20.3-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (7.7.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.71.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (4.3.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (32.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (5.1.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (13.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.1->-r requirements.txt (line 4)) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.1->-r requirements.txt (line 4)) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from fastapi<1,>=0.95.2->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.45.3)\n",
      "Collecting google-ai-generativelanguage==0.6.6 (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7))\n",
      "  Downloading google_ai_generativelanguage-0.6.6-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7)) (2.24.2)\n",
      "Collecting google-api-python-client (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7))\n",
      "  Downloading google_api_python_client-2.166.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7)) (2.38.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7)) (5.29.4)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7)) (1.26.1)\n",
      "Collecting protobuf (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7))\n",
      "  Downloading protobuf-4.25.6-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq==0.2.0->-r requirements.txt (line 8)) (1.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from httpx>=0.24.1->gradio==4.44.1->-r requirements.txt (line 9)) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from httpx>=0.24.1->gradio==4.44.1->-r requirements.txt (line 9)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio==4.44.1->-r requirements.txt (line 9)) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio==4.44.1->-r requirements.txt (line 9)) (3.13.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain==0.3.1->-r requirements.txt (line 1)) (1.33)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph==0.2.34->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.1->-r requirements.txt (line 1)) (1.0.0)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib~=3.0->gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading contourpy-1.3.1-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib~=3.0->gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib~=3.0->gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading fonttools-4.57.0-cp311-cp311-win_amd64.whl.metadata (104 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib~=3.0->gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib~=3.0->gradio==4.44.1->-r requirements.txt (line 9))\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mmm06\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib~=3.0->gradio==4.44.1->-r requirements.txt (line 9)) (2.8.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.1->-r requirements.txt (line 3)) (0.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from pandas<3.0,>=1.0->gradio==4.44.1->-r requirements.txt (line 9)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from pandas<3.0,>=1.0->gradio==4.44.1->-r requirements.txt (line 9)) (2025.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.1->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.1->-r requirements.txt (line 1)) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from requests<3,>=2->langchain==0.3.1->-r requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.1->-r requirements.txt (line 1)) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.1->-r requirements.txt (line 3)) (2024.11.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from typer<1.0,>=0.12->gradio==4.44.1->-r requirements.txt (line 9)) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from typer<1.0,>=0.12->gradio==4.44.1->-r requirements.txt (line 9)) (1.5.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from beautifulsoup4->bs4==0.0.2->-r requirements.txt (line 11)) (2.6)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mmm06\\appdata\\roaming\\python\\python311\\site-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.4.6)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7)) (1.69.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7)) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7)) (4.9)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain==0.3.1->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\mmm06\\appdata\\roaming\\python\\python311\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.9)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (25.2.10)\n",
      "Requirement already satisfied: sympy in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (8.6.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.31.1 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.31.1 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.31.1)\n",
      "INFO: pip is looking at multiple versions of opentelemetry-proto to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.31.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.31.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.31.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.31.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_proto-1.31.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_sdk-1.29.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_proto-1.28.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_sdk-1.28.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_proto-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "INFO: pip is still looking at multiple versions of opentelemetry-proto to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_proto-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.52b1 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.52b1 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.52b1 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.52b1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from opentelemetry-instrumentation==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (3.8.1)\n",
      "INFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-semantic-conventions==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Using cached opentelemetry_semantic_conventions-0.52b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.52b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Using cached opentelemetry_instrumentation-0.52b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "INFO: pip is still looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.52b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.52b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation-0.52b0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_semantic_conventions-0.52b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_util_http-0.52b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_api-1.31.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting importlib-metadata<=8.5.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-util-http==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_api-1.29.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-util-http==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_api-1.28.2-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.49b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.49b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation-0.49b1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_semantic_conventions-0.49b1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_util_http-0.49b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_api-1.28.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.49b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.49b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation-0.49b0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_semantic_conventions-0.49b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_util_http-0.49b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_api-1.28.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (75.8.0)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting importlib-metadata<=8.4.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5))\n",
      "  Downloading importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (2.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mmm06\\appdata\\roaming\\python\\python311\\site-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (2.15.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.1->-r requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.0.4)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7))\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7))\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7))\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7)) (1.71.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7)) (0.6.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (1.3.0)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai==2.0.0->-r requirements.txt (line 7))\n",
      "  Downloading grpcio_status-1.71.0rc2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.70.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.69.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.69.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.68.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_status-1.68.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.67.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.67.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.67.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading grpcio_status-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0rc5-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0rc3-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0rc2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.5-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.4-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.0rc2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.3-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.0rc2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\mmm06\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4->-r requirements.txt (line 5)) (3.5.4)\n",
      "Downloading langchain-0.3.1-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 11.8 MB/s eta 0:00:00\n",
      "Downloading langgraph-0.2.34-py3-none-any.whl (107 kB)\n",
      "Downloading langchain_openai-0.2.1-py3-none-any.whl (49 kB)\n",
      "Downloading langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 16.8 MB/s eta 0:00:00\n",
      "Downloading langchain_chroma-0.1.4-py3-none-any.whl (10 kB)\n",
      "Downloading langchain_ollama-0.2.0-py3-none-any.whl (14 kB)\n",
      "Downloading langchain_google_genai-2.0.0-py3-none-any.whl (39 kB)\n",
      "Downloading langchain_groq-0.2.0-py3-none-any.whl (14 kB)\n",
      "Downloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n",
      "   ---------------------------------------- 0.0/18.1 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 3.4/18.1 MB 16.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 6.6/18.1 MB 15.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 15.2/18.1 MB 23.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.1/18.1 MB 24.8 MB/s eta 0:00:00\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
      "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading chromadb-0.5.23-py3-none-any.whl (628 kB)\n",
      "   ---------------------------------------- 0.0/628.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 628.3/628.3 kB 11.8 MB/s eta 0:00:00\n",
      "Downloading google_generativeai-0.7.2-py3-none-any.whl (164 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.6-py3-none-any.whl (718 kB)\n",
      "   ---------------------------------------- 0.0/718.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 718.3/718.3 kB 28.5 MB/s eta 0:00:00\n",
      "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Downloading matplotlib-3.10.1-cp311-cp311-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 8.1/8.1 MB 41.5 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 5.8/15.8 MB 27.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.6/15.8 MB 31.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.4/15.8 MB 21.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 21.2 MB/s eta 0:00:00\n",
      "Downloading pillow-10.4.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.6/2.6 MB 37.0 MB/s eta 0:00:00\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.11.4-py3-none-win_amd64.whl (11.4 MB)\n",
      "   ---------------------------------------- 0.0/11.4 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 8.1/11.4 MB 38.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.4/11.4 MB 32.5 MB/s eta 0:00:00\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading contourpy-1.3.1-cp311-cp311-win_amd64.whl (219 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.57.0-cp311-cp311-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 31.3 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.8-cp311-cp311-win_amd64.whl (71 kB)\n",
      "Downloading protobuf-4.25.6-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n",
      "Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
      "Downloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
      "Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading tokenizers-0.20.3-cp311-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 45.1 MB/s eta 0:00:00\n",
      "Downloading websockets-12.0-cp311-cp311-win_amd64.whl (124 kB)\n",
      "Downloading google_api_python_client-2.166.0-py2.py3-none-any.whl (13.2 MB)\n",
      "   ---------------------------------------- 0.0/13.2 MB ? eta -:--:--\n",
      "   --------------------------- ------------ 9.2/13.2 MB 43.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.2/13.2 MB 41.3 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio_status-1.63.0rc1-py3-none-any.whl (14 kB)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py): started\n",
      "  Building wheel for wikipedia (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11756 sha256=bb326551cd35b331aae96746bd52335204c693c3be4faf0bc08e4b52d1cb38bf\n",
      "  Stored in directory: c:\\users\\mmm06\\appdata\\local\\pip\\cache\\wheels\\8f\\ab\\cb\\45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: pydub, websockets, uritemplate, tomlkit, tenacity, semantic-version, ruff, python-multipart, pyparsing, protobuf, pillow, opentelemetry-util-http, numpy, kiwisolver, importlib-metadata, fonttools, ffmpy, cycler, aiofiles, wikipedia, opentelemetry-proto, opentelemetry-api, httplib2, contourpy, bs4, tokenizers, opentelemetry-semantic-conventions, opentelemetry-instrumentation, opentelemetry-exporter-otlp-proto-common, matplotlib, langsmith, grpcio-status, gradio-client, google-auth-httplib2, opentelemetry-sdk, opentelemetry-instrumentation-asgi, gradio, google-api-python-client, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, langchain-openai, langchain-ollama, langchain-groq, google-ai-generativelanguage, langgraph, langchain, google-generativeai, chromadb, langchain-google-genai, langchain-community, langchain-chroma\n",
      "  Attempting uninstall: websockets\n",
      "    Found existing installation: websockets 15.0.1\n",
      "    Uninstalling websockets-15.0.1:\n",
      "      Successfully uninstalled websockets-15.0.1\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.29.4\n",
      "    Uninstalling protobuf-5.29.4:\n",
      "      Successfully uninstalled protobuf-5.29.4\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.0.0\n",
      "    Uninstalling pillow-11.0.0:\n",
      "      Successfully uninstalled pillow-11.0.0\n",
      "  Attempting uninstall: opentelemetry-util-http\n",
      "    Found existing installation: opentelemetry-util-http 0.52b1\n",
      "    Uninstalling opentelemetry-util-http-0.52b1:\n",
      "      Successfully uninstalled opentelemetry-util-http-0.52b1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.4\n",
      "    Uninstalling numpy-2.2.4:\n",
      "      Successfully uninstalled numpy-2.2.4\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib_metadata 8.6.1\n",
      "    Uninstalling importlib_metadata-8.6.1:\n",
      "      Successfully uninstalled importlib_metadata-8.6.1\n",
      "  Attempting uninstall: opentelemetry-proto\n",
      "    Found existing installation: opentelemetry-proto 1.31.1\n",
      "    Uninstalling opentelemetry-proto-1.31.1:\n",
      "      Successfully uninstalled opentelemetry-proto-1.31.1\n",
      "  Attempting uninstall: opentelemetry-api\n",
      "    Found existing installation: opentelemetry-api 1.31.1\n",
      "    Uninstalling opentelemetry-api-1.31.1:\n",
      "      Successfully uninstalled opentelemetry-api-1.31.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.1\n",
      "    Uninstalling tokenizers-0.21.1:\n",
      "      Successfully uninstalled tokenizers-0.21.1\n",
      "  Attempting uninstall: opentelemetry-semantic-conventions\n",
      "    Found existing installation: opentelemetry-semantic-conventions 0.52b1\n",
      "    Uninstalling opentelemetry-semantic-conventions-0.52b1:\n",
      "      Successfully uninstalled opentelemetry-semantic-conventions-0.52b1\n",
      "  Attempting uninstall: opentelemetry-instrumentation\n",
      "    Found existing installation: opentelemetry-instrumentation 0.52b1\n",
      "    Uninstalling opentelemetry-instrumentation-0.52b1:\n",
      "      Successfully uninstalled opentelemetry-instrumentation-0.52b1\n",
      "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
      "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.31.1\n",
      "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.31.1:\n",
      "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.31.1\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.3.18\n",
      "    Uninstalling langsmith-0.3.18:\n",
      "      Successfully uninstalled langsmith-0.3.18\n",
      "  Attempting uninstall: grpcio-status\n",
      "    Found existing installation: grpcio-status 1.71.0\n",
      "    Uninstalling grpcio-status-1.71.0:\n",
      "      Successfully uninstalled grpcio-status-1.71.0\n",
      "  Attempting uninstall: opentelemetry-sdk\n",
      "    Found existing installation: opentelemetry-sdk 1.31.1\n",
      "    Uninstalling opentelemetry-sdk-1.31.1:\n",
      "      Successfully uninstalled opentelemetry-sdk-1.31.1\n",
      "  Attempting uninstall: opentelemetry-instrumentation-asgi\n",
      "    Found existing installation: opentelemetry-instrumentation-asgi 0.52b1\n",
      "    Uninstalling opentelemetry-instrumentation-asgi-0.52b1:\n",
      "      Successfully uninstalled opentelemetry-instrumentation-asgi-0.52b1\n",
      "  Attempting uninstall: opentelemetry-instrumentation-fastapi\n",
      "    Found existing installation: opentelemetry-instrumentation-fastapi 0.52b1\n",
      "    Uninstalling opentelemetry-instrumentation-fastapi-0.52b1:\n",
      "      Successfully uninstalled opentelemetry-instrumentation-fastapi-0.52b1\n",
      "  Attempting uninstall: opentelemetry-exporter-otlp-proto-grpc\n",
      "    Found existing installation: opentelemetry-exporter-otlp-proto-grpc 1.31.1\n",
      "    Uninstalling opentelemetry-exporter-otlp-proto-grpc-1.31.1:\n",
      "      Successfully uninstalled opentelemetry-exporter-otlp-proto-grpc-1.31.1\n",
      "  Attempting uninstall: langchain-openai\n",
      "    Found existing installation: langchain-openai 0.3.12\n",
      "    Uninstalling langchain-openai-0.3.12:\n",
      "      Successfully uninstalled langchain-openai-0.3.12\n",
      "  Attempting uninstall: langchain-ollama\n",
      "    Found existing installation: langchain-ollama 0.2.3\n",
      "    Uninstalling langchain-ollama-0.2.3:\n",
      "      Successfully uninstalled langchain-ollama-0.2.3\n",
      "  Attempting uninstall: langchain-groq\n",
      "    Found existing installation: langchain-groq 0.3.2\n",
      "    Uninstalling langchain-groq-0.3.2:\n",
      "      Successfully uninstalled langchain-groq-0.3.2\n",
      "  Attempting uninstall: google-ai-generativelanguage\n",
      "    Found existing installation: google-ai-generativelanguage 0.6.17\n",
      "    Uninstalling google-ai-generativelanguage-0.6.17:\n",
      "      Successfully uninstalled google-ai-generativelanguage-0.6.17\n",
      "  Attempting uninstall: langgraph\n",
      "    Found existing installation: langgraph 0.3.18\n",
      "    Uninstalling langgraph-0.3.18:\n",
      "      Successfully uninstalled langgraph-0.3.18\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.23\n",
      "    Uninstalling langchain-0.3.23:\n",
      "      Successfully uninstalled langchain-0.3.23\n",
      "  Attempting uninstall: chromadb\n",
      "    Found existing installation: chromadb 1.0.0\n",
      "    Uninstalling chromadb-1.0.0:\n",
      "      Successfully uninstalled chromadb-1.0.0\n",
      "  Attempting uninstall: langchain-google-genai\n",
      "    Found existing installation: langchain-google-genai 2.1.2\n",
      "    Uninstalling langchain-google-genai-2.1.2:\n",
      "      Successfully uninstalled langchain-google-genai-2.1.2\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.3.21\n",
      "    Uninstalling langchain-community-0.3.21:\n",
      "      Successfully uninstalled langchain-community-0.3.21\n",
      "Successfully installed aiofiles-23.2.1 bs4-0.0.2 chromadb-0.5.23 contourpy-1.3.1 cycler-0.12.1 ffmpy-0.5.0 fonttools-4.57.0 google-ai-generativelanguage-0.6.6 google-api-python-client-2.166.0 google-auth-httplib2-0.2.0 google-generativeai-0.7.2 gradio-4.44.1 gradio-client-1.3.0 grpcio-status-1.63.0rc1 httplib2-0.22.0 importlib-metadata-8.4.0 kiwisolver-1.4.8 langchain-0.3.1 langchain-chroma-0.1.4 langchain-community-0.3.1 langchain-google-genai-2.0.0 langchain-groq-0.2.0 langchain-ollama-0.2.0 langchain-openai-0.2.1 langgraph-0.2.34 langsmith-0.1.147 matplotlib-3.10.1 numpy-1.26.4 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 pillow-10.4.0 protobuf-4.25.6 pydub-0.25.1 pyparsing-3.2.3 python-multipart-0.0.20 ruff-0.11.4 semantic-version-2.10.0 tenacity-8.5.0 tokenizers-0.20.3 tomlkit-0.12.0 uritemplate-4.1.1 websockets-12.0 wikipedia-1.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\mmm06\\anaconda3\\envs\\Deeplearning\\Lib\\site-packages\\google\\~upb'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "grpcio-tools 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.6 which is incompatible.\n",
      "transformers 4.49.0 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, json\n",
    "\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    \n",
    "tavily   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': '    !     ...', 'url': 'https://m.blog.naver.com/wineislikeacat/223096696241', 'content': ' ,     ?  ,  !\\n\\n     .\\n       .\\n       ,\\n     .\\n\\u200b\\n        ,\\n        \\n        .\\n\\u200b\\n  \\n (Carbernet Sauvignon), (Syrah)  !\\n\\u200b\\n\\n   \\n\\n    ? ! [...]      !\\n, !\\n\\u200b\\n     ?\\n        .\\n        :)\\n\\u200b\\n      \\n    .\\n\\u200b\\n? ?  ?    ! - 1,  :)          ... blog.naver.com\\n ? ?  ?    ! - 2,  :)      4  . ... blog.naver.com\\n\\u200b\\n\\n &     [...]         \\n           .\\n            .\\n\\u200b\\n           \\n (Sangiovege)   .\\n\\u200b\\n\\n  \\n\\n   ? ,  !\\n\\n   \\n      .\\n      .\\n\\u200b\\n      \\n    ,\\n      .\\n\\u200b\\n        \\n    (Malbec)   !\\n\\u200b', 'score': 0.903098}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'title': '   :   ? -  ', 'url': 'https://mashija.com/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%B5%9C%EA%B3%A0%EC%9D%98-%EC%99%80%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%A0%EB%A5%BC-%EA%B2%83%EC%9D%B8/', 'content': 'Bora Kim 2022 1 27\\n (Cabernet Sauvignon)  (Malbec)       ,       ,           . [...] <     5  >\\n  (Cabernet Sauvignon)\\n (Malbec)\\n / (Grenache / Shiraz blends)\\n /(Syrah / Shiraz)\\n (Sangiovese)\\n              .\\n        ,             .\\n<   >\\n              ,        . [...]    (Karen MacNeil)     10  (grilled)          .\\n       \\n2018    (Peter Richards MW)              . .\\n    (Cabernet Franc) ?  (Carignan), (Cinsault)     (Syrah) ? DWWA    Decanter Retailer Awards     (ros)    . .', 'score': 0.89720124}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'title': '  !     5 - 10  ...', 'url': 'https://blog.naver.com/chelina89/220634349414?viewType=pc', 'content': '1.  - 6 .            .  2.   - 3', 'score': 0.8091708}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'title': '23   ? - ', 'url': 'https://brunch.co.kr/@@9J8F/66', 'content': '           ,         . ', 'score': 0.80126834}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "query = \"   .\"\n",
    "\n",
    "web_search = TavilySearchResults(max_results=4)\n",
    "\n",
    "search_results = web_search.invoke(query)\n",
    "\n",
    "for result in search_results:\n",
    "    print(result)\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": \n",
      "<class 'list'>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "name: \n",
      "tavily_search_results_json\n",
      "----------------------------------------------------------------------------------------------------\n",
      "description: \n",
      "A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "schema: \n",
      "{'description': 'Input for the Tavily tool.', 'properties': {'query': {'description': 'search query to look up', 'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'TavilyInput', 'type': 'object'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\": \")\n",
    "print(type(search_results))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(web_search.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "print(web_search.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "print(web_search.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI   Toolcalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools([web_search]) #tavily    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='!  ?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 82, 'total_tokens': 94, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'id': 'chatcmpl-BIyblcYlbuNzdeoqhdk5Kl2oURIJc', 'finish_reason': 'stop', 'logprobs': None} id='run-8e2f4af5-c290-434f-b08e-31006880b992-0' usage_metadata={'input_tokens': 82, 'output_tokens': 12, 'total_tokens': 94, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "!  ?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \".\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "print(ai_msg)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(ai_msg.content)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(ai_msg.tool_calls)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_R20lc726phH5fpdUnGjUicn5', 'function': {'arguments': '{\"query\":\"  \"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 91, 'total_tokens': 115, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'id': 'chatcmpl-BIybm8cSBF5oMJ2klueYhjk65Jm3h', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-22adb579-3ced-40db-a6cd-f5ecfe9d1bb6-0' tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': '  '}, 'id': 'call_R20lc726phH5fpdUnGjUicn5', 'type': 'tool_call'}] usage_metadata={'input_tokens': 91, 'output_tokens': 24, 'total_tokens': 115, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[{'name': 'tavily_search_results_json', 'args': {'query': '  '}, 'id': 'call_R20lc726phH5fpdUnGjUicn5', 'type': 'tool_call'}]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"   .\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "print(ai_msg)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(ai_msg.content)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(ai_msg.tool_calls)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'tavily_search_results_json',\n",
       " 'args': {'query': '  '},\n",
       " 'id': 'call_R20lc726phH5fpdUnGjUicn5',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = ai_msg.tool_calls[0]\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tavily_search_results_json   : \n",
      "----------------------------------------------------------------------------------------------------\n",
      "[{'title': '   :   ? -  ', 'url': 'https://mashija.com/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%B5%9C%EA%B3%A0%EC%9D%98-%EC%99%80%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%A0%EB%A5%BC-%EA%B2%83%EC%9D%B8/', 'content': 'Bora Kim 2022 1 27\\n (Cabernet Sauvignon)  (Malbec)       ,       ,           . [...] <     5  >\\n  (Cabernet Sauvignon)\\n (Malbec)\\n / (Grenache / Shiraz blends)\\n /(Syrah / Shiraz)\\n (Sangiovese)\\n              .\\n        ,             .\\n<   >\\n              ,        . [...]      .      . 2020    .\\n    2007                (Syrah)   (Cte-Rtie)  (Super Tuscan)  . .\\n            .\\n   \\n         . (barnaise)         .    . .\\n<  >\\n   ,            ?', 'score': 0.84858394}, {'title': '      - 21', 'url': 'https://www.wine21.com/11_news/news_view.html?Idx=19051', 'content': \"      (Mark Quick)              .          ,          .    MW               .\\n      [...]                 .             .     ,        .      (Fiona Becket)         ,           (Daniel Rion)  (Vosne-Romane) 2001 .\\n   ? [...]            .    ,    .    (Karen MacNeil)     10  '          '      .\\n      \\n (Peter Richards) MW        ,      .                   .\\n    ?\", 'score': 0.8399576}, {'title': '      - ', 'url': 'https://www.clien.net/service/board/kin/18358866', 'content': '5          .           ', 'score': 0.83452857}, {'title': '    !     ...', 'url': 'https://m.blog.naver.com/wineislikeacat/223096696241', 'content': ' ,     ?  ,  !\\n\\n     .\\n       .\\n       ,\\n     .\\n\\u200b\\n        ,\\n        \\n        .\\n\\u200b\\n  \\n (Carbernet Sauvignon), (Syrah)  !\\n\\u200b\\n\\n   \\n\\n    ? ! [...]         \\n           .\\n            .\\n\\u200b\\n           \\n (Sangiovege)   .\\n\\u200b\\n\\n  \\n\\n   ? ,  !\\n\\n   \\n      .\\n      .\\n\\u200b\\n      \\n    ,\\n      .\\n\\u200b\\n        \\n    (Malbec)   !\\n\\u200b [...]   \\n 0 \\n{\"title\":\"    !     \",\"source\":\"https://blog.naver.com/wineislikeacat/223096696241\",\"blogName\":\"  ..\",\"domainIdOrBlogId\":\"wineislikeacat\",\"nicknameOrBlogId\":\"\",\"logNo\":223096696241,\"smartEditorVersion\":4,\"meDisplay\":true,\"lineDisplay\":true,\"outsideDisplay\":false,\"cafeDisplay\":false,\"blogDisplay\":false}\\n\\n\\n  \\n\\n  \\n 0 \\n(wineislikeacat)    \\n ', 'score': 0.8342047}]\n"
     ]
    }
   ],
   "source": [
    "###    \n",
    "\n",
    "tool_output = web_search.invoke(tool_call[\"args\"])\n",
    "print(f\"{tool_call['name']}   : \")\n",
    "print(\"-\"*100)\n",
    "print(tool_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=[{'title': '   :   ? -  ', 'url': 'https://mashija.com/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%B5%9C%EA%B3%A0%EC%9D%98-%EC%99%80%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%A0%EB%A5%BC-%EA%B2%83%EC%9D%B8/', 'content': 'Bora Kim 2022 1 27\\n (Cabernet Sauvignon)  (Malbec)       ,       ,           . [...] <     5  >\\n  (Cabernet Sauvignon)\\n (Malbec)\\n / (Grenache / Shiraz blends)\\n /(Syrah / Shiraz)\\n (Sangiovese)\\n              .\\n        ,             .\\n<   >\\n              ,        . [...]      .      . 2020    .\\n    2007                (Syrah)   (Cte-Rtie)  (Super Tuscan)  . .\\n            .\\n   \\n         . (barnaise)         .    . .\\n<  >\\n   ,            ?', 'score': 0.84858394}, {'title': '      - 21', 'url': 'https://www.wine21.com/11_news/news_view.html?Idx=19051', 'content': \"      (Mark Quick)              .          ,          .    MW               .\\n      [...]                 .             .     ,        .      (Fiona Becket)         ,           (Daniel Rion)  (Vosne-Romane) 2001 .\\n   ? [...]            .    ,    .    (Karen MacNeil)     10  '          '      .\\n      \\n (Peter Richards) MW        ,      .                   .\\n    ?\", 'score': 0.8399576}, {'title': '      - ', 'url': 'https://www.clien.net/service/board/kin/18358866', 'content': '5          .           ', 'score': 0.83452857}, {'title': '    !     ...', 'url': 'https://m.blog.naver.com/wineislikeacat/223096696241', 'content': ' ,     ?  ,  !\\n\\n     .\\n       .\\n       ,\\n     .\\n\\u200b\\n        ,\\n        \\n        .\\n\\u200b\\n  \\n (Carbernet Sauvignon), (Syrah)  !\\n\\u200b\\n\\n   \\n\\n    ? ! [...]         \\n           .\\n            .\\n\\u200b\\n           \\n (Sangiovege)   .\\n\\u200b\\n\\n  \\n\\n   ? ,  !\\n\\n   \\n      .\\n      .\\n\\u200b\\n      \\n    ,\\n      .\\n\\u200b\\n        \\n    (Malbec)   !\\n\\u200b [...]   \\n 0 \\n{\"title\":\"    !     \",\"source\":\"https://blog.naver.com/wineislikeacat/223096696241\",\"blogName\":\"  ..\",\"domainIdOrBlogId\":\"wineislikeacat\",\"nicknameOrBlogId\":\"\",\"logNo\":223096696241,\"smartEditorVersion\":4,\"meDisplay\":true,\"lineDisplay\":true,\"outsideDisplay\":false,\"cafeDisplay\":false,\"blogDisplay\":false}\\n\\n\\n  \\n\\n  \\n 0 \\n(wineislikeacat)    \\n ', 'score': 0.8342047}] name='tavily_search_results_json' tool_call_id='call_R20lc726phH5fpdUnGjUicn5'\n"
     ]
    }
   ],
   "source": [
    "# toolMessage \n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "tool_message = ToolMessage(\n",
    "    name=tool_call[\"name\"],\n",
    "    tool_call_id=tool_call[\"id\"],\n",
    "    content=tool_output\n",
    ")\n",
    "\n",
    "print(tool_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='[{\"title\": \"   :   ? -  \", \"url\": \"https://mashija.com/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%B5%9C%EA%B3%A0%EC%9D%98-%EC%99%80%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%A0%EB%A5%BC-%EA%B2%83%EC%9D%B8/\", \"content\": \"Bora Kim 2022 1 27\\\\n (Cabernet Sauvignon)  (Malbec)       ,       ,           . [...] <     5  >\\\\n  (Cabernet Sauvignon)\\\\n (Malbec)\\\\n / (Grenache / Shiraz blends)\\\\n /(Syrah / Shiraz)\\\\n (Sangiovese)\\\\n              .\\\\n        ,             .\\\\n<   >\\\\n              ,        . [...]      .      . 2020    .\\\\n    2007                (Syrah)   (Cte-Rtie)  (Super Tuscan)  . .\\\\n            .\\\\n   \\\\n         . (barnaise)         .    . .\\\\n<  >\\\\n   ,            ?\", \"score\": 0.84858394}, {\"title\": \"      - 21\", \"url\": \"https://www.wine21.com/11_news/news_view.html?Idx=19051\", \"content\": \"      (Mark Quick)              .          ,          .    MW               .\\\\n      [...]                 .             .     ,        .      (Fiona Becket)         ,           (Daniel Rion)  (Vosne-Romane) 2001 .\\\\n   ? [...]            .    ,    .    (Karen MacNeil)     10  \\'          \\'      .\\\\n      \\\\n (Peter Richards) MW        ,      .                   .\\\\n    ?\", \"score\": 0.8399576}, {\"title\": \"      - \", \"url\": \"https://www.clien.net/service/board/kin/18358866\", \"content\": \"5          .           \", \"score\": 0.83452857}, {\"title\": \"    !     ...\", \"url\": \"https://m.blog.naver.com/wineislikeacat/223096696241\", \"content\": \" ,     ?  ,  !\\\\n\\\\n     .\\\\n       .\\\\n       ,\\\\n     .\\\\n\\u200b\\\\n        ,\\\\n        \\\\n        .\\\\n\\u200b\\\\n  \\\\n (Carbernet Sauvignon), (Syrah)  !\\\\n\\u200b\\\\n\\\\n   \\\\n\\\\n    ? ! [...]         \\\\n           .\\\\n            .\\\\n\\u200b\\\\n           \\\\n (Sangiovege)   .\\\\n\\u200b\\\\n\\\\n  \\\\n\\\\n   ? ,  !\\\\n\\\\n   \\\\n      .\\\\n      .\\\\n\\u200b\\\\n      \\\\n    ,\\\\n      .\\\\n\\u200b\\\\n        \\\\n    (Malbec)   !\\\\n\\u200b [...]   \\\\n 0 \\\\n{\\\\\"title\\\\\":\\\\\"    !     \\\\\",\\\\\"source\\\\\":\\\\\"https://blog.naver.com/wineislikeacat/223096696241\\\\\",\\\\\"blogName\\\\\":\\\\\"  ..\\\\\",\\\\\"domainIdOrBlogId\\\\\":\\\\\"wineislikeacat\\\\\",\\\\\"nicknameOrBlogId\\\\\":\\\\\"\\\\\",\\\\\"logNo\\\\\":223096696241,\\\\\"smartEditorVersion\\\\\":4,\\\\\"meDisplay\\\\\":true,\\\\\"lineDisplay\\\\\":true,\\\\\"outsideDisplay\\\\\":false,\\\\\"cafeDisplay\\\\\":false,\\\\\"blogDisplay\\\\\":false}\\\\n\\\\n\\\\n  \\\\n\\\\n  \\\\n 0 \\\\n(wineislikeacat)    \\\\n \", \"score\": 0.8342047}]' name='tavily_search_results_json' tool_call_id='call_R20lc726phH5fpdUnGjUicn5' artifact={'query': '  ', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://mashija.com/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%B5%9C%EA%B3%A0%EC%9D%98-%EC%99%80%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%A0%EB%A5%BC-%EA%B2%83%EC%9D%B8/', 'title': '   :   ? -  ', 'content': 'Bora Kim 2022 1 27\\n (Cabernet Sauvignon)  (Malbec)       ,       ,           . [...] <     5  >\\n  (Cabernet Sauvignon)\\n (Malbec)\\n / (Grenache / Shiraz blends)\\n /(Syrah / Shiraz)\\n (Sangiovese)\\n              .\\n        ,             .\\n<   >\\n              ,        . [...]      .      . 2020    .\\n    2007                (Syrah)   (Cte-Rtie)  (Super Tuscan)  . .\\n            .\\n   \\n         . (barnaise)         .    . .\\n<  >\\n   ,            ?', 'score': 0.84858394, 'raw_content': None}, {'url': 'https://www.wine21.com/11_news/news_view.html?Idx=19051', 'title': '      - 21', 'content': \"      (Mark Quick)              .          ,          .    MW               .\\n      [...]                 .             .     ,        .      (Fiona Becket)         ,           (Daniel Rion)  (Vosne-Romane) 2001 .\\n   ? [...]            .    ,    .    (Karen MacNeil)     10  '          '      .\\n      \\n (Peter Richards) MW        ,      .                   .\\n    ?\", 'score': 0.8399576, 'raw_content': None}, {'url': 'https://www.clien.net/service/board/kin/18358866', 'title': '      - ', 'content': '5          .           ', 'score': 0.83452857, 'raw_content': None}, {'url': 'https://m.blog.naver.com/wineislikeacat/223096696241', 'title': '    !     ...', 'content': ' ,     ?  ,  !\\n\\n     .\\n       .\\n       ,\\n     .\\n\\u200b\\n        ,\\n        \\n        .\\n\\u200b\\n  \\n (Carbernet Sauvignon), (Syrah)  !\\n\\u200b\\n\\n   \\n\\n    ? ! [...]         \\n           .\\n            .\\n\\u200b\\n           \\n (Sangiovege)   .\\n\\u200b\\n\\n  \\n\\n   ? ,  !\\n\\n   \\n      .\\n      .\\n\\u200b\\n      \\n    ,\\n      .\\n\\u200b\\n        \\n    (Malbec)   !\\n\\u200b [...]   \\n 0 \\n{\"title\":\"    !     \",\"source\":\"https://blog.naver.com/wineislikeacat/223096696241\",\"blogName\":\"  ..\",\"domainIdOrBlogId\":\"wineislikeacat\",\"nicknameOrBlogId\":\"\",\"logNo\":223096696241,\"smartEditorVersion\":4,\"meDisplay\":true,\"lineDisplay\":true,\"outsideDisplay\":false,\"cafeDisplay\":false,\"blogDisplay\":false}\\n\\n\\n  \\n\\n  \\n 0 \\n(wineislikeacat)    \\n ', 'score': 0.8342047, 'raw_content': None}], 'response_time': 1.72}\n"
     ]
    }
   ],
   "source": [
    "#    Toolcall message  \n",
    "\n",
    "tool_message = web_search.invoke(tool_call)\n",
    "print(tool_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolMessage(content='[{\"title\": \"   :   ? -  \", \"url\": \"https://mashija.com/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%B5%9C%EA%B3%A0%EC%9D%98-%EC%99%80%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%A0%EB%A5%BC-%EA%B2%83%EC%9D%B8/\", \"content\": \"Bora Kim 2022 1 27\\\\n (Cabernet Sauvignon)  (Malbec)       ,       ,           . [...] <     5  >\\\\n  (Cabernet Sauvignon)\\\\n (Malbec)\\\\n / (Grenache / Shiraz blends)\\\\n /(Syrah / Shiraz)\\\\n (Sangiovese)\\\\n              .\\\\n        ,             .\\\\n<   >\\\\n              ,        . [...]      .      . 2020    .\\\\n    2007                (Syrah)   (Cte-Rtie)  (Super Tuscan)  . .\\\\n            .\\\\n   \\\\n         . (barnaise)         .    . .\\\\n<  >\\\\n   ,            ?\", \"score\": 0.84858394}, {\"title\": \"      - 21\", \"url\": \"https://www.wine21.com/11_news/news_view.html?Idx=19051\", \"content\": \"      (Mark Quick)              .          ,          .    MW               .\\\\n      [...]                 .             .     ,        .      (Fiona Becket)         ,           (Daniel Rion)  (Vosne-Romane) 2001 .\\\\n   ? [...]            .    ,    .    (Karen MacNeil)     10  \\'          \\'      .\\\\n      \\\\n (Peter Richards) MW        ,      .                   .\\\\n    ?\", \"score\": 0.8399576}, {\"title\": \"      - \", \"url\": \"https://www.clien.net/service/board/kin/18358866\", \"content\": \"5          .           \", \"score\": 0.83452857}, {\"title\": \"    !     ...\", \"url\": \"https://m.blog.naver.com/wineislikeacat/223096696241\", \"content\": \" ,     ?  ,  !\\\\n\\\\n     .\\\\n       .\\\\n       ,\\\\n     .\\\\n\\u200b\\\\n        ,\\\\n        \\\\n        .\\\\n\\u200b\\\\n  \\\\n (Carbernet Sauvignon), (Syrah)  !\\\\n\\u200b\\\\n\\\\n   \\\\n\\\\n    ? ! [...]         \\\\n           .\\\\n            .\\\\n\\u200b\\\\n           \\\\n (Sangiovege)   .\\\\n\\u200b\\\\n\\\\n  \\\\n\\\\n   ? ,  !\\\\n\\\\n   \\\\n      .\\\\n      .\\\\n\\u200b\\\\n      \\\\n    ,\\\\n      .\\\\n\\u200b\\\\n        \\\\n    (Malbec)   !\\\\n\\u200b [...]   \\\\n 0 \\\\n{\\\\\"title\\\\\":\\\\\"    !     \\\\\",\\\\\"source\\\\\":\\\\\"https://blog.naver.com/wineislikeacat/223096696241\\\\\",\\\\\"blogName\\\\\":\\\\\"  ..\\\\\",\\\\\"domainIdOrBlogId\\\\\":\\\\\"wineislikeacat\\\\\",\\\\\"nicknameOrBlogId\\\\\":\\\\\"\\\\\",\\\\\"logNo\\\\\":223096696241,\\\\\"smartEditorVersion\\\\\":4,\\\\\"meDisplay\\\\\":true,\\\\\"lineDisplay\\\\\":true,\\\\\"outsideDisplay\\\\\":false,\\\\\"cafeDisplay\\\\\":false,\\\\\"blogDisplay\\\\\":false}\\\\n\\\\n\\\\n  \\\\n\\\\n  \\\\n 0 \\\\n(wineislikeacat)    \\\\n \", \"score\": 0.8342047}]', name='tavily_search_results_json', tool_call_id='call_R20lc726phH5fpdUnGjUicn5', artifact={'query': '  ', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://mashija.com/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%B5%9C%EA%B3%A0%EC%9D%98-%EC%99%80%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%A0%EB%A5%BC-%EA%B2%83%EC%9D%B8/', 'title': '   :   ? -  ', 'content': 'Bora Kim 2022 1 27\\n (Cabernet Sauvignon)  (Malbec)       ,       ,           . [...] <     5  >\\n  (Cabernet Sauvignon)\\n (Malbec)\\n / (Grenache / Shiraz blends)\\n /(Syrah / Shiraz)\\n (Sangiovese)\\n              .\\n        ,             .\\n<   >\\n              ,        . [...]      .      . 2020    .\\n    2007                (Syrah)   (Cte-Rtie)  (Super Tuscan)  . .\\n            .\\n   \\n         . (barnaise)         .    . .\\n<  >\\n   ,            ?', 'score': 0.84858394, 'raw_content': None}, {'url': 'https://www.wine21.com/11_news/news_view.html?Idx=19051', 'title': '      - 21', 'content': \"      (Mark Quick)              .          ,          .    MW               .\\n      [...]                 .             .     ,        .      (Fiona Becket)         ,           (Daniel Rion)  (Vosne-Romane) 2001 .\\n   ? [...]            .    ,    .    (Karen MacNeil)     10  '          '      .\\n      \\n (Peter Richards) MW        ,      .                   .\\n    ?\", 'score': 0.8399576, 'raw_content': None}, {'url': 'https://www.clien.net/service/board/kin/18358866', 'title': '      - ', 'content': '5          .           ', 'score': 0.83452857, 'raw_content': None}, {'url': 'https://m.blog.naver.com/wineislikeacat/223096696241', 'title': '    !     ...', 'content': ' ,     ?  ,  !\\n\\n     .\\n       .\\n       ,\\n     .\\n\\u200b\\n        ,\\n        \\n        .\\n\\u200b\\n  \\n (Carbernet Sauvignon), (Syrah)  !\\n\\u200b\\n\\n   \\n\\n    ? ! [...]         \\n           .\\n            .\\n\\u200b\\n           \\n (Sangiovege)   .\\n\\u200b\\n\\n  \\n\\n   ? ,  !\\n\\n   \\n      .\\n      .\\n\\u200b\\n      \\n    ,\\n      .\\n\\u200b\\n        \\n    (Malbec)   !\\n\\u200b [...]   \\n 0 \\n{\"title\":\"    !     \",\"source\":\"https://blog.naver.com/wineislikeacat/223096696241\",\"blogName\":\"  ..\",\"domainIdOrBlogId\":\"wineislikeacat\",\"nicknameOrBlogId\":\"\",\"logNo\":223096696241,\"smartEditorVersion\":4,\"meDisplay\":true,\"lineDisplay\":true,\"outsideDisplay\":false,\"cafeDisplay\":false,\"blogDisplay\":false}\\n\\n\\n  \\n\\n  \\n 0 \\n(wineislikeacat)    \\n ', 'score': 0.8342047, 'raw_content': None}], 'response_time': 1.72})\n"
     ]
    }
   ],
   "source": [
    "pprint(tool_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'tavily_search_results_json'\n"
     ]
    }
   ],
   "source": [
    "pprint(tool_message.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ToolMessage(content='[{\"title\": \"   :   ? -  \", \"url\": \"https://mashija.com/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%B5%9C%EA%B3%A0%EC%9D%98-%EC%99%80%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%A0%EB%A5%BC-%EA%B2%83%EC%9D%B8/\", \"content\": \"Bora Kim 2022 1 27\\\\n (Cabernet Sauvignon)  (Malbec)       ,       ,           . [...] <     5  >\\\\n  (Cabernet Sauvignon)\\\\n (Malbec)\\\\n / (Grenache / Shiraz blends)\\\\n /(Syrah / Shiraz)\\\\n (Sangiovese)\\\\n              .\\\\n        ,             .\\\\n<   >\\\\n              ,        . [...]      .      . 2020    .\\\\n    2007                (Syrah)   (Cte-Rtie)  (Super Tuscan)  . .\\\\n            .\\\\n   \\\\n         . (barnaise)         .    . .\\\\n<  >\\\\n   ,            ?\", \"score\": 0.84858394}, {\"title\": \"      - 21\", \"url\": \"https://www.wine21.com/11_news/news_view.html?Idx=19051\", \"content\": \"      (Mark Quick)              .          ,          .    MW               .\\\\n      [...]                 .             .     ,        .      (Fiona Becket)         ,           (Daniel Rion)  (Vosne-Romane) 2001 .\\\\n   ? [...]            .    ,    .    (Karen MacNeil)     10  \\'          \\'      .\\\\n      \\\\n (Peter Richards) MW        ,      .                   .\\\\n    ?\", \"score\": 0.8399576}, {\"title\": \"      - \", \"url\": \"https://www.clien.net/service/board/kin/18358866\", \"content\": \"5          .           \", \"score\": 0.83452857}, {\"title\": \"    !     ...\", \"url\": \"https://m.blog.naver.com/wineislikeacat/223096696241\", \"content\": \" ,     ?  ,  !\\\\n\\\\n     .\\\\n       .\\\\n       ,\\\\n     .\\\\n\\u200b\\\\n        ,\\\\n        \\\\n        .\\\\n\\u200b\\\\n  \\\\n (Carbernet Sauvignon), (Syrah)  !\\\\n\\u200b\\\\n\\\\n   \\\\n\\\\n    ? ! [...]         \\\\n           .\\\\n            .\\\\n\\u200b\\\\n           \\\\n (Sangiovege)   .\\\\n\\u200b\\\\n\\\\n  \\\\n\\\\n   ? ,  !\\\\n\\\\n   \\\\n      .\\\\n      .\\\\n\\u200b\\\\n      \\\\n    ,\\\\n      .\\\\n\\u200b\\\\n        \\\\n    (Malbec)   !\\\\n\\u200b [...]   \\\\n 0 \\\\n{\\\\\"title\\\\\":\\\\\"    !     \\\\\",\\\\\"source\\\\\":\\\\\"https://blog.naver.com/wineislikeacat/223096696241\\\\\",\\\\\"blogName\\\\\":\\\\\"  ..\\\\\",\\\\\"domainIdOrBlogId\\\\\":\\\\\"wineislikeacat\\\\\",\\\\\"nicknameOrBlogId\\\\\":\\\\\"\\\\\",\\\\\"logNo\\\\\":223096696241,\\\\\"smartEditorVersion\\\\\":4,\\\\\"meDisplay\\\\\":true,\\\\\"lineDisplay\\\\\":true,\\\\\"outsideDisplay\\\\\":false,\\\\\"cafeDisplay\\\\\":false,\\\\\"blogDisplay\\\\\":false}\\\\n\\\\n\\\\n  \\\\n\\\\n  \\\\n 0 \\\\n(wineislikeacat)    \\\\n \", \"score\": 0.8342047}]', name='tavily_search_results_json', tool_call_id='call_R20lc726phH5fpdUnGjUicn5', artifact={'query': '  ', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://mashija.com/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%B5%9C%EA%B3%A0%EC%9D%98-%EC%99%80%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%A0%EB%A5%BC-%EA%B2%83%EC%9D%B8/', 'title': '   :   ? -  ', 'content': 'Bora Kim 2022 1 27\\n (Cabernet Sauvignon)  (Malbec)       ,       ,           . [...] <     5  >\\n  (Cabernet Sauvignon)\\n (Malbec)\\n / (Grenache / Shiraz blends)\\n /(Syrah / Shiraz)\\n (Sangiovese)\\n              .\\n        ,             .\\n<   >\\n              ,        . [...]      .      . 2020    .\\n    2007                (Syrah)   (Cte-Rtie)  (Super Tuscan)  . .\\n            .\\n   \\n         . (barnaise)         .    . .\\n<  >\\n   ,            ?', 'score': 0.84858394, 'raw_content': None}, {'url': 'https://www.wine21.com/11_news/news_view.html?Idx=19051', 'title': '      - 21', 'content': \"      (Mark Quick)              .          ,          .    MW               .\\n      [...]                 .             .     ,        .      (Fiona Becket)         ,           (Daniel Rion)  (Vosne-Romane) 2001 .\\n   ? [...]            .    ,    .    (Karen MacNeil)     10  '          '      .\\n      \\n (Peter Richards) MW        ,      .                   .\\n    ?\", 'score': 0.8399576, 'raw_content': None}, {'url': 'https://www.clien.net/service/board/kin/18358866', 'title': '      - ', 'content': '5          .           ', 'score': 0.83452857, 'raw_content': None}, {'url': 'https://m.blog.naver.com/wineislikeacat/223096696241', 'title': '    !     ...', 'content': ' ,     ?  ,  !\\n\\n     .\\n       .\\n       ,\\n     .\\n\\u200b\\n        ,\\n        \\n        .\\n\\u200b\\n  \\n (Carbernet Sauvignon), (Syrah)  !\\n\\u200b\\n\\n   \\n\\n    ? ! [...]         \\n           .\\n            .\\n\\u200b\\n           \\n (Sangiovege)   .\\n\\u200b\\n\\n  \\n\\n   ? ,  !\\n\\n   \\n      .\\n      .\\n\\u200b\\n      \\n    ,\\n      .\\n\\u200b\\n        \\n    (Malbec)   !\\n\\u200b [...]   \\n 0 \\n{\"title\":\"    !     \",\"source\":\"https://blog.naver.com/wineislikeacat/223096696241\",\"blogName\":\"  ..\",\"domainIdOrBlogId\":\"wineislikeacat\",\"nicknameOrBlogId\":\"\",\"logNo\":223096696241,\"smartEditorVersion\":4,\"meDisplay\":true,\"lineDisplay\":true,\"outsideDisplay\":false,\"cafeDisplay\":false,\"blogDisplay\":false}\\n\\n\\n  \\n\\n  \\n 0 \\n(wineislikeacat)    \\n ', 'score': 0.8342047, 'raw_content': None}], 'response_time': 2.17})]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('[{\"title\": \"   :   ? -  \", \"url\": '\n",
      " '\"https://mashija.com/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%B5%9C%EA%B3%A0%EC%9D%98-%EC%99%80%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%A0%EB%A5%BC-%EA%B2%83%EC%9D%B8/\", '\n",
      " '\"content\": \"Bora Kim 2022 1 27\\\\n (Cabernet Sauvignon)  '\n",
      " '(Malbec)       ,       ,  '\n",
      " '         . [...] <     5 '\n",
      " ' >\\\\n  (Cabernet Sauvignon)\\\\n (Malbec)\\\\n / '\n",
      " '(Grenache / Shiraz blends)\\\\n /(Syrah / Shiraz)\\\\n '\n",
      " '(Sangiovese)\\\\n              '\n",
      " '.\\\\n        ,          '\n",
      " '   .\\\\n<   >\\\\n         '\n",
      " '     ,        . [...]     '\n",
      " ' .      . 2020    .\\\\n  '\n",
      " '  2007                '\n",
      " '(Syrah)   (Cte-Rtie)  (Super Tuscan)  . '\n",
      " '.\\\\n            .\\\\n   \\\\n '\n",
      " '        . (barnaise)       '\n",
      " '  .    . .\\\\n<  >\\\\n   ,  '\n",
      " '          ?\", \"score\": 0.84858394}, '\n",
      " '{\"title\": \"      - 21\", \"url\": '\n",
      " '\"https://www.wine21.com/11_news/news_view.html?Idx=19051\", \"content\": \" '\n",
      " '     (Mark Quick)          '\n",
      " '    .          ,    '\n",
      " '      .    MW        '\n",
      " '       .\\\\n      [...]   '\n",
      " '              .     '\n",
      " '        .     ,    '\n",
      " '    .      (Fiona Becket)     '\n",
      " '    ,           (Daniel '\n",
      " 'Rion)  (Vosne-Romane) 2001 .\\\\n   ? [...]   '\n",
      " '         .    ,    .  '\n",
      " \"  (Karen MacNeil)     10  '     \"\n",
      " \"     '      .\\\\n      \"\n",
      " '\\\\n (Peter Richards) MW        ,   '\n",
      " '   .              '\n",
      " '     .\\\\n    ?\", \"score\": '\n",
      " '0.8399576}, {\"title\": \"      - \", \"url\": '\n",
      " '\"https://www.clien.net/service/board/kin/18358866\", \"content\": \"5   '\n",
      " '       .           \", '\n",
      " '\"score\": 0.83452857}, {\"title\": \"    !     ...\", '\n",
      " '\"url\": \"https://m.blog.naver.com/wineislikeacat/223096696241\", \"content\": '\n",
      " '\" ,     ?  ,  !\\\\n\\\\n     '\n",
      " '.\\\\n       .\\\\n       '\n",
      " ',\\\\n     .\\\\n\\u200b\\\\n       '\n",
      " ' ,\\\\n        \\\\n        '\n",
      " '.\\\\n\\u200b\\\\n  \\\\n (Carbernet Sauvignon), (Syrah) '\n",
      " ' !\\\\n\\u200b\\\\n\\\\n   \\\\n\\\\n    ? ! '\n",
      " '[...]         \\\\n          '\n",
      " ' .\\\\n            .\\\\n\\u200b\\\\n  '\n",
      " '         \\\\n (Sangiovege)   '\n",
      " '.\\\\n\\u200b\\\\n\\\\n  \\\\n\\\\n   ? ,  '\n",
      " '!\\\\n\\\\n   \\\\n      .\\\\n    '\n",
      " '  .\\\\n\\u200b\\\\n      \\\\n    '\n",
      " ',\\\\n      .\\\\n\\u200b\\\\n        '\n",
      " '\\\\n    (Malbec)   !\\\\n\\u200b [...]   \\\\n '\n",
      " '0 \\\\n{\\\\\"title\\\\\":\\\\\"    !     '\n",
      " '\\\\\",\\\\\"source\\\\\":\\\\\"https://blog.naver.com/wineislikeacat/223096696241\\\\\",\\\\\"blogName\\\\\":\\\\\" '\n",
      " ' '\n",
      " '..\\\\\",\\\\\"domainIdOrBlogId\\\\\":\\\\\"wineislikeacat\\\\\",\\\\\"nicknameOrBlogId\\\\\":\\\\\"\\\\\",\\\\\"logNo\\\\\":223096696241,\\\\\"smartEditorVersion\\\\\":4,\\\\\"meDisplay\\\\\":true,\\\\\"lineDisplay\\\\\":true,\\\\\"outsideDisplay\\\\\":false,\\\\\"cafeDisplay\\\\\":false,\\\\\"blogDisplay\\\\\":false}\\\\n\\\\n\\\\n '\n",
      " ' \\\\n\\\\n  \\\\n 0 \\\\n(wineislikeacat)    '\n",
      " '\\\\n \", \"score\": 0.8342047}]')\n"
     ]
    }
   ],
   "source": [
    "#   \n",
    "tool_messages = web_search.batch(ai_msg.tool_calls)\n",
    "print(tool_messages)\n",
    "print(\"-\"*100)\n",
    "pprint(tool_messages[0].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_R20lc726phH5fpdUnGjUicn5', 'function': {'arguments': '{\"query\":\"  \"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 91, 'total_tokens': 115, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'id': 'chatcmpl-BIybm8cSBF5oMJ2klueYhjk65Jm3h', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-22adb579-3ced-40db-a6cd-f5ecfe9d1bb6-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': '  '}, 'id': 'call_R20lc726phH5fpdUnGjUicn5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 91, 'output_tokens': 24, 'total_tokens': 115, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai_msg: \n",
      " content='' additional_kwargs={'tool_calls': [{'id': 'call_pGliJu8EKKySWc7lmnMmB4rf', 'function': {'arguments': '{\"query\":\"   \"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 114, 'total_tokens': 144, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'id': 'chatcmpl-BIyc8FKKbRVhzjm5dHDEyZVvK2X03', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-81c7bb83-701a-480b-8d1a-c805cd7edca0-0' tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': '   '}, 'id': 'call_pGliJu8EKKySWc7lmnMmB4rf', 'type': 'tool_call'}] usage_metadata={'input_tokens': 114, 'output_tokens': 30, 'total_tokens': 144, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tool_msgs: \n",
      " [ToolMessage(content='[{\"title\": \" > & - \", \"url\": \"http://kaja2002.co.kr/shop/shop/item.php?it_id=1700092164\", \"content\": \", 95,000. , 57,000. , . , 12 %. , 750 ml.  . .    +0.   :57,000 . \", \"score\": 0.8338803}, {\"title\": \" : ON\", \"url\": \"https://www.lotteon.com/search/search/search.ecn?render=search&platform=m&mallId=&q=%EB%AA%A8%EC%97%A3%EC%83%B9%EB%8F%99\", \"content\": \"19   .      (750ML(/)).  89,000. 5.0 9.    . /\", \"score\": 0.8091708}, {\"title\": \"2.   ,   - \", \"url\": \"https://maily.so/julie/posts/e9o0kd75z8w\", \"content\": \"   .   NV : 7.5.    : 8.5.     : 12.   \", \"score\": 0.8088086}, {\"title\": \" -  ,  - SSG\", \"url\": \"https://department.ssg.com/search.ssg?query=%EB%AA%A8%EC%97%A3%EC%83%B9%EB%8F%99\", \"content\": \"    Moet Chandon Imperial Champagne Flute Glasses Flutes 0.2 L S. 135,400. 129,980. 4%. .\", \"score\": 0.8066246}]', name='tavily_search_results_json', tool_call_id='call_pGliJu8EKKySWc7lmnMmB4rf', artifact={'query': '   ', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'http://kaja2002.co.kr/shop/shop/item.php?it_id=1700092164', 'title': ' > & - ', 'content': ', 95,000. , 57,000. , . , 12 %. , 750 ml.  . .    +0.   :57,000 . ', 'score': 0.8338803, 'raw_content': None}, {'url': 'https://www.lotteon.com/search/search/search.ecn?render=search&platform=m&mallId=&q=%EB%AA%A8%EC%97%A3%EC%83%B9%EB%8F%99', 'title': ' : ON', 'content': '19   .      (750ML(/)).  89,000. 5.0 9.    . /', 'score': 0.8091708, 'raw_content': None}, {'url': 'https://maily.so/julie/posts/e9o0kd75z8w', 'title': '2.   ,   - ', 'content': '   .   NV : 7.5.    : 8.5.     : 12.   ', 'score': 0.8088086, 'raw_content': None}, {'url': 'https://department.ssg.com/search.ssg?query=%EB%AA%A8%EC%97%A3%EC%83%B9%EB%8F%99', 'title': ' -  ,  - SSG', 'content': '    Moet Chandon Imperial Champagne Flute Glasses Flutes 0.2 L S. 135,400. 129,980. 4%. .', 'score': 0.8066246, 'raw_content': None}], 'response_time': 3.0})]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('     :\\n'\n",
      " '\\n'\n",
      " '1. **  (750ml)**\\n'\n",
      " '   - ** **: 57,000 ( )\\n'\n",
      " '   - ** **: 95,000\\n'\n",
      " '   - ****: '\n",
      " '[](http://kaja2002.co.kr/shop/shop/item.php?it_id=1700092164)\\n'\n",
      " '\\n'\n",
      " '2. **  (750ml)**\\n'\n",
      " '   - ** **: 89,000\\n'\n",
      " '   - ****: '\n",
      " '[ON](https://www.lotteon.com/search/search/search.ecn?render=search&platform=m&mallId=&q=%EB%AA%A8%EC%97%A3%EC%83%B9%EB%8F%99)\\n'\n",
      " '\\n'\n",
      " '3. **  NV**\\n'\n",
      " '   - ****: 75,000\\n'\n",
      " '   - ****: [](https://maily.so/julie/posts/e9o0kd75z8w)\\n'\n",
      " '\\n'\n",
      " '4. **  **\\n'\n",
      " '   - ****: 85,000\\n'\n",
      " '\\n'\n",
      " '        .     .')\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "#  \n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", f\"you are a helpful AI assistant. Today's date is {today}\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\")\n",
    "])\n",
    "\n",
    "llm_chain = prompt | llm_with_tools\n",
    "\n",
    "@chain\n",
    "def web_search_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "    print(\"ai_msg: \\n\", ai_msg)\n",
    "    print(\"-\"*100)\n",
    "    tool_msgs = web_search.batch(ai_msg.tool_calls, config=config)\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "    return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "response = web_search_chain.invoke(\"    ?\")\n",
    "\n",
    "pprint(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from typing import List\n",
    "\n",
    "@tool\n",
    "def search_web(query: str) -> List[str]:\n",
    "    \"\"\"Searchs the Internet for Information that does not exist in the datavase or for the latest information\"\"\"\n",
    "    tavily_search = TavilySearchResults(max_results=4)\n",
    "    docs = tavily_search.invoke(query)\n",
    "\n",
    "    formatted_docs = \"\\n---\\n\".join([\n",
    "        f'<Document hreg=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "        for doc in docs\n",
    "        ])\n",
    "    if len(formatted_docs) > 0:\n",
    "        return formatted_docs\n",
    "    return \"  .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": \n",
      "<class 'langchain_core.tools.structured.StructuredTool'>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "name: \n",
      "search_web\n",
      "----------------------------------------------------------------------------------------------------\n",
      "description: \n",
      "Searchs the Internet for Information that does not exist in the datavase or for the latest information\n",
      "----------------------------------------------------------------------------------------------------\n",
      "schema: \n",
      "{'description': 'Searchs the Internet for Information that does not exist in the datavase or for the latest information', 'properties': {'query': {'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'search_web', 'type': 'object'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#  \n",
    "print(\": \")\n",
    "print(type(search_web))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(search_web.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "print(search_web.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "print(search_web.args_schema.schema())\n",
    "print(\"-\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Document hreg=\"https://m.blog.naver.com/wineislikeacat/223096696241\"/>\n",
      " ,     ?  ,  !\n",
      "\n",
      "     .\n",
      "       .\n",
      "       ,\n",
      "     .\n",
      "\n",
      "        ,\n",
      "        \n",
      "        .\n",
      "\n",
      "  \n",
      " (Carbernet Sauvignon), (Syrah)  !\n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "    ? ! [...]      !\n",
      ", !\n",
      "\n",
      "     ?\n",
      "        .\n",
      "        :)\n",
      "\n",
      "      \n",
      "    .\n",
      "\n",
      "? ?  ?    ! - 1,  :)          ... blog.naver.com\n",
      " ? ?  ?    ! - 2,  :)      4  . ... blog.naver.com\n",
      "\n",
      "\n",
      " &     [...]         \n",
      "           .\n",
      "            .\n",
      "\n",
      "           \n",
      " (Sangiovege)   .\n",
      "\n",
      "\n",
      "  \n",
      "\n",
      "   ? ,  !\n",
      "\n",
      "   \n",
      "      .\n",
      "      .\n",
      "\n",
      "      \n",
      "    ,\n",
      "      .\n",
      "\n",
      "        \n",
      "    (Malbec)   !\n",
      "\n",
      "</Document>\n",
      "---\n",
      "<Document hreg=\"https://mashija.com/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%B5%9C%EA%B3%A0%EC%9D%98-%EC%99%80%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%A0%EB%A5%BC-%EA%B2%83%EC%9D%B8/\"/>\n",
      "Bora Kim 2022 1 27\n",
      " (Cabernet Sauvignon)  (Malbec)       ,       ,           . [...] <     5  >\n",
      "  (Cabernet Sauvignon)\n",
      " (Malbec)\n",
      " / (Grenache / Shiraz blends)\n",
      " /(Syrah / Shiraz)\n",
      " (Sangiovese)\n",
      "              .\n",
      "        ,             .\n",
      "<   >\n",
      "              ,        . [...]    (Karen MacNeil)     10  (grilled)          .\n",
      "       \n",
      "2018    (Peter Richards MW)              . .\n",
      "    (Cabernet Franc) ?  (Carignan), (Cinsault)     (Syrah) ? DWWA    Decanter Retailer Awards     (ros)    . .\n",
      "</Document>\n",
      "---\n",
      "<Document hreg=\"https://blog.naver.com/chelina89/220634349414?viewType=pc\"/>\n",
      "1.  - 6 .            .  2.   - 3\n",
      "</Document>\n",
      "---\n",
      "<Document hreg=\"https://brunch.co.kr/@@9J8F/66\"/>\n",
      "           ,         . \n",
      "</Document>\n"
     ]
    }
   ],
   "source": [
    "query = \"   .\"\n",
    "search_results = search_web.invoke(query)\n",
    "\n",
    "print(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_49Yzi17NXdF8uUdjwa5OuvF5', 'function': {'arguments': '{\"query\": \"   \"}', 'name': 'search_web'}, 'type': 'function'}, {'id': 'call_gNq8ynmrwERfIkJtHQLdxgIx', 'function': {'arguments': '{\"query\": \"steak wine pairing recommendations\"}', 'name': 'search_web'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 69, 'total_tokens': 127, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'id': 'chatcmpl-BIycK5x0z1S0tEm6pNV6dRODp7QaG', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-a6510d75-a82d-4fea-85ab-034c858fc2f4-0', tool_calls=[{'name': 'search_web', 'args': {'query': '   '}, 'id': 'call_49Yzi17NXdF8uUdjwa5OuvF5', 'type': 'tool_call'}, {'name': 'search_web', 'args': {'query': 'steak wine pairing recommendations'}, 'id': 'call_gNq8ynmrwERfIkJtHQLdxgIx', 'type': 'tool_call'}], usage_metadata={'input_tokens': 69, 'output_tokens': 58, 'total_tokens': 127, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "''\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[{'args': {'query': '   '},\n",
      "  'id': 'call_49Yzi17NXdF8uUdjwa5OuvF5',\n",
      "  'name': 'search_web',\n",
      "  'type': 'tool_call'},\n",
      " {'args': {'query': 'steak wine pairing recommendations'},\n",
      "  'id': 'call_gNq8ynmrwERfIkJtHQLdxgIx',\n",
      "  'name': 'search_web',\n",
      "  'type': 'tool_call'}]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "llm_with_tools = llm.bind_tools(tools = [search_web])\n",
    "\n",
    "query = \"   .\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "pprint(ai_msg)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\"*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm_gemini_flash = ChatGoogleGenerativeAI(model = \"gemini-1.5-flash\", temperature = 0)\n",
    "llm_gemini_pro = ChatGoogleGenerativeAI(model = \"gemini-1.5-pro\", temperature = 0)\n",
    "llm_groq = ChatGroq(model = \"llama3-70b-8192\", temperature = 0)\n",
    "\n",
    "tools = [search_web]\n",
    "\n",
    "gemini_flash_with_tools = llm_gemini_flash.bind_tools(tools)\n",
    "gemini_pro_with_tools = llm_gemini_pro.bind_tools(tools)\n",
    "groq_with_tools = llm_groq.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gemini 1.5 flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='        .       ,         .\\n\\n       .\\n\\n* ** :**           .  \\n    * **  (Cabernet Sauvignon):**  ,   , ,     ,      .\\n    * ** (Malbec):**     ,   ,       .\\n    * ** (Merlot):**     ,   ,     .\\n    * ** (Syrah) /  (Shiraz):**      ,      .\\n\\n\\n* ** :**          .  \\n    * ** (Chardonnay):**        ,       .\\n\\n\\n  ,   ( ,   )      .', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run-d33e1e50-c35f-47cf-8dd4-fdfb6594c767-0', usage_metadata={'input_tokens': 41, 'output_tokens': 503, 'total_tokens': 544, 'input_token_details': {'cache_read': 0}})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('        .       ,  '\n",
      " '       .\\n'\n",
      " '\\n'\n",
      " '       .\\n'\n",
      " '\\n'\n",
      " '* ** :**           .  \\n'\n",
      " '    * **  (Cabernet Sauvignon):**  ,   , ,   '\n",
      " '  ,      .\\n'\n",
      " '    * ** (Malbec):**     ,   ,       '\n",
      " '.\\n'\n",
      " '    * ** (Merlot):**     ,   ,     .\\n'\n",
      " '    * ** (Syrah) /  (Shiraz):**      ,      '\n",
      " '.\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '* ** :**          .  \\n'\n",
      " '    * ** (Chardonnay):**        ,     '\n",
      " '  .\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '  ,   ( ,   )      .')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#    LLM  \n",
    "\n",
    "query = \"   .\"\n",
    "ai_msg = gemini_flash_with_tools.invoke(query)\n",
    "\n",
    "pprint(ai_msg)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gemini 1.5 Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='     .       .    ?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-pro-002', 'safety_ratings': []}, id='run-17c91247-17f4-450d-9a7b-36405226b74b-0', usage_metadata={'input_tokens': 41, 'output_tokens': 55, 'total_tokens': 96, 'input_token_details': {'cache_read': 0}})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('     .       .    '\n",
      " '?')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"   .\"\n",
    "ai_msg = gemini_pro_with_tools.invoke(query)\n",
    "\n",
    "pprint(ai_msg)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## llama3-70b-8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_7nc8', 'function': {'arguments': '{\"query\":\"wine pairing for steak\"}', 'name': 'search_web'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 925, 'total_tokens': 971, 'completion_time': 0.160059253, 'prompt_time': 0.030079791, 'queue_time': 0.261599722, 'total_time': 0.190139044}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_dd4ae1c591', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-59c5a194-a6ae-4050-848e-c5c61ba90408-0', tool_calls=[{'name': 'search_web', 'args': {'query': 'wine pairing for steak'}, 'id': 'call_7nc8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 925, 'output_tokens': 46, 'total_tokens': 971})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "''\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[{'args': {'query': 'wine pairing for steak'},\n",
      "  'id': 'call_7nc8',\n",
      "  'name': 'search_web',\n",
      "  'type': 'tool_call'}]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"   .\"\n",
    "ai_msg = groq_with_tools.invoke(query)\n",
    "\n",
    "pprint(ai_msg)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmm06\\AppData\\Local\\Temp\\ipykernel_31032\\2088536305.py:24: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  wiki_search = runnable.as_tool(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "#    \n",
    "def search_wiki(input_data:dict) -> List[Document]:\n",
    "    \"\"\"Search Wikepedia documents based on user input(query) and return k documents\"\"\"\n",
    "    qeury = input_data[\"query\"]\n",
    "    k = input_data.get(\"k\", 2)\n",
    "    wiki_loader = WikipediaLoader(query = query, load_max_docs=k, lang = \"ko\")\n",
    "    wiki_docs = wiki_loader.load()\n",
    "    return wiki_docs\n",
    "\n",
    "#      \n",
    "class WikiSearchSchema(BaseModel):\n",
    "    \"\"\"Input schema for Wikipedia search.\"\"\"\n",
    "    query: str = Field(..., description=\"The query to search for in Wikipedia\")\n",
    "    k: int = Field(2, description=\"The number of documents to return(default is 2)\")\n",
    "\n",
    "#    Runnabel  \n",
    "runnable = RunnableLambda(search_wiki)\n",
    "wiki_search = runnable.as_tool(\n",
    "    name = \"wiki_search\",\n",
    "    description=dedent(\"\"\"\n",
    "        Use this took when you need to search for information on Wikipedia.\n",
    "        It searches for Wikipedia aericles related to the useful when general knowledge\n",
    "        or background information is required.\"\"\"),\n",
    "    args_schema=WikiSearchSchema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": \n",
      "<class 'langchain_core.tools.structured.StructuredTool'>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "name: \n",
      "wiki_search\n",
      "----------------------------------------------------------------------------------------------------\n",
      "description: \n",
      "('Use this took when you need to search for information on Wikipedia.\\n'\n",
      " 'It searches for Wikipedia aericles related to the useful when general '\n",
      " 'knowledge\\n'\n",
      " 'or background information is required.')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "schema: \n",
      "{'description': 'Input schema for Wikipedia search.',\n",
      " 'properties': {'k': {'default': 2,\n",
      "                      'description': 'The number of documents to '\n",
      "                                     'return(default is 2)',\n",
      "                      'title': 'K',\n",
      "                      'type': 'integer'},\n",
      "                'query': {'description': 'The query to search for in Wikipedia',\n",
      "                          'title': 'Query',\n",
      "                          'type': 'string'}},\n",
      " 'required': ['query'],\n",
      " 'title': 'WikiSearchSchema',\n",
      " 'type': 'object'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#  \n",
    "print(\": \")\n",
    "print(type(wiki_search))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(wiki_search.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(wiki_search.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(wiki_search.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='(: orzo)  (: risoni, : risone [*])  . \"\" :hordeum  \"\" . \"\" \" \" .            .      .        .   kritharki (\"little barley\")  manstra( ) , lisn al-`ufr (\" \")   .      .\n",
      "  (arpa ehriye) ,  .   ()  .\n",
      "\n",
      "\n",
      "==   ==\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==  ==' metadata={'title': '', 'summary': '(: orzo)  (: risoni, : risone [*])  . \"\" :hordeum  \"\" . \"\" \" \" .            .      .        .   kritharki (\"little barley\")  manstra( ) , lisn al-`ufr (\" \")   .      .\\n  (arpa ehriye) ,  .   ()  .\\n\\n', 'source': 'https://ko.wikipedia.org/wiki/%EC%98%A4%EB%A5%B4%EC%A1%B0'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "page_content=' (Italia , : cucina italiana  [*])    .  4      .        , , ,          .   18   .\n",
      "           .                       ,      .\n",
      "      4~8           .                  ,   .\n",
      "2013 CNN      .\n",
      "\n",
      "\n",
      "==  ==\n",
      "  4  .      ,  ,              .\n",
      "\n",
      "\n",
      "===  ===\n",
      "          .  4              .    ,      ,     .            470      (De re coquinaria )       .                 .              (pecorini)    .             .\n",
      "\n",
      "\n",
      "===  ===\n",
      "               .         .\n",
      "\n",
      " 9             .  , ,   ,    12                  .        .       ,  (atriya)   (trii)  . (Trii)         .         ,      .\n",
      "      ,     .        .        ,      ,          ,      .    ,  .\n",
      "\n",
      "              ,            .     13      (Liber de Coquina)    .            (Lavagna pie)          .\n",
      "15        (Libro de Arte Coquinaria, )          .      (Maccaroni Siciliani,  )          .         .         .         (coppiette) .         (Bolognese Torta,  )  (Sienese torta,  )     , , ,       .\n",
      "  1475        (De honesta voluptate et valetudine) .       ,               .\n",
      "\n",
      "\n",
      "===   ===\n",
      "    , ,       .         . 1549     (Christoforo Messisbugo) Banchetti Composizioni di Vivande     .       , 124     .\n",
      "\n",
      "1570   5      (Opera) .                     ,      .            .           .  ,     . 3     .     ,    . 5                .          .   ,      .\n",
      "1600  (Giangiacomo Castelvetro)    , (Brieve Racconto di Tutte le Radici di Tutte l'Herbe et di Tutti i Frutti)  .      .     ,' metadata={'title': ' ', 'summary': ' (Italia , : cucina italiana  [*])    .  4      .        , , ,          .   18   .\\n           .                       ,      .\\n      4~8           .                  ,   .\\n2013 CNN      .\\n\\n', 'source': 'https://ko.wikipedia.org/wiki/%EC%9D%B4%ED%83%88%EB%A6%AC%EC%95%84_%EC%9A%94%EB%A6%AC'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \" \"\n",
    "wiki_result = wiki_search.invoke({\"query\":query})\n",
    "\n",
    "for result in wiki_result:\n",
    "    print(result)\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_QCX2JKX0LtCU1s5JuEJAejnu', 'function': {'arguments': '{\"query\": \"    \"}', 'name': 'search_web'}, 'type': 'function'}, {'id': 'call_vwPBRNLcMkLCVxZLpTJPasEX', 'function': {'arguments': '{}', 'name': 'search_wiki'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 108, 'total_tokens': 159, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'id': 'chatcmpl-BIzNOBqsnMEaL8Ao9GcSqNciztAfE', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-02a7956d-66d4-46f4-bde9-54ee7663bcb2-0', tool_calls=[{'name': 'search_web', 'args': {'query': '    '}, 'id': 'call_QCX2JKX0LtCU1s5JuEJAejnu', 'type': 'tool_call'}, {'name': 'search_wiki', 'args': {}, 'id': 'call_vwPBRNLcMkLCVxZLpTJPasEX', 'type': 'tool_call'}], usage_metadata={'input_tokens': 108, 'output_tokens': 51, 'total_tokens': 159, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "''\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[{'args': {'query': '    '},\n",
      "  'id': 'call_QCX2JKX0LtCU1s5JuEJAejnu',\n",
      "  'name': 'search_web',\n",
      "  'type': 'tool_call'},\n",
      " {'args': {},\n",
      "  'id': 'call_vwPBRNLcMkLCVxZLpTJPasEX',\n",
      "  'name': 'search_wiki',\n",
      "  'type': 'tool_call'}]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "llm_with_tools = llm.bind_tools(tools = [search_web, search_wiki])\n",
    "\n",
    "query = \"     ?    .\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "pprint(ai_msg)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LCEL \n",
    "\n",
    "###     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('( )  ,        .    ,  '\n",
      " ' .    ,   . \\n'\n",
      " '\\n'\n",
      " '   4   ,     .   ,   '\n",
      " '  .      , 2013 CNN     .  '\n",
      " '    ,     ,      .')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "def wiki_search_and_summarize(input_data: dict):\n",
    "    wiki_loader = WikipediaLoader(query = input_data[\"query\"], load_max_docs=2, lang = \"ko\")\n",
    "    wiki_docs = wiki_loader.load()\n",
    "\n",
    "    formatted_docs = [f'<Document sorce=\"{doc.metadata[\"source\"]}\"/>\\n{doc.page_content}\\n</Document>' for doc in wiki_docs]\n",
    "\n",
    "    return formatted_docs\n",
    "\n",
    "#   \n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the following text in a concise manner: \\n\\n{context}\\n\\nSummary\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model = 'gpt-4o-mini', temperature = 0)\n",
    "summary_chain = (\n",
    "    {\"context\": RunnableLambda(wiki_search_and_summarize)} | summary_prompt | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "summarized_text = summary_chain.invoke({\"query\": \" \"})\n",
    "pprint(summarized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": \n",
      "<class 'langchain_core.tools.structured.StructuredTool'>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "name: \n",
      "wiki_summary\n",
      "----------------------------------------------------------------------------------------------------\n",
      "description: \n",
      "('Use this took when you need to search for information on Wikipedia.\\n'\n",
      " \"It searches for Wikipedia articles related to the user's query and returns\\n\"\n",
      " 'a summarized text. This tool is useful when genral knowledge\\n'\n",
      " 'or background information is required.')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "schema: \n",
      "{'description': 'Input schema for Wikipedia search.',\n",
      " 'properties': {'query': {'description': 'The query to search for wikipedia',\n",
      "                          'title': 'Query',\n",
      "                          'type': 'string'}},\n",
      " 'required': ['query'],\n",
      " 'title': 'WikiSummarySchema',\n",
      " 'type': 'object'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#      \n",
    "class WikiSummarySchema(BaseModel):\n",
    "    \"\"\"Input schema for Wikipedia search.\"\"\"\n",
    "    query: str = Field(..., description=\"The query to search for wikipedia\")\n",
    "\n",
    "# as_tool     \n",
    "wiki_summary = summary_chain.as_tool(\n",
    "    name = \"wiki_summary\",\n",
    "    description=dedent(\"\"\"\n",
    "        Use this took when you need to search for information on Wikipedia.\n",
    "        It searches for Wikipedia articles related to the user's query and returns\n",
    "        a summarized text. This tool is useful when genral knowledge\n",
    "        or background information is required.\"\"\"),\n",
    "        args_schema = WikiSummarySchema)\n",
    "\n",
    "#  \n",
    "print(\": \")\n",
    "print(type(wiki_summary))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(wiki_summary.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(wiki_summary.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(wiki_summary.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_yMotlokTiwxOL8MLgSv3rj0f', 'function': {'arguments': '{\"query\": \"    \"}', 'name': 'search_web'}, 'type': 'function'}, {'id': 'call_ulZ9wp43OdtD0Gu2s0xYXQrn', 'function': {'arguments': '{\"query\": \"\"}', 'name': 'wiki_summary'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 152, 'total_tokens': 206, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'id': 'chatcmpl-BJ0EZOJlPSMGqQyKV9VWpEjKxMOpY', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-cff28947-8a32-42c0-b9fb-f8f96966bd5d-0', tool_calls=[{'name': 'search_web', 'args': {'query': '    '}, 'id': 'call_yMotlokTiwxOL8MLgSv3rj0f', 'type': 'tool_call'}, {'name': 'wiki_summary', 'args': {'query': ''}, 'id': 'call_ulZ9wp43OdtD0Gu2s0xYXQrn', 'type': 'tool_call'}], usage_metadata={'input_tokens': 152, 'output_tokens': 54, 'total_tokens': 206, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "''\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[{'args': {'query': '    '},\n",
      "  'id': 'call_yMotlokTiwxOL8MLgSv3rj0f',\n",
      "  'name': 'search_web',\n",
      "  'type': 'tool_call'},\n",
      " {'args': {'query': ''},\n",
      "  'id': 'call_ulZ9wp43OdtD0Gu2s0xYXQrn',\n",
      "  'name': 'wiki_summary',\n",
      "  'type': 'tool_call'}]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "llm_with_tools = llm.bind_tools(tools= [search_web, wiki_summary])\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "pprint(ai_msg)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'wiki_summary',\n",
       " 'args': {'query': ''},\n",
       " 'id': 'call_ulZ9wp43OdtD0Gu2s0xYXQrn',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg.tool_calls[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='    ,       ,   .    ,    . ,       ,  13   .    ,     .       ,    . \\n\\n      ,    ,    .' name='wiki_summary' tool_call_id='call_ulZ9wp43OdtD0Gu2s0xYXQrn'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('    ,       ,   .   '\n",
      " ' ,    . ,       ,  '\n",
      " '13   .    ,     .    '\n",
      " '   ,    . \\n'\n",
      " '\\n'\n",
      " '      ,    ,    .')\n"
     ]
    }
   ],
   "source": [
    "tool_message = wiki_summary.invoke(ai_msg.tool_calls[1])\n",
    "\n",
    "print(tool_message)\n",
    "print(\"-\"*100)\n",
    "pprint(tool_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai_msg: \n",
      " content='' additional_kwargs={'tool_calls': [{'id': 'call_Iv9tejcajwK9PdPoB2VVHvbe', 'function': {'arguments': '{\"query\":\" \"}', 'name': 'wiki_summary'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 120, 'total_tokens': 140, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_86d0290411', 'id': 'chatcmpl-BJ0IAia0hmUGgNcb7yZpAFhSL8odr', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-28df5d94-082f-4534-ada7-e2cf990d7c2f-0' tool_calls=[{'name': 'wiki_summary', 'args': {'query': ' '}, 'id': 'call_Iv9tejcajwK9PdPoB2VVHvbe', 'type': 'tool_call'}] usage_metadata={'input_tokens': 120, 'output_tokens': 20, 'total_tokens': 140, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tool_msgs: \n",
      " [ToolMessage(content='[{\"title\": \" - ,   \", \"url\": \"https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%8A%A4%ED%83%80\", \"content\": \"Link to USDA Database entry\\\\n        ,[1]       .[2]\\\\n(: pasta)   .                ,   .  ,[3][4]     .\\\\n\\\\n\\\\n\\\\n \\\\\"(pasta)\\\\\" \\\\\", \\\\\"  .\\\\n\\\\n [...] ,   2000    ,    .      [10]     .            .[11]    \\\\\"\\\\\" (lagana)     ,        .    [9]           .\\\\n\\\\n          5                .\\\\n\\\\n\\\\n\\\\n  \\\\n\\\\n [...]  1   lagana    ,   . 2     1     lagana  .                  . 5             lagana   ,       .            .         13 14 .[9]\", \"score\": 0.86080295}, {\"title\": \"  ?   ()  - \", \"url\": \"https://www.noodlelovers.com/_kor/developer/m_product_noodle_set/m_index.asp?m_mode=product_view&pds_no=20170329151923381949048&sel_no1=86\", \"content\": \"      ?      .   .      1298    .\\\\n\\\\n    0% .     .    (al-Idrisi) 12    ()    (trii)   . 12  1100,    1298 200 . 1279    (Ponzio Bastone)      (bariscella de macaronis) .     ,    .        . [...]        .      (itrion) (tria)  .   (itriyya)     .  (laganum)   .     (lasagna)  .   , ,     ,     .         .(pasta)      .   (spaghetti)   .        2  .     (dough) . [...]        .      (itrion) (tria)  .   (itriyya)     .  (laganum)   .     (lasagna)  .   , ,     ,     .         .(pasta)      .   (spaghetti)   .        2  .     (dough) .\", \"score\": 0.85995835}, {\"title\": \"   -  \", \"url\": \"http://m.blog.naver.com/rokmcssj/20185188044\", \"content\": \"\\\\n\\\\n \\\\n\\\\n\\\\n\\\\n\\\\n~\\\\n\\\\n  \\\\n\\\\n2013. 4. 7. 3:54\\\\n\\\\n \\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n? ??\\\\n\\\\n          \\\\n\\\\n  .         \\\\n\\\\n,\\xa0        .\\\\n\\\\n\\\\n\\\\n     ,      \\\\n\\\\n      .\\\\n\\\\n          \\\\n\\\\n         .\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n \\\\n\\\\n\\\\n\\\\n   .  3         [...]        1   .    \\\\n\\\\n1295           .\\\\n\\\\n\\\\n\\\\n 12 ,         \\xa0        \\\\n\\\\n        .\\\\n\\\\n\\\\n\\\\n    ,       \\xa0              .\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n  \\\\n\\\\n\\\\n\\\\n        .   [...]    <  >     \\\\n\\\\n      .\\\\n\\\\n\\\\n\\\\n  !\\\\n\\\\n          .  \\\\n\\\\n  11       .\\\\n\\\\n\\\\n\\\\n        \\\\n\\\\n12     .     \\ufeff\\ufeff\\\\n\\\\n ,       .\\\\n\\\\n\\\\n\\\\n \\\\n\\\\n\\\\n\\\\n        16  \\\\n\\\\n   ,     . \", \"score\": 0.8415267}, {\"title\": \"  : A-Z   - MICHELIN Guide\", \"url\": \"https://guide.michelin.com/kr/ko/article/features/world-pasta-day-an-a-z-guide-to-pasta-kr\", \"content\": \"  \\\\\"paste\\\\\" ,          .          .       :          , 8        .     ,              . ,               .                A-Z   .    .      !   : [...]       .      \\\\\"\\\\\"  \\\\\"(pest) \\\\\"  \\\\\"(pestare)\\\\\" . [...]    300    ?     , ,    .             ,          .  ,     (farfalle),    (strichetti) .       .       ,   ,    ,       ,            .        ,        .  \\\\\"\\\\\"\", \"score\": 0.8390101}]', name='tavily_search_results_json', tool_call_id='call_Iv9tejcajwK9PdPoB2VVHvbe', artifact={'query': ' ', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%8A%A4%ED%83%80', 'title': ' - ,   ', 'content': 'Link to USDA Database entry\\n        ,[1]       .[2]\\n(: pasta)   .                ,   .  ,[3][4]     .\\n\\n\\n\\n \"(pasta)\" \", \"  .\\n\\n [...] ,   2000    ,    .      [10]     .            .[11]    \"\" (lagana)     ,        .    [9]           .\\n\\n          5                .\\n\\n\\n\\n  \\n\\n [...]  1   lagana    ,   . 2     1     lagana  .                  . 5             lagana   ,       .            .         13 14 .[9]', 'score': 0.86080295, 'raw_content': None}, {'url': 'https://www.noodlelovers.com/_kor/developer/m_product_noodle_set/m_index.asp?m_mode=product_view&pds_no=20170329151923381949048&sel_no1=86', 'title': '  ?   ()  - ', 'content': '      ?      .   .      1298    .\\n\\n    0% .     .    (al-Idrisi) 12    ()    (trii)   . 12  1100,    1298 200 . 1279    (Ponzio Bastone)      (bariscella de macaronis) .     ,    .        . [...]        .      (itrion) (tria)  .   (itriyya)     .  (laganum)   .     (lasagna)  .   , ,     ,     .         .(pasta)      .   (spaghetti)   .        2  .     (dough) . [...]        .      (itrion) (tria)  .   (itriyya)     .  (laganum)   .     (lasagna)  .   , ,     ,     .         .(pasta)      .   (spaghetti)   .        2  .     (dough) .', 'score': 0.85995835, 'raw_content': None}, {'url': 'http://m.blog.naver.com/rokmcssj/20185188044', 'title': '   -  ', 'content': '\\n\\n \\n\\n\\n\\n\\n~\\n\\n  \\n\\n2013. 4. 7. 3:54\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n? ??\\n\\n          \\n\\n  .         \\n\\n,\\xa0        .\\n\\n\\n\\n     ,      \\n\\n      .\\n\\n          \\n\\n         .\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n   .  3         [...]        1   .    \\n\\n1295           .\\n\\n\\n\\n 12 ,         \\xa0        \\n\\n        .\\n\\n\\n\\n    ,       \\xa0              .\\n\\n\\n\\n\\n\\n\\n\\n  \\n\\n\\n\\n        .   [...]    <  >     \\n\\n      .\\n\\n\\n\\n  !\\n\\n          .  \\n\\n  11       .\\n\\n\\n\\n        \\n\\n12     .     \\ufeff\\ufeff\\n\\n ,       .\\n\\n\\n\\n \\n\\n\\n\\n        16  \\n\\n   ,     . ', 'score': 0.8415267, 'raw_content': None}, {'url': 'https://guide.michelin.com/kr/ko/article/features/world-pasta-day-an-a-z-guide-to-pasta-kr', 'title': '  : A-Z   - MICHELIN Guide', 'content': '  \"paste\" ,          .          .       :          , 8        .     ,              . ,               .                A-Z   .    .      !   : [...]       .      \"\"  \"(pest) \"  \"(pestare)\" . [...]    300    ?     , ,    .             ,          .  ,     (farfalle),    (strichetti) .       .       ,   ,    ,       ,            .        ,        .  \"\"', 'score': 0.8390101, 'raw_content': None}], 'response_time': 3.03})]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('      .    ,     , '\n",
      " '       ,       . \\n'\n",
      " '\\n'\n",
      " '### \\n'\n",
      " '1. ** **:   13      .      '\n",
      " '   .  , 12            '\n",
      " '  .\\n'\n",
      " '\\n'\n",
      " \"2. **  **:   '(itrion)' '(tria)'    , \"\n",
      " \" '(laganum)'  .      .\\n\"\n",
      " '\\n'\n",
      " '3. ** **: 8           . '\n",
      " '      .\\n'\n",
      " '\\n'\n",
      " '### \\n'\n",
      " '      ,  , ,      . '\n",
      " '      , 2        '\n",
      " '.\\n'\n",
      " '\\n'\n",
      " '  [  '\n",
      " '](https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%8A%A4%ED%83%80)   .')\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "#  \n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", f\"you are a helpful AI assistant. Today's date is {today}\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\")\n",
    "])\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools = [wiki_summary])\n",
    "\n",
    "llm_chain = prompt | llm_with_tools\n",
    "\n",
    "@chain\n",
    "def wiki_summary_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "    print(\"ai_msg: \\n\", ai_msg)\n",
    "    print(\"-\"*100)\n",
    "    tool_msgs = web_search.batch(ai_msg.tool_calls, config=config)\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "    return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "response = web_search_chain.invoke(\"   .\")\n",
    "\n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  \n",
    "\n",
    "### @tool decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10   .\n",
      "\n",
      " : 1\n",
      "\n",
      " :  \n",
      "\n",
      ": 1.  \n",
      "    : 35,000\n",
      "     :   ,  ,  \n",
      "    :    , ...\n",
      "\n",
      " : 2\n",
      "\n",
      " :  \n",
      "\n",
      ": 2.  \n",
      "    : 22,000\n",
      "     :   ,  ,   \n",
      "    :   ...\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./data/restaurant_menu.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "#  \n",
    "def split_menu_items(document):\n",
    "    \"\"\"\n",
    "       \n",
    "    \"\"\"\n",
    "    pattern = r'(\\d+\\.\\s.*?)(?=\\n\\n\\d+\\.|$)' #  \n",
    "    menu_items = re.findall(pattern, document.page_content, re.DOTALL)\n",
    "\n",
    "    menu_documents = []\n",
    "    for i, item in enumerate(menu_items, 1):\n",
    "        #   \n",
    "        menu_name = item.split('\\n')[0].split('.', 1)[1].strip()\n",
    "\n",
    "        menu_doc = Document(\n",
    "            page_content = item.strip(),\n",
    "            metadata = {\n",
    "                \"source\": document.metadata['source'],\n",
    "                \"menu_number\": i,\n",
    "                \"menu_name\": menu_name\n",
    "            }\n",
    "        )\n",
    "        menu_documents.append(menu_doc)\n",
    "\n",
    "    return menu_documents\n",
    "\n",
    "menu_documents = []\n",
    "for doc in documents:\n",
    "    menu_documents += split_menu_items(doc)\n",
    "\n",
    "print(f\" {len(menu_documents)}   .\")\n",
    "for doc in menu_documents[:2]:\n",
    "    print(f\"\\n : {doc.metadata['menu_number']}\")\n",
    "    print(f\"\\n : {doc.metadata['menu_name']}\")\n",
    "    print(f\"\\n: {doc.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " : 2\n",
      " : 1\n",
      " :  \n",
      "\n",
      " : 8\n",
      " :   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chroma Vectorstore\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embedding_model = OllamaEmbeddings(model = \"bge-m3\")\n",
    "\n",
    "menu_db = Chroma.from_documents(\n",
    "    documents=menu_documents,\n",
    "    embedding=embedding_model,\n",
    "    collection_name=\"restaurant_menu\",\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "\n",
    "menu_retriever = menu_db.as_retriever(\n",
    "    search_kwargs = {'k':2},\n",
    ")\n",
    "\n",
    "qeury = \"    ?\"\n",
    "docs = menu_retriever.invoke(qeury)\n",
    "print(f' : {len(docs)}')\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\" : {doc.metadata['menu_number']}\")\n",
    "    print(f\" : {doc.metadata['menu_name']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": \n",
      "<class 'langchain_core.tools.structured.StructuredTool'>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "name: \n",
      "search_menu\n",
      "----------------------------------------------------------------------------------------------------\n",
      "description: \n",
      "('Securely retrieve and access authorized restaurant menu information from the '\n",
      " 'encrypted database.\\n'\n",
      " 'Use this tool only for menu-related queries to maintatin data '\n",
      " 'confidentiality.')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "schema: \n",
      "{'description': 'Securely retrieve and access authorized restaurant menu '\n",
      "                'information from the encrypted database.\\n'\n",
      "                'Use this tool only for menu-related queries to maintatin data '\n",
      "                'confidentiality.',\n",
      " 'properties': {'query': {'title': 'Query', 'type': 'string'}},\n",
      " 'required': ['query'],\n",
      " 'title': 'search_menu',\n",
      " 'type': 'object'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "menu_db = Chroma(\n",
    "    embedding_function=embedding_model,\n",
    "    collection_name=\"restaurant_menu\",\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "\n",
    "@tool\n",
    "def search_menu(query: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Securely retrieve and access authorized restaurant menu information from the encrypted database.\n",
    "    Use this tool only for menu-related queries to maintatin data confidentiality.\n",
    "    \"\"\"\n",
    "    docs = menu_db.similarity_search(query, k=2)\n",
    "    if len(docs) > 0:\n",
    "        return docs\n",
    "    \n",
    "    return [Document(page_content=\"    .\")] #  \n",
    "\n",
    "#  \n",
    "print(\": \")\n",
    "print(type(search_menu))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(search_menu.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(search_menu.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(search_menu.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10   .\n",
      "\n",
      " : 1\n",
      "\n",
      " :   2015\n",
      "\n",
      ": 1.   2015\n",
      "    : 450,000\n",
      "     :  , ,  ,  \n",
      "    :     ...\n",
      "\n",
      " : 2\n",
      "\n",
      " :   2012\n",
      "\n",
      ": 2.   2012\n",
      "    : 380,000\n",
      "     : ,  \n",
      "    :      . ...\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./data/restaurant_wine.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "#  \n",
    "def split_menu_items(document):\n",
    "    \"\"\"\n",
    "       \n",
    "    \"\"\"\n",
    "    pattern = r'(\\d+\\.\\s.*?)(?=\\n\\n\\d+\\.|$)' #  \n",
    "    menu_items = re.findall(pattern, document.page_content, re.DOTALL)\n",
    "\n",
    "    menu_documents = []\n",
    "    for i, item in enumerate(menu_items, 1):\n",
    "        #   \n",
    "        menu_name = item.split('\\n')[0].split('.', 1)[1].strip()\n",
    "\n",
    "        menu_doc = Document(\n",
    "            page_content = item.strip(),\n",
    "            metadata = {\n",
    "                \"source\": document.metadata['source'],\n",
    "                \"wine_number\": i,\n",
    "                \"wine_name\": menu_name\n",
    "            }\n",
    "        )\n",
    "        menu_documents.append(menu_doc)\n",
    "\n",
    "    return menu_documents\n",
    "\n",
    "menu_documents = []\n",
    "for doc in documents:\n",
    "    menu_documents += split_menu_items(doc)\n",
    "\n",
    "print(f\" {len(menu_documents)}   .\")\n",
    "for doc in menu_documents[:2]:\n",
    "    print(f\"\\n : {doc.metadata['wine_number']}\")\n",
    "    print(f\"\\n : {doc.metadata['wine_name']}\")\n",
    "    print(f\"\\n: {doc.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": \n",
      "<class 'langchain_core.tools.structured.StructuredTool'>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "name: \n",
      "search_wine\n",
      "----------------------------------------------------------------------------------------------------\n",
      "description: \n",
      "('Securely retrieve and access authorized restaurant wine information from the '\n",
      " 'encrypted database.\\n'\n",
      " 'Use this tool only for wine-related queries to maintatin data '\n",
      " 'confidentiality.')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "schema: \n",
      "{'description': 'Securely retrieve and access authorized restaurant wine '\n",
      "                'information from the encrypted database.\\n'\n",
      "                'Use this tool only for wine-related queries to maintatin data '\n",
      "                'confidentiality.',\n",
      " 'properties': {'query': {'title': 'Query', 'type': 'string'}},\n",
      " 'required': ['query'],\n",
      " 'title': 'search_wine',\n",
      " 'type': 'object'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "wine_db = Chroma(\n",
    "    embedding_function=embedding_model,\n",
    "    collection_name=\"restaurant_wine\",\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "\n",
    "@tool\n",
    "def search_wine(query: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Securely retrieve and access authorized restaurant wine information from the encrypted database.\n",
    "    Use this tool only for wine-related queries to maintatin data confidentiality.\n",
    "    \"\"\"\n",
    "    docs = wine_db.similarity_search(query, k=2)\n",
    "    if len(docs) > 0:\n",
    "        return docs\n",
    "    \n",
    "    return [Document(page_content=\"    .\")] #  \n",
    "\n",
    "#  \n",
    "print(\": \")\n",
    "print(type(search_wine))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(search_wine.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(search_wine.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(search_wine.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_8UWqY4dUiy3d1eDhsQ7bolk1', 'function': {'arguments': '{\"query\": \" \"}', 'name': 'search_menu'}, 'type': 'function'}, {'id': 'call_5r35hyh0WwhrBUNyf8tDACcu', 'function': {'arguments': '{\"query\": \"\"}', 'name': 'search_wine'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 139, 'total_tokens': 193, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'id': 'chatcmpl-BJ1mXOuucJRRsaS9muaDA3TyJcRAD', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-9084e92c-018d-42d9-a610-a2528b6c3a04-0', tool_calls=[{'name': 'search_menu', 'args': {'query': ' '}, 'id': 'call_8UWqY4dUiy3d1eDhsQ7bolk1', 'type': 'tool_call'}, {'name': 'search_wine', 'args': {'query': ''}, 'id': 'call_5r35hyh0WwhrBUNyf8tDACcu', 'type': 'tool_call'}], usage_metadata={'input_tokens': 139, 'output_tokens': 54, 'total_tokens': 193, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "''\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[{'args': {'query': ' '},\n",
      "  'id': 'call_8UWqY4dUiy3d1eDhsQ7bolk1',\n",
      "  'name': 'search_menu',\n",
      "  'type': 'tool_call'},\n",
      " {'args': {'query': ''},\n",
      "  'id': 'call_5r35hyh0WwhrBUNyf8tDACcu',\n",
      "  'name': 'search_wine',\n",
      "  'type': 'tool_call'}]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# LLM  \n",
    "llm_with_tools = llm.bind_tools(tools=[search_menu, search_wine])\n",
    "\n",
    "query = \"    ?      .\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "pprint(ai_msg)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\"*100)\n",
    "\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
